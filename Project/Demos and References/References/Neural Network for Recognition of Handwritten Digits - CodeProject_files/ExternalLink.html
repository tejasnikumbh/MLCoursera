<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">


<html>
<head>
	<title>Neural Network for Recognition of Handwritten Digits - CodeProject</title> 
	<link type="text/css" rel="stylesheet" href="/App_Themes/CodeProject/Css/Main.min.css?dt=2.6.1309024.1">

	
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="Description" content="A convolutional neural network achieves 99.26% accuracy on a modified NIST database of hand-written digits.; Author: Mike O&#39;Neill; Updated: 5 Dec 2006; Section: Libraries; Chapter: Platforms, Frameworks &amp; Libraries; Updated: 5 Dec 2006" />
<meta name="Keywords" content="VC6, Win2K, WinXP, MFC, Dev, Advanced,Libraries,Platforms, Frameworks &amp; Libraries,Free source code, tutorials" />
<meta name="Author" content="Mike O&#39;Neill" />
<meta name="Rating" content="General" />
<meta name="Robots" content="index, follow, NOODP" />
<meta name="Revisit-After" content="1 days" />
<meta name="application-name" content="CodeProject" />

<link rel="dns-prefetch" href="//ajax.googleapis.com" /> 
<link rel="canonical" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi" />


<link rel="alternate" type="application/rss+xml" title="CodeProject Latest articles - All Topics" href="http://www.codeproject.com/WebServices/ArticleRSS.aspx?cat=1" />
<link rel="alternate" type="application/rss+xml" title="CodeProject Latest articles - MFC/C++" href="http://www.codeproject.com/WebServices/ArticleRSS.aspx?cat=2" />
<link rel="alternate" type="application/rss+xml" title="CodeProject Latest articles - C#" href="http://www.codeproject.com/WebServices/ArticleRSS.aspx?cat=3" />
<link rel="alternate" type="application/rss+xml" title="CodeProject Latest articles - VB.NET" href="http://www.codeproject.com/WebServices/ArticleRSS.aspx?cat=6" />
<link rel="alternate" type="application/rss+xml" title="CodeProject Latest articles - Mobile" href="http://www.codeproject.com/WebServices/ArticleRSS.aspx?cat=18" />
<link rel="alternate" type="application/rss+xml" title="CodeProject Latest articles - ASP.NET" href="http://www.codeproject.com/WebServices/ArticleRSS.aspx?cat=4" />
<link rel="alternate" type="application/rss+xml" title="CodeProject Lounge Postings" href="http://www.codeproject.com/webservices/LoungeRSS.aspx" />
<link rel="search" type="application/opensearchdescription+xml" title="CodeProject" href="http://www.codeproject.com/info/OpenSearch.xml" />

	<base target="_top" />
	<link rel="icon" href="/favicon.ico" type="image/ico" >
<link rel="shortcut icon" href="/favicon.ico"  type="image/ico" >
<link rel="apple-touch-icon" href="/images/FavIcon-Apple.png" type="image/png" >
<script type="text/javascript" language="Javascript">//<![CDATA[
function defrm () { /* thanks twitter */ document.write = ''; window.top.location = window.self.location;  setTimeout(function() { document.body.innerHTML = ''; }, 0);  window.self.onload = function(evt) { document.body.innerHTML = ''; }; }if (window.top !== window.self) {  try {  if (window.top.location.host) { /* will throw */ } else { defrm(); /* chrome */ }  } catch (ex) { defrm(); /* everyone else */ } }if (typeof(DemoUrl)!='undefined')   document.write(unescape('%3Cme')+'ta http'+'-equiv="re'+'fresh"                  con'+'tent="1;url='+DemoUrl+unescape('"%3CE'));
function _dmBootstrap(file) { var _dma = document.createElement('script');  _dma.type = 'text/javascript'; _dma.async = true;  _dma.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + file; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(_dma);}
function _dmFollowup(file) { if (typeof DMAds === 'undefined')  _dmBootstrap('cdn2.developermedia.com/a.min.js?dt=2.6.1309024.1');}
(function () { _dmBootstrap('cdn1.developermedia.com/a.min.js?dt=2.6.1309024.1'); setTimeout(_dmFollowup, 2000);})();

//]]>
</script>

	




<script type="text/javascript">
	var _gaq = _gaq || [];
	_gaq.push(['_setAccount', 'UA-1735123-1']);
	_gaq.push(['_trackPageview']);
	_gaq.push(['_setDomainName', 'www.codeproject.com']);
	_gaq.push(['_setSessionTimeout', '1200']); 

	(function () {
		var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ga);
	})(); 
</script>


</head>	

<body class="firefox firefox23">

<a href="#Main"><img alt="Click here to Skip to main content" class="access-link" src="/Images/t.gif" /></a>





<div class="page-background">

	
	

	

	<table id="ctl00_Bn" style="width:100%;height:135px" cellpadding="0" cellspacing="0" class="banner fixed">
	<tr valign="bottom">
		<td class="blank-background" style="height:31px">&nbsp;</td>
		<td class="blank-background" rowspan="3" style="width:250px;height:135px"><a href="/"><img id="ctl00_Logo" tabindex="1" title="CodeProject" src="/App_Themes/CodeProject/Img/logo250x135.gif" alt="Home" style="height:135px;width:250px;border-width:0px;" /></a></td>
		<td class="blank-background align-right" style="width:728px;height:31px">

<div class="container memberbar clearfix">

	<div id="ctl00_MemberMenu_GenInfo" class="float-left">10,104,583 members (35,725 online) &nbsp; &nbsp; </div>

	<div class="float-left">
		
	</div>

	<div class="float-right">

		<span id="ctl00_MemberMenu_CodeProjectTV" class="tooltip" style="margin-right:15px;">
			<div class="speech-bubble-container-up" style="width:180px;line-height:20px">
				<div class="speech-bubble-up">
					<b><a href="http://codeproject.TV">Visit CodeProject.TV</a><br />
					<a id="ctl00_MemberMenu_DiscussCPTV" href="/Forums/1829610/CodeProject-TV.aspx">Discuss CodeProject.TV</a></b>
				</div>
				<div class="speech-bubble-pointer-up">
					<div class="speech-bubble-pointer-up-inner"></div>
				</div>
			</div>
		</span>

		

		<span id="ctl00_MemberMenu_Messages_NotificationDiv" class="tooltip member-message">
	<a id="ctl00_MemberMenu_Messages_NotificationCount" class="notification-count" href="/script/Membership/MyNotifications.aspx">1</a>

	<div class="tooltip-flyout notification-dropdown">
		
		<div id="ctl00_MemberMenu_Messages_Confirm" class="bold spaced"><a id="ctl00_MemberMenu_Messages_EmailConfirm" href="/script/Membership/SendConfirmRequest.aspx?rp=%2fArticles%2f16650%2fNeural-Network-for-Recognition-of-Handwritten-Digi">Your email address needs to be confirmed.</a></div>
		
		<div id="Notifications" class="notification-list">
			<img src="/images/animated_loading.gif" alt="loading" style="margin:auto;" />
		</div>
		<div class="spaced">
			
		</div>
	</div>
</span><span id="ctl00_MemberMenu_CurRat" class="tooltip">
				<a id="ctl00_MemberMenu_MyProfile" href="/script/Membership/View.aspx?mid=10295269">Member 10295269</a><img src="/Images/arrow-down-16.png" 
					style="width:16px;height:16px;vertical-align:text-top" />
				<div class="tooltip-flyout" style="width:135px !important">
					<div class="list-item"><a id="ctl00_MemberMenu_MySettingsDefault" href="https://www.codeproject.com/script/Membership/Modify.aspx">My Settings</a></div>
					
					<div class="list-item"><a id="ctl00_MemberMenu_MyContacts" href="/script/Membership/ListContacts.aspx">My Contact info</a></div>
					<div class="list-item"><a id="ctl00_MemberMenu_MyBookmarks" href="/script/Bookmarks/List.aspx?obtid=2">My Bookmarks</a></div>
					
					<div class="list-item"><a id="ctl00_MemberMenu_MyCodeProject" href="/script/Membership/MyWatchedItems.aspx">My Watched Items</a></div>
					<div class="list-item"><a id="ctl00_MemberMenu_MyArticles" href="/script/Articles/MemberArticles.aspx?amid=10295269">My Articles</a></div>
					<div class="list-item"><a id="ctl00_MemberMenu_MyMessages" href="/script/Forums/Messages.aspx?fmid=10295269">My Messages</a></div>
					<div class="list-item"><a id="ctl00_MemberMenu_MyQuestions" href="/script/Answers/MemberPosts.aspx?tab=questions&amp;mid=10295269&amp;showall=True">My Questions</a></div>
					<div class="list-item"><a id="ctl00_MemberMenu_MyAnswers" href="/script/Answers/MemberPosts.aspx?tab=answers&amp;mid=10295269&amp;showall=True">My Answers</a></div>
					<div class="list-item"><a id="ctl00_MemberMenu_MyComments" href="/script/comments/MemberComments.aspx?mid=10295269">My Comments</a></div>
					
					
				</div>
			</span><span id="ctl00_MemberMenu_TotalPoints" title="Total reputation points"><a class="bold member-rep-box bronze" title="305" href="/script/Reputation/List.aspx?mid=10295269">305</a></span>
			&nbsp;
			<a id="ctl00_MemberMenu_Signout" href="/script/Membership/LogOff.aspx?rp=%2fArticles%2f16650%2fNeural-Network-for-Recognition-of-Handwritten-Digi">Sign out</a>
			<img src="/images/circle-cross.gif" width="16px" height="16px" style="vertical-align:middle;margin-top:-3px;"/>
		

		
	</div>
</div></td>
		<td class="blank-background" style="height:31px">&nbsp;</td>
	</tr>
	<tr valign="middle">
		<td class="theme1-background" style="height:94px">&nbsp;</td>
		<td class="theme1-background ad"><div class="msg-728x90" data-format="728x90" data-type="ad" data-publisher="lqm.codeproject.site" data-zone="ros"  data-tags='VC6, Win2K, WinXP, MFC, Dev, Advanced,rating4.5'></div></td>
		<td class="theme1-background" style="height:94px">&nbsp;</td>
	</tr>
	<tr valign="top">
		<td style="height: 10px;"></td>
		<td style="height: 10px;" class="blank-background"></td>
		<td style="height: 10px;"></td>
	</tr>
</table>


	<a href="#Main"><img alt="Click here to Skip to main content" class="access-link" 
		src="/Images/t.gif" /></a>

	
	<div id="ctl00_TPR" class="sub-headerbar fixed">
	<table cellpadding="0" cellspacing="0" class="extended"><tr><td nowrap="nowrap">
		

<div class="navbar clearfix">
<ul class="navmenu openable">

<li><a id="ctl00_TopNavBar_Home" href="http://www.codeproject.com">home</a>


<li class="openable"><a id="ctl00_TopNavBar_Art" class="down selected" href="/script/Articles/Latest.aspx">articles</a>

	<ul>
		<li class="openable"><a id="ctl00_TopNavBar_ArtTopicList" class="fly" onmouseover="navBarMenu.ShowMap(this, &#39;ctl00_TopNavBar_MapFlyout&#39;);" href="/script/Content/SiteMap.aspx">Chapters and Sections<span class="has-submenu">&gt;</span></a><ul id="ctl00_TopNavBar_MapFlyout">
			<li>
				<div id="siteMap">
					<img src="/images/animated.gif" alt="loading" style="margin:150px;width:100px;height:100px;" />
				</div>
			</li>
			</ul>
		</li>
		<li><a id="ctl00_TopNavBar_ArtSearch" class="fly break" href="/search.aspx">Search</a></li>
		<li><a id="ctl00_TopNavBar_ArtLatestArts" class="fly" href="/script/Articles/Latest.aspx?at=1,3,7">Latest Articles</a></li>
		<li><a id="ctl00_TopNavBar_ArtLatestTips" class="fly" href="/script/Articles/Latest.aspx?at=6">Latest Tips/Tricks</a></li>
		<li><a id="ctl00_TopNavBar_ArtTop" class="fly" href="/script/Articles/TopArticles.aspx?ta_so=5">Top Articles</a></li>
		<li><a id="ctl00_TopNavBar_ArtBeginner" class="fly" href="/search.aspx?aidlst=152&amp;sa_us=True">Beginner Articles</a></li>
		<li><a id="ctl00_TopNavBar_ArtBlogArticles" class="fly break" href="/script/Articles/BlogArticleList.aspx">Technical Blogs</a></li>
		<li><a id="ctl00_TopNavBar_ArtGuide" class="fly" href="/info/Submit.aspx">Posting/Update Guidelines</a></li>
		<li><a id="ctl00_TopNavBar_ArtHelpForum" class="fly" href="/Forums/1641/Article-Writing.aspx">Article Help Forum</a></li>
		<li><a id="ctl00_TopNavBar_ArtCompetition" class="fly break" href="/script/Awards/CurrentCompetitions.aspx?cmpTpId=1">Article Competition</a></li>
		<li><a id="ctl00_TopNavBar_ArtPostArticle" class="fly highlight1" href="/script/Articles/Submit.aspx">
			<img src="/images/write-gr.png" width="19px" height="13px" /> Submit an article or tip
			</a></li>
		<li><a id="ctl00_TopNavBar_ArtPostBlog" class="fly highlight2" href="/script/Articles/BlogFeed.aspx">
			<img src="/images/write-or.png" width="19px" height="13px" /> Post your Blog
			</a></li>		<li class="last"></li>
	</ul>

</li>



<li class="openable"><a id="ctl00_TopNavBar_Answers" href="/script/Answers/List.aspx?tab=active">quick answers</a>
	<ul>
		<li id="ctl00_TopNavBar_AQL"><a id="ctl00_TopNavBar_ArticleQuestion" class="fly highlight1" href="#_comments">
			<img src="/images/write-gr.png" width="19px" height="13px" /> Ask a Question about this 
			article</a>
		</li>

		<li><a id="ctl00_TopNavBar_QAAsk" class="fly highlight2" href="/Questions/ask.aspx"><img 
			src="/images/write-or.png" width="19px" height="13px" /> Ask a Question</a></li>

		
		<li><a id="ctl00_TopNavBar_QAUnanswered" class="fly" href="/script/Answers/List.aspx?tab=unanswered">View Unanswered Questions</a></li>
		<li><a id="ctl00_TopNavBar_QALatest" class="fly" href="/script/Answers/List.aspx?tab=active">View All Questions...</a></li>
		
				<li><a id="ctl00_TopNavBar_QATR_ctl00_Tag" class="fly" href="/script/Answers/List.aspx?tab=active&amp;alltags=true&amp;tags=81" style="padding-left:30px">C# questions</a></li>
			
				<li><a id="ctl00_TopNavBar_QATR_ctl01_Tag" class="fly" href="/script/Answers/List.aspx?tab=active&amp;alltags=true&amp;tags=85" style="padding-left:30px">ASP.NET questions</a></li>
			
				<li><a id="ctl00_TopNavBar_QATR_ctl02_Tag" class="fly" href="/script/Answers/List.aspx?tab=active&amp;alltags=true&amp;tags=842" style="padding-left:30px">VB.NET questions</a></li>
			
				<li><a id="ctl00_TopNavBar_QATR_ctl03_Tag" class="fly" href="/script/Answers/List.aspx?tab=active&amp;alltags=true&amp;tags=308" style="padding-left:30px">C#4.0 questions</a></li>
			
				<li><a id="ctl00_TopNavBar_QATR_ctl04_Tag" class="fly" href="/script/Answers/List.aspx?tab=active&amp;alltags=true&amp;tags=78" style="padding-left:30px">C++ questions</a></li>
			
		<li class="last"></li>
	</ul>

</li>



<li class="openable"><a id="ctl00_TopNavBar_Forums" href="/script/Forums/List.aspx">discussions</a>

	<ul>
		<li><a id="ctl00_TopNavBar_MessageBoardsAll" class="fly" href="/script/Forums/List.aspx">All Message Boards...</a></li>
		<li class="openable"><a class="fly" style="padding-left:30px" href="/Forums/1580997/Application-Lifecycle.aspx">Application Lifecycle<span class="has-submenu">&gt;</span></a>
<ul class="openable"><li><a class="fly" href="/Forums/1533717/Running-a-Business.aspx">Running a Business</a></li>
<li><a class="fly" href="/Forums/1533716/Sales-Marketing.aspx">Sales / Marketing</a></li>
<li><a class="fly" href="/Forums/1651/Collaboration-Beta-Testing.aspx">Collaboration / Beta Testing</a></li>
<li><a class="fly" href="/Forums/3304/Work-Training-Issues.aspx">Work &amp; Training Issues</a></li>
</ul></li>
<li><a class="fly" style="padding-left:30px" href="/Forums/369270/Design-and-Architecture.aspx">Design and Architecture</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/12076/ASP-NET.aspx">ASP.NET</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1580226/JavaScript.aspx">JavaScript</a>
</li>
<li class="openable"><a class="fly" style="padding-left:30px" href="/Forums/1647/C-Cplusplus-MFC.aspx">C / C++ / MFC<span class="has-submenu">&gt;</span></a>
<ul class="openable"><li><a class="fly" href="/Forums/4486/ATL-WTL-STL.aspx">ATL /  WTL / STL</a></li>
<li><a class="fly" href="/Forums/3785/Managed-Cplusplus-CLI.aspx">Managed C++/CLI</a></li>
</ul></li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1827459/Adobe-Technologies.aspx">Adobe Technologies</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1649/Csharp.aspx">C#</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1627782/Free-Tools.aspx">Free Tools</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1827460/Objective-C.aspx">Objective-C</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1832431/Ruby-On-Rails.aspx">Ruby On Rails</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1725/Database.aspx">Database</a>
</li>
<li class="openable"><a class="fly" style="padding-left:30px" href="/Forums/186301/Hardware-Devices.aspx">Hardware &amp; Devices<span class="has-submenu">&gt;</span></a>
<ul class="openable"><li><a class="fly" href="/Forums/1644/System-Admin.aspx">System Admin</a></li>
</ul></li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1606152/Hosting-and-Servers.aspx">Hosting and Servers</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1643/Java.aspx">Java</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1650/NET-Framework.aspx">.NET Framework</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/13695/Mobile.aspx">Mobile</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1653293/VS-2012-2013-NET-4-5-1.aspx">VS 2012/2013 &amp; .NET 4.5.1</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1540733/Sharepoint.aspx">Sharepoint</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1004257/Silverlight-WPF.aspx">Silverlight / WPF</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1646/Visual-Basic.aspx">Visual Basic</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1640/Web-Development.aspx">Web Development</a>
</li>
<li><a class="fly" style="padding-left:30px" href="/Forums/1645/Site-Bugs-Suggestions.aspx">Site Bugs / Suggestions</a>
</li>

		<li class="last"></li>
	</ul>

</li>




<li class="openable"><a id="ctl00_TopNavBar_Features" href="/Feature/">features</a>

	<ul>
		<li><a id="ctl00_TopNavBar_CPTV" class="fly highlight1" href="http://CodeProject.TV">
			<img src="/images/CPTV-24.png" width="24px" height="24px" alt="CP.TV" style="vertical-align:text-bottom"/>
				CodeProject.TV</a></li>
		<li><a id="ctl00_TopNavBar_Catalog" class="fly" href="/script/Catalog/List.aspx">Component & Service Catalog</a></li>
		<li><a id="ctl00_TopNavBar_Comps" class="fly" href="/script/Awards/CurrentCompetitions.aspx?cmpTpId=1&amp;awsac=true">Competitions</a></li>
		<li><a id="ctl00_TopNavBar_News" class="fly" href="/script/News/List.aspx">News</a></li>
		<li><a id="ctl00_TopNavBar_Insider" class="fly" href="/Feature/Insider/">The Insider Newsletter</a></li>
		<li><a id="ctl00_TopNavBar_Newsletters" class="fly" href="/script/Mailouts/Archive.aspx?mtpid=1">Newsletter archive</a></li>
		<li><a id="ctl00_TopNavBar_Surveys" class="fly" href="/script/Surveys/List.aspx">Surveys</a></li>
		<li><a id="ctl00_TopNavBar_Showcase" class="fly" href="/KB/showcase/">Product Showcase</a></li>
		<li><a id="ctl00_TopNavBar_Research" class="fly" href="/script/ResearchLibrary/Index.aspx">Research Library</a></li>

		
		<li><a id="ctl00_TopNavBar_Stuff" class="fly" href="/Info/Stuff.aspx">CodeProject Stuff</a></li>
		<li class="last"></li>
	</ul>

</li>


<li  class="openable"><a id="ctl00_TopNavBar_Lounge" href="/Lounge.aspx">community</a>

	<ul>
		<li><a id="ctl00_TopNavBar_InsiderLnk" class="fly" href="/insider.aspx/cdn1.developermedia.com/cdn1.developermedia.com/cdn2.developermedia.com/cdn1.developermedia.com/cdn2.developermedia.com/a.min.js">The Insider News</a></li>
		<li><a id="ctl00_TopNavBar_LoungeLnk" class="fly" href="/Lounge.aspx">The Lounge  </a></li>
		<li><a id="ctl00_TopNavBar_WeirdWonderful" class="fly" href="/Feature/WeirdAndWonderful.aspx">The Weird & The Wonderful</a></li>
		<li><a id="ctl00_TopNavBar_SoapBoxLnk" class="fly" href="/Forums/1536756/The-Soapbox.aspx">The Soapbox</a></li>
		<li><a id="ctl00_TopNavBar_PRLnk" class="fly break" href="/Forums/1738007/Press-Releases.aspx">Press Releases</a></li>
		<li><a id="ctl00_TopNavBar_WhosWho" class="fly" href="/script/Membership/Profiles.aspx">Who's Who</a></li>
		<li><a id="ctl00_TopNavBar_MVPs" class="fly" href="/script/Awards/MVPWinners.aspx">Most Valuable Professionals</a></li>
		<li><a id="ctl00_TopNavBar_Companies" class="fly break" href="/script/Membership/Profiles.aspx?mgtid=1&amp;mgm=True">Company Listings</a></li>

		
		<li class="openable"><a class="fly" href="/Forums/1580229/Hindi.aspx">Non-English Language
			<span class="has-submenu">&gt;</span></a>
		<ul>
		<li><a class="fly" href="/Forums/1580229/Hindi.aspx">General Indian Topics</a></li>
		<li><a class="fly" href="/Forums/1580230/Chinese.aspx">General Chinese Topics</a></li>
		</ul>
		<li class="last"></li>
		
	</ul>

</li>


<li class="openable" style="margin-left:20px"><a id="ctl00_TopNavBar_Help" href="/KB/FAQs/">help</a>

	<ul>
		<li><a id="ctl00_TopNavBar_HelpWhatIs" class="fly" href="/info/guide.aspx">What is 'CodeProject'?</a></li>
		<li><a id="ctl00_TopNavBar_HelpGeneral" class="fly break" href="/KB/FAQs/">General FAQ</a></li>
		<li><a id="ctl00_TopNavBar_HelpPostQuestion" class="fly break highlight1" href="/Questions/ask.aspx">Ask a Question</a></li>
		<li><a id="ctl00_TopNavBar_HelpBugs" class="fly" href="/Forums/1645/Site-Bugs-Suggestions.aspx">Bugs and Suggestions</a></li>
		<li><a id="ctl00_TopNavBar_HelpArticles" class="fly" href="/Forums/1641/Article-Writing.aspx">Article Help Forum</a></li>
		<li><a id="ctl00_TopNavBar_HelpSiteMap" class="fly" href="/script/Content/SiteMap.aspx">Site Map</a></li>
		<li><a id="ctl00_TopNavBar_HelpAdvertise" class="fly" href="http://developermedia.com/">Advertise with us</a></li>
		<li><a id="ctl00_TopNavBar_HelpJobs" class="fly" href="/info/Jobs/">Employment Opportunities</a></li>
		<li><a id="ctl00_TopNavBar_HelpAboutUs" class="fly" href="/info/about.aspx">About Us</a></li>
		<li class="last"></li>
	</ul>

</li>

</ul>

</div>
	</td><td align="right">
		

<div class="searchbar">

<form method="get" action="/search.aspx" name="Search" class="tight">


<table border="0" cellspacing="0" cellpadding="0" class="search"><tr><td><input TabIndex="2" class="search " id="sb_tb" value="" name="q" /></td><td><input type="image" src="/images/search.gif" /></td></tr></table>

<div class="hover-container">
	<div id="SearchFilter" class="search-advanced popup small-text align-left">
	<b>Search within:<br /></b>
		
		<input type="radio" id="sb_kw" name="sbo" value="kw" checked="true"><label for="sb_kw">Articles</label><br>
<input type="radio" id="sb_vkw" name="sbo" value="vkw"><label for="sb_vkw">Videos</label><br>
<input type="radio" id="sb_qa" name="sbo" value="qa"><label for="sb_qa">Quick Answers</label><br>
<input type="radio" id="sb_fm" name="sbo" value="fm"><label for="sb_fm">Messages</label><br>
<input type="radio" id="sb_ctlk" name="sbo" value="ctlk"><label for="sb_ctlk">Product Catalog</label><br>


		
		
	</div>
</div>
</form>

</div>
	</td></tr></table>
	<div class="sub-headerbar-divider"></div>
	</div>
	

	<div id="A" class="container-content-wrap fixed"> 

	<div itemscope itemtype="http://schema.org/Article" class="container-content"> 

		<div class="clearfix">
			<div class="float-left container-breadcrumb">
				<div><a href="/script/Content/SiteMap.aspx">Articles</a> &#187; <a href="/Chapters/8/Platforms-Frameworks-Libraries.aspx">Platforms, Frameworks & Libraries</a> &#187; <a href="/KB/library/"><span itemprop="articleSection">Libraries</span></a> &#187; <a href="/KB/library/#General">General</a></div>
			</div>

			<div class="align-left float-right padded-top">
				


 
&nbsp;










			</div>

			<div class="float-right container-breadcrumb article-nav">
				
<div class="">


<a id="ctl00_PrevNext_NextLink" title="Next" href="/script/Articles/PrevNextLookup.aspx?aid=16650&amp;at=1&amp;secId=119" style="margin-left:5px">Next</a>
<img id="ctl00_PrevNext_NextImg" title="Next" rel="nofollow" src="/Images/arrow-right.png" style="border-width:0px;vertical-align:bottom;" />
</div>
			</div>

			<div class="align-right float-left">
				
			</div>
		</div>

		<table class="extended container-article-parts" cellpadding="0" cellspacing="0"><tr valign="top">
		<td>

			<div id="ctl00_Nav" class="container-article-tabs">
				<div class="tabs">
					

<div class="">
	<div class="selected">Article</div><div class="unselected"><a href="/script/Articles/ViewDownloads.aspx?aid=16650">Browse Code</a></div><div class="unselected"><a href="/script/Articles/Statistics.aspx?aid=16650">Stats</a></div><div class="unselected"><a href="/script/Articles/ListVersions.aspx?aid=16650">Revisions</a></div><div class="unselected"><a href="/script/Articles/ListAlternatives.aspx?aid=16650">Alternatives</a></div>
</div>	


					<!-- anchorLink used to auto-link to comments at end of article -->
					<div class="unselected"><a href="../../MasterPages/#_comments" id="ctl00_CommentLink" class="anchorLink">Comments &amp; 
						Discussions <span id="ctl00_CmtCnt">(202)</span></a>
					</div>
				</div>

				<a id="ctl00_AddAlternative" title="Write a related article about upgrades or translate this into a different language." class="add-item" href="/script/Articles/SubmissionWizard.aspx?at=1&amp;apid=16650">Add your own<br />alternative version</a>
			</div>

		</td>
		<td>
			
			<div id="AT" class="container-article  fixed"> 
				<div class="article">

					
					 
					<div class="header">

					<a name="Main"></a>

					
					<a name="_articleTop" id="_articleTop"></a>
					<div class="title">
					
					
					<h1 id="ctl00_ArticleTitle" itemprop="name">Neural Network for Recognition of Handwritten Digits</h1> 
					</div>

					
					<div class="entry">
						By <span class="author"><a href="/script/Membership/View.aspx?mid=208786" rel="author"><span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Mike O'Neill</span></span></a></span>, 
						<span class="date" itemprop="dateModified" content="2006-12-05 14:38:00">
							5 Dec 2006</span>
			
									
					</div>

					
					<!-- Tables. Yes. I'm weak -->
					<table class="container-rating"><tr><td>
						<div id="ctl00_CurRat" class="tooltip anchorLink" style="cursor:pointer" onclick="scrollToAnchor(&#39;#_rating&#39;);" name="CurRat_16650">
				
							

<table cellpadding="0" cellspacing="0" class="small-text" itemprop="aggregateRating" itemscope itemtype="http://schema.org/AggregateRating"> 
<tr>
	
	<td class="nowrap">

		
			<meta itemprop="bestRating" content="5"> 
			<meta itemprop="worstRating" content="1">
		

		<span id="ctl00_ArticleRating_VI">
		<div class="nowrap rating-stars-large" style="height:19px;width:139px;position:relative;">
	<div class="clipped align-left float-left" style="height:19px;width:138px;">
		<img src="/script/Ratings/Images/stars-fill-lg.png" style="border-width:0px;" />
	</div><div class="clipped" style="height:19px;width:1px;position:relative;">
		<img src="/script/Ratings/Images/stars-empty-lg.png" style="border-width:0px;position:absolute;top:0;right:0;" />
	</div>
</div>
		</span>

		
	</td>
	
	<td id="ctl00_ArticleRating_VR" class="nowrap">
		&nbsp;
		<span id="ctl00_ArticleRating_VotesR">&nbsp;<span itemprop="ratingValue" class="rating">4.97</span> (<span itemprop="ratingCount" class="count">163</span> votes)</span>
		
	</td>

</tr>

</table>


							<div id="ctl00_RB" class="speech-bubble-container-up">
								<div class="speech-bubble-up" style="width:150px !important">
									            
<div>
<table class="feature" width="100%" height="50px" title="Voting Distribution. Recent data only" cellpadding="0" cellspacing="0"><tr class="chart-row"><td class="chart-column rating-ignore-vote" title="Outside deviation limits - not included in score."><img src="/script/Ratings/Images/pollcol.gif" width="20pxpx" height="1px" border="0px" alt="3 votes, 1.9%" title="3 votes, 1.9%" /><br /><span title="3 votes">1</span></td>
<td class="chart-column rating-ignore-vote" title="Outside deviation limits - not included in score."><img src="/Images/t.gif" width="20pxpx" height="1px" border="0px" alt="" title="" /><br /><span title="0 votes">2</span></td>
<td class="chart-column rating-ignore-vote" title="Outside deviation limits - not included in score."><img src="/Images/t.gif" width="20pxpx" height="1px" border="0px" alt="" title="" /><br /><span title="0 votes">3</span></td>
<td class="chart-column"><img src="/script/Ratings/Images/pollcol.gif" width="20pxpx" height="1px" border="0px" alt="4 votes, 2.5%" title="4 votes, 2.5%" /><br /><span title="4 votes">4</span></td>
<td class="chart-column"><img src="/script/Ratings/Images/pollcol.gif" width="20pxpx" height="50px" border="0px" alt="154 votes, 95.7%" title="154 votes, 95.7%" /><br /><span title="154 votes">5</span></td>
</tr></table><div class="small-text align-center">4.97/5 - 163 votes</div><div class="small-text align-center subdue">3 removed</div><div class="small-text align-center subdue">μ 4.94, σ<sub>a</sub> 0.99 [<a href="/KB/FAQs/RatingReputationFAQ.aspx#noisefilter">?</a>]</div>
</div>
								</div>
								<div class="speech-bubble-pointer-up">
									<div class="speech-bubble-pointer-up-inner"></div>
								</div>
							</div>
						</div>
					</td>
					<td>
						&nbsp;
						
					</td></tr></table>

					</div>
					
					

					
					<div class="prize-winner">
<div><img id="ctl00_ArticleAwards_AR_ctl01_AI" src="/images/award24.gif" align="absmiddle" style="border-width:0px;" /> Prize winner in Competition 
"MFC/C++ Nov 2006" <i></i></div>
</div>

					
					
					

						
					

					<div id="ctl00_confirmError" class="advise"><img 
						style="float:left;margin-right:10px" src="/images/warning48.png" width="48px" 
						height="48px" /><b>Is your email address OK?</b> You are signed up for our 
						newsletters but your email address is either unconfirmed, or has not been 
						reconfirmed in a long time. Please click <a id="ctl00_RequestConfirmLink2" href="/script/Membership/SendConfirmRequest.aspx?rp=%2fArticles%2f16650%2fNeural-Network-for-Recognition-of-Handwritten-Digi">here</a> to have a confirmation email sent 
						so we can confirm your email address and start sending you newsletters 
						again. Alternatively, you can 
						<a id="ctl00_SubscribeLink2" href="/script/Membership/Subscribe.aspx?rp=%2fArticles%2f16650%2fNeural-Network-for-Recognition-of-Handwritten-Digi">update your subscriptions</a>.</div><form name="aspnetForm" method="post" action="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi" id="aspnetForm" style="margin:0;padding:0">
<div>
<input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE" value="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" />
</div>

<div>

	<input type="hidden" name="__EVENTVALIDATION" id="__EVENTVALIDATION" value="/wEWCALNgo+vCwLAlMXDBwLBlMXDBwLClMXDBwLDlMXDBwLElMXDBwLP+++tCwK5upDkC+OMyFsNrfO0DyXzWZY73PRfx5Oe" />
</div>

							
							<div id="contentdiv" class="text" itemprop="articleBody">
							



<UL class=download>
<LI><A href="/KB/library/NeuralNetRecognition/Demo-Mnist.zip">Download the Neural Network demo project - 203 Kb</A> (includes a release-build executable that you can run without the need to compile) 
<LI><A href="/KB/library/NeuralNetRecognition/simpleneutronweightfile.zip">Download a sample neuron weight file - 2,785 Kb</A> (achieves the 99.26% accuracy mentioned above) 
<LI><A href="http://yann.lecun.com/exdb/mnist/index.html" target=_blank>Download the MNIST database - 11,594 Kb total for all four files</A>&nbsp;(external link to four files which are all required for this project) </LI></UL>
<P><IMG height=372 alt="Graphical view of the neural network" src="/KB/library/NeuralNetRecognition/Screenshot-GraphicalView.gif" width=600 border=0></P><A name=topmost>
<H2>Contents</H2>
<UL type=disc>
<LI><A href="#Introduction">Introduction</A> 
<LI><A href="#Theory">Some Neural Network Theory</A> 
<UL type=disc>
<LI><A href="#ForwardPropagation">Forward Propagation</A> 
<LI><A href="#ActivationFunction">The Activation Function (or, "Sigmoid" or "Squashing" Function)</A> 
<LI><A href="#Backpropagation">Backpropagation</A> 
<LI><A href="#SecondOrder">Second Order Methods</A> </LI></UL>
<LI><A href="#ConvolutionalStructure">Structure of the Convolutional Neural Network</A> 
<UL type=disc>
<LI><A href="#Illustration">Illustration and General Description</A> 
<LI><A href="#CodeToBuild">Code For Building the Neural Network</A> </LI></UL>
<LI><A href="#AboutMNist">MNIST Database of Handwritten Digits</A> 
<LI><A href="#Architecture">Overall Architecture of the Test/Demo Program</A> 
<UL type=disc>
<LI><A href="#Using">Using the Demo Program</A> 
<LI><A href="#GraphicalView">Graphical View of the Neural Network</A> 
<LI><A href="#TrainingView">Training View and Control Over the Neural Network</A> 
<LI><A href="#TestingView">Testing View of the Neural Network</A> </LI></UL>
<LI><A href="#Training">Training the Neural Network</A> 
<LI><A href="#Tricks">Tricks That Make Training Faster</A> 
<UL type=disc>
<LI><A href="#Hessian">Second Order Backpropagation Using Pseudo-Hessian</A> 
<LI><A href="#SimultaneousBackprop">Simultaneous Backpropagation and Forward Propagation</A> 
<LI><A href="#SkipBackprop">Skip Backpropagation for Small Errors</A> </LI></UL>
<LI><A href="#Experiences">Experiences in Training the Neural Network</A> 
<LI><A href="#Results">Results</A> 
<LI><A href="#Bibliography">Bibliography</A> 
<LI><A href="#Version">License and Version Information</A> </LI></UL><A name=Introduction>
<H2>Introduction</H2></A>
<P>This article chronicles the development of an artificial neural network designed to recognize handwritten digits. Although some theory of neural networks is given here, it would be better if you already understood some neural network concepts, like neurons, layers, weights, and backpropagation.</P>
<P>The neural network described here is <I>not</I> a general-purpose neural network, and it's not some kind of a neural network workbench. Rather, we will focus on one very specific neural network (a five-layer convolutional neural network) built for one very specific purpose (to recognize handwritten digits).</P>
<P>The idea of using neural networks for the purpose of recognizing handwritten digits is not a new one. The inspiration for the architecture described here comes from articles written by two separate authors. The first is Dr. Yann LeCun, who was an independent discoverer of the basic backpropagation algorithm. Dr. LeCun hosts <A href="http://yann.lecun.com/" target=_blank>an excellent site on his research into neural networks</A>. In particular, you should view his <A href="http://yann.lecun.com/exdb/lenet/index.html" target=_newwin>"Learning and Visual Perception"</A> section, which uses animated GIFs to show results of his research. The MNIST database (which provides the database of handwritten digits) was developed by him. I used two of his publications as primary source materials for much of my work, and I highly recommend reading his other publications too (they're posted at his site). Unlike many other publications on neural networks, Dr. LeCun's publications are not inordinately theoretical and math-intensive; rather, they are extremely readable, and provide practical insights and explanations. His articles and publications can be found <A href="http://yann.lecun.com/exdb/publis/index.html" target=_newwin>here</A>. Here are the two publications that I relied on:</P>
<UL>
<LI>Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, <A href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target=_newwin>"Gradient-Based Learning Applied to Document Recognition,"&nbsp;</A>Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, Nov. 1998. [46 pages] 
<LI>Y. LeCun, L. Bottou, G. Orr, and K. Muller, <A href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target=_newwin>"Efficient BackProp,"&nbsp;</A>in Neural Networks: Tricks of the trade, (G. Orr and Muller K., eds.), 1998. [44 pages] </LI></UL>
<P>The second author is Dr. Patrice Simard, a former collaborator with Dr. LeCun when they both worked at AT&amp;T Laboratories. Dr. Simard is now a researcher at Microsoft's <A href="http://www.research.microsoft.com/dpu/" target=_newwin>"Document Processing and Understanding"</A> group. His articles and publications can be found <A href="http://research.microsoft.com/~patrice/publi.html" target=_newwin>here</A>, and the publication that I relied on is:</P>
<UL>
<LI>Patrice Y. Simard, Dave Steinkraus, John Platt, <A href="http://research.microsoft.com/~patrice/PDF/fugu9.pdf" target=_newwin>"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis,"&nbsp;<IMG height=14 alt="External Link" src="Images/ExternalLink.gif" width=14 border=0></A> International Conference on Document Analysis and Recognition (ICDAR), IEEE Computer Society, Los Alamitos, pp. 958-962, 2003. </LI></UL>
<P>One of my goals here was to reproduce the accuracy achieved by Dr. LeCun, who was able to train his neural network to achieve 99.18% accuracy (i.e., an error rate of only 0.82%). This error rate served as a type of "benchmark", guiding my work.</P>
<P>As a final introductory note, I'm not overly proud of the source code, which is most definitely an engineering work-in-progress. I started out with good intentions, to make source code that was flexible and easy to understand and to change. As things progressed, the code started to turn ugly. I began to write code simply to get the job done, sometimes at the expense of clean code and comprehensibility. To add to the mix, I was also experimenting with different ideas, some of which worked and some of which did not. As I removed the failed ideas, I did not always back out all the changes and there are therefore some dangling stubs and dead ends. I contemplated the possibility of not releasing the code. But that was one of my criticisms of the articles I read: none of them included code. So, with trepidation and the recognition that the code is easy to criticize and could really use a re-write, here it is.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Theory></A>
<H2>Some Neural Network Theory</H2>
<P>This is not a neural network tutorial, but to understand the code and the names of the variables used in it, it helps to see some neural networks basics. </P>
<P>The following discussion is not completely general. It considers only feed-forward neural networks, that is, neural networks composed of multiple layers, in which each layer of neurons feeds only the very next layer of neurons, and receives input only from the immediately preceding layer of neurons. In other words, the neurons don't skip layers.</P>
<P>Consider a neural network that is composed of multiple layers, with multiple neurons in each layer. Focus on one neuron in layer <I>n</I>, namely the <I>i-th</I> neuron. This neuron gets its inputs from the outputs of neurons in the previous layer, plus a bias whose valued is one ("1"). I use the variable "<I>x</I>" to refer to outputs of neurons. The <I>i-th</I> neuron applies a weight to each of its inputs, and then adds the weighted inputs together so as to obtain something called the "activation value". I use the variable "<I>y</I>" to refer to activation values. The <I>i-th</I> neuron then calculates its output value "<I>x</I>" by applying an "activation function" to the activation value. I use the letter "<I>F()</I>" to refer to the activation function. The activation function is sometimes referred to as a "Sigmoid" function, a "Squashing" function and other names, since its primary purpose is to limit the output of the neuron to some reasonable range like a range of -1 to +1, and thereby inject some degree of non-linearity into the network. Here's a diagram of a small part of the neural network; remember to focus on the <I>i-th</I> neuron in level <I>n</I>:</P>
<P><IMG height=543 alt="General diagram of a neuron in a neural network" src="/KB/library/NeuralNetRecognition/NeuralNetDiagram.gif" width=573 border=0> </P>
<P>This is what each variable means:</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=25 alt="Output of the i-th neuron in layer n" src="/KB/library/NeuralNetRecognition/xNI.gif" width=21 border=0></P></TD>
<TD>is the output of the <I>i</I>-th neuron in layer <I>n</I></TD></TR>
<TR>
<TD>
<P><IMG height=25 alt="Output of the j-th neuron in layer n-1" src="/KB/library/NeuralNetRecognition/xNm1J.gif" width=32 border=0></P></TD>
<TD>is the output of the <I>j</I>-th neuron in layer <I>n-1</I></TD></TR>
<TR>
<TD>
<P><IMG height=25 alt="Output of the k-th neuron in layer n-1" src="/KB/library/NeuralNetRecognition/xNm1K.gif" width=30 border=0></P></TD>
<TD>is the output of the <I>k</I>-th neuron in layer <I>n-1</I></TD></TR>
<TR>
<TD vAlign=top>
<P><IMG height=25 alt="Weight that the i-th neuron in layer n applies to the output of the j-th neuron from layer n-1" src="/KB/library/NeuralNetRecognition/wNIJ.gif" width=27 border=0></P></TD>
<TD>is the weight that the <I>i</I>-th neuron in layer <I>n</I> applies to the output of the <I>j</I>-th neuron from layer <I>n-1</I> (i.e., the previous layer). In other words, it's the weight from the output of the <I>j</I>-th neuron in the previous layer to the <I>i</I>-th neuron in the current (<I>n</I>-th) layer.</TD></TR>
<TR>
<TD>
<P><IMG height=25 alt="Weight that the i-th neuron in layer n applies to the output of the k-th neuron in layer n-1" src="/KB/library/NeuralNetRecognition/wNIK.gif" width=27 border=0></P></TD>
<TD>is the weight that the <I>i</I>-th neuron in layer <I>n</I> applies to the output of the <I>k</I>-th neuron in layer <I>n-1</I></TD></TR></TBODY></TABLE>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=53 alt="General feed-forward equation" src="/KB/library/NeuralNetRecognition/ForwardPropagationEquation.gif" width=227 border=0></P></TD>
<TD>is the general feed-forward equation, where <I>F()</I> is the activation function. We will discuss the activation function in more detail in a moment.</TD></TR></TBODY></TABLE>
<P>How does this translate into code and C++ classes? The way I saw it, the above diagram suggested that a neural network is composed of objects of four different classes: layers, neurons in the layers, connections from neurons in one layer to those in another layer, and weights that are applied to connections. Those four classes are reflected in the code, together with a fifth class -- the neural network itself -- which acts as a container for all other objects and which serves as the main interface with the outside world. Here's a simplified view of the classes. Note that the code makes heavy use of <CODE>std::vector</CODE>, particularly <CODE>std::vector&lt; <span class='cpp-keyword'>double</span> &gt;</CODE>:</P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified view: some members have been omitted,
</span><span class="code-comment">//</span><span class="code-comment"> and some signatures have been altered
</span>
<span class="code-comment">//</span><span class="code-comment"> helpful typedef's
</span>
typedef std::vector&lt; NNLayer* &gt;  VectorLayers;
typedef std::vector&lt; NNWeight* &gt;  VectorWeights;
typedef std::vector&lt; NNNeuron* &gt;  VectorNeurons;
typedef std::vector&lt; NNConnection &gt; VectorConnections;


<span class="code-comment">//</span><span class="code-comment"> Neural Network class
</span>
<span class="code-keyword">class</span> NeuralNetwork  
{
<span class="code-keyword">public</span>:
    NeuralNetwork();
    <span class="code-keyword">virtual</span> ~NeuralNetwork();
    
    <span class="code-keyword">void</span> Calculate( double* inputVector, UINT iCount, 
        double* outputVector = NULL, UINT oCount = <span class="code-digit">0</span> );

    <span class="code-keyword">void</span> Backpropagate( <span class="code-keyword">double</span> *actualOutput, 
         <span class="code-keyword">double</span> *desiredOutput, UINT count );

    VectorLayers m_Layers;
};


<span class="code-comment">//</span><span class="code-comment"> Layer class
</span>
<span class="code-keyword">class</span> NNLayer
{
<span class="code-keyword">public</span>:
    NNLayer( LPCTSTR str, NNLayer* pPrev = NULL );
    <span class="code-keyword">virtual</span> ~NNLayer();
    
    <span class="code-keyword">void</span> Calculate();
    
    <span class="code-keyword">void</span> Backpropagate( std::vector&lt; <span class="code-keyword">double</span> &gt;&amp; dErr_wrt_dXn <span class="code-comment">/*</span><span class="code-comment"> in */</span>, 
        std::vector&lt; <span class="code-keyword">double</span> &gt;&amp; dErr_wrt_dXnm1 <span class="code-comment">/*</span><span class="code-comment"> out */</span>, 
        <span class="code-keyword">double</span> etaLearningRate );

    NNLayer* m_pPrevLayer;
    VectorNeurons m_Neurons;
    VectorWeights m_Weights;
};


<span class="code-comment">//</span><span class="code-comment"> Neuron class
</span>
<span class="code-keyword">class</span> NNNeuron
{
<span class="code-keyword">public</span>:
    NNNeuron( LPCTSTR str );
    <span class="code-keyword">virtual</span> ~NNNeuron();

    <span class="code-keyword">void</span> AddConnection( UINT iNeuron, UINT iWeight );
    <span class="code-keyword">void</span> AddConnection( NNConnection <span class="code-keyword">const</span> &amp; conn );

    <span class="code-keyword">double</span> output;

    VectorConnections m_Connections;
};


<span class="code-comment">//</span><span class="code-comment"> Connection class
</span>
<span class="code-keyword">class</span> NNConnection
{
<span class="code-keyword">public</span>: 
    NNConnection(UINT neuron = ULONG_MAX, UINT weight = ULONG_MAX);
    <span class="code-keyword">virtual</span> ~NNConnection();

    UINT NeuronIndex;
    UINT WeightIndex;
};


<span class="code-comment">//</span><span class="code-comment"> Weight class
</span>
<span class="code-keyword">class</span> NNWeight
{
<span class="code-keyword">public</span>:
    NNWeight( LPCTSTR str, <span class="code-keyword">double</span> val = <span class="code-digit">0</span>.<span class="code-digit">0</span> );
    <span class="code-keyword">virtual</span> ~NNWeight();

    <span class="code-keyword">double</span> value;
};
</PRE>
<P>As you can see from the above, class <CODE>NeuralNetwork</CODE> stores a vector of pointers to layers in the neural network, which are represented by class <CODE>NNLayer</CODE>. There is no special function to add a layer (there probably should be one); simply use the <CODE>std::vector::push_back()</CODE> function. The <CODE>NeuralNetwork</CODE> class also provides the two primary interfaces with the outside world, namely, a function to forward propagate the neural network (the <CODE>Calculate()</CODE> function) and a function to <CODE>Backpropagate()</CODE> the neural network so as to train it.</P>
<P>Each <CODE>NNLayer</CODE> stores a pointer to the previous layer, so that it knows where to look for its input values. In addition, it stores a vector of pointers to the neurons in the layer, represented by class <CODE>NNNeuron</CODE>, and a vector of pointers to weights, represented by class <CODE>NNWeight</CODE>. Similar to the <CODE>NeuralNetwork</CODE> class, the pointers to the neurons and to the weights are added using the <CODE>std::vector::push_back()</CODE> function. Finally, the <CODE>NNLayer</CODE> class includes functions to <CODE>Calculate()</CODE> the output values of neurons in the layer, and to <CODE>Backpropagate()</CODE> them; in fact, the corresponding function in the <CODE>NeuralNetwork</CODE> class simply iterate through all layers in the network and call these functions.</P>
<P>Each <CODE>NNNeuron</CODE> stores a vector of connections that tell the neurons where to get its inputs. Connections are added using the <CODE>NNNeuron::AddConnection()</CODE> function, which takes an index to a neuron and an index to a weight, constructs a <CODE>NNConnection</CODE> object, and <CODE>push_back()</CODE>'s the new connection onto the vector of connections. Each neuron also stores its own output value, even though it's the <CODE>NNLayer</CODE> class that is responsible for calculating the actual value of the output and storing it there. The <CODE>NNConnection</CODE> and <CODE>NNWeight</CODE> classes respectively store obviously-labeled information.</P>
<P>One legitimate question about the class structure is, why are there separate classes for the weights and the connections? According to the diagram above, each connection has a weight, so why not put them in the same class? The answer lies in the fact that weights are often shared between connections. In fact, the convolutional neural network of this program specifically shares weights amongst its connections. So, for example, even though there might be several hundred neurons in a layer, there might only be a few dozen weights due to sharing. By making the <CODE>NNWeight</CODE> class separate from the <CODE>NNConnection</CODE> class, this sharing is more readily accomplished.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=ForwardPropagation></A>
<H3>Forward Propagation</H3>
<P>Forward propagation is the process whereby each of all of the neurons calculates its output value, based on inputs provided by the output values of the neurons that feed it.</P>
<P>In the code, the process is initiated by calling <CODE>NeuralNetwork::Calculate()</CODE>. <CODE>NeuralNetwork::Calculate()</CODE> directly sets the values of neurons in the input layer, and then iterates through the remaining layers, calling each layer's <CODE>NNLayer::Calculate()</CODE> function. This results in a forward propagation that's completely sequential, starting from neurons in the input layer and progressing through to the neurons in the output layer. A sequential calculation is not the only way to forward propagate, but it's the most straightforward. Here's simplified code, which takes a pointer to a C-style array of <CODE><span class='cpp-keyword'>double</span></CODE>s representing the input to the neural network, and stores the output of the neural network to another C-style array of <CODE><span class='cpp-keyword'>double</span></CODE>s:</P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified code
</span>
<span class="code-keyword">void</span> NeuralNetwork::Calculate(double* inputVector, UINT iCount, 
               double* outputVector <span class="code-comment">/*</span><span class="code-comment"> =NULL */</span>, 
               UINT oCount <span class="code-comment">/*</span><span class="code-comment"> =0 */</span>)
                              
{
    VectorLayers::iterator lit = m_Layers.begin();
    VectorNeurons::iterator nit;
    
    <span class="code-comment">//</span><span class="code-comment"> first layer is input layer: directly
</span>    <span class="code-comment">//</span><span class="code-comment"> set outputs of all of its neurons
</span>    <span class="code-comment">//</span><span class="code-comment"> to the given input vector
</span>    
    <span class="code-keyword">if</span> ( lit &lt; m_Layers.end() )  
    {
        nit = (*lit)-&gt;m_Neurons.begin();
        <span class="code-keyword">int</span> count = <span class="code-digit">0</span>;
        
        ASSERT( iCount == (*lit)-&gt;m_Neurons.size() );
        <span class="code-comment">//</span><span class="code-comment"> there should be exactly one neuron per input
</span>        
        <span class="code-keyword">while</span>( ( nit &lt; (*lit)-&gt;m_Neurons.end() ) &amp;&amp; ( count &lt; iCount ) )
        {
            (*nit)-&gt;output = inputVector[ count ];
            nit++;
            count++;
        }
    }
    
    <span class="code-comment">//</span><span class="code-comment"> iterate through remaining layers,
</span>    <span class="code-comment">//</span><span class="code-comment"> calling their Calculate() functions
</span>    
    <span class="code-keyword">for</span>( lit++; lit&lt;m_Layers.end(); lit++ )
    {
        (*lit)-&gt;Calculate();
    }
    
    <span class="code-comment">//</span><span class="code-comment"> load up output vector with results
</span>    
    <span class="code-keyword">if</span> ( outputVector != NULL )
    {
        lit = m_Layers.end();
        lit--;
        
        nit = (*lit)-&gt;m_Neurons.begin();
        
        <span class="code-keyword">for</span> ( <span class="code-keyword">int</span> ii=0; ii&lt;oCount; ++ii )
        {
            outputVector[ ii ] = (*nit)-&gt;output;
            nit++;
        }
    }
}
</PRE>
<P>Inside the layer's <CODE>Calculate()</CODE> function, the layer iterates through all neurons in the layer, and for each neuron the output is calculated according to the feed-forward formula given above, namely</P>
<P><IMG height=53 alt="General feed-forward equation" src="/KB/library/NeuralNetRecognition/ForwardPropagationEquation.gif" width=227 border=0></P>
<P>This formula is applied by iterating through all connections for the neuron, and for each connection, obtaining the corresponding weight and the corresponding output value from a neuron in the previous layer:</P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified code
</span>
<span class="code-keyword">void</span> NNLayer::Calculate()
{
    ASSERT( m_pPrevLayer != NULL );
    
    VectorNeurons::iterator nit;
    VectorConnections::iterator cit;
    
    <span class="code-keyword">double</span> dSum;
    
    <span class="code-keyword">for</span>( nit=m_Neurons.begin(); nit&lt;m_Neurons.end(); nit++ )
    {
        NNNeuron&amp; n = *(*nit);  <span class="code-comment">//</span><span class="code-comment"> to ease the terminology
</span>        
        cit = n.m_Connections.begin();
        
        ASSERT( (*cit).WeightIndex &lt; m_Weights.size() );
        
        <span class="code-comment">//</span><span class="code-comment"> weight of the first connection is the bias;
</span>        <span class="code-comment">//</span><span class="code-comment"> its neuron-index is ignored
</span>
        dSum = m_Weights[ (*cit).WeightIndex ]-&gt;value;  
        
        <span class="code-keyword">for</span> ( cit++ ; cit&lt;n.m_Connections.end(); cit++ )
        {
            ASSERT( (*cit).WeightIndex &lt; m_Weights.size() );
            ASSERT( (*cit).NeuronIndex &lt; 
                     m_pPrevLayer-&gt;m_Neurons.size() );
            
            dSum += ( m_Weights[ (*cit).WeightIndex ]-&gt;value ) * 
                ( m_pPrevLayer-&gt;m_Neurons[ 
                   (*cit).NeuronIndex ]-&gt;output );
        }
        
        n.output = SIGMOID( dSum );
        
    }
    
}</PRE>
<P>In this code, <CODE>SIGMOID</CODE> is <CODE><span class='cpp-preprocessor'>#define</span></CODE>d to the activation function, which is described in the next section. </P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=ActivationFunction></A>
<H3>The Activation Function (or, "Sigmoid" or "Squashing" Function)</H3>
<P>Selection of a good activation function is an important part of the design of a neural network. Generally speaking, the activation function should be symmetric, and the neural network should be trained to a value that is lower than the limits of the function.</P>
<P>One function that should <I><B>never</B></I> be used as the activation function is the classical sigmoid function (or "logistic" function), defined as <IMG height=42 alt="Logisitc function" src="/KB/library/NeuralNetRecognition/LogisticFunction.gif" width=110 align=middle border=0>. It should never be used since it is not symmetric: its value approaches +1 for increasing x, but for decreasing x its value approaches zero (i.e., it does not approach -1 which it should for symmetry). The reason the logistic function is even mentioned here is that there are many articles on the web that recommend its use in neural networks, for example, <A href="http://en.wikipedia.org/wiki/Sigmoid_function" target=_newwin>Sigmoid function</A> in the Wikipedia. In my view, this is a poor recommendation and should be avoided.</P>
<P>One good selection for the activation function is the hyperbolic tangent, or <IMG height=22 alt="Hyperbolic tangent" src="/KB/library/NeuralNetRecognition/HyperbolicTangent.gif" width=117 border=0>. This function is a good choice because it's completely symmetric, as shown in the following graph. If used, then do not train the neural network to ±1.0. Instead, choose an intermediate value, like ±0.8.</P>
<P><IMG height=220 alt="Graph of hyperbolic tangent" src="/KB/library/NeuralNetRecognition/HyperbolicTangentGraph.gif" width=327 border=0></P>
<P>Another reason why hyperbolic tangent is a good choice is that it's easy to obtain its derivative. Yes, sorry, but a bit of calculus is needed in neural networks. Not only is it easy to obtain its derivative, but also the value of derivative can be expressed in terms of the output value (i.e., as opposed to the input value). More specifically, given that:</P>
<P><IMG height=50 alt="Basic tanh function" src="/KB/library/NeuralNetRecognition/DerivativeEquation1.gif" width=219 align=center border=0>&nbsp;, where (using the notation established above) y is the input to the function (corresponding to the activation value of a neuron) and x is the output of the neuron.</P>
<P>Then <IMG height=55 alt="Derivative of tanh function" src="/KB/library/NeuralNetRecognition/DerivativeEquation2.gif" width=324 align=center border=0></P>
<P>Which simplifies to <IMG height=47 alt="Simplified derivative" src="/KB/library/NeuralNetRecognition/DerivativeEquation3.gif" width=140 align=center border=0> </P>
<P>Or, since <IMG height=21 alt="Given values" src="/KB/library/NeuralNetRecognition/DerivativeEquation4.gif" width=86 align=center border=0>, the result is <IMG height=47 alt=Result src="/KB/library/NeuralNetRecognition/DerivativeEquation5.gif" width=90 align=center border=0>. This result means that we can calculate the value of the derivative of <I>F()</I> given only the output of the function, without any knowledge of the input. In this article, we will refer to the derivative of the activation function as <I>G(x)</I>.</P>
<P>The activation function used in the code is a scaled version of the hyperbolic tangent. It was chosen based on a recommendation in one of Dr. LeCun's articles. Scaling causes the function to vary between ±1.7159, and permits us to train the network to values of ±1.0.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Backpropagation></A>
<H3>Backpropagation</H3>
<P>Backpropagation is an iterative process that starts with the last layer and moves backwards through the layers until the first layer is reached. Assume that for each layer, we know the error in the output of the layer. If we know the error of the output, then it is not hard to calculate changes for the weights, so as to reduce that error. The problem is that we can only observe the error in the output of the very last layer.</P>
<P>Backpropagation gives us a way to determine the error in the output of a prior layer given the output of a current layer. The process is therefore iterative: start at the last layer and calculate the change in the weights for the last layer. Then calculate the error in the output of the prior layer. Repeat.</P>
<P>The backpropagation equations are given below. My purpose in showing you the equations is so that you can find them in the code, and understand them. For example, the first equation shows how to calculate the partial derivative of the error <I>E<SUP>P</SUP></I> with respect to the activation value <I>y<SUP>i</SUP></I> at the <I>n-th</I> layer. In the code, you will see a variable named <CODE>dErr_wrt_dYn[ ii ]</CODE>.</P>
<P>Start the process off by computing the partial derivative of the error due to a single input image pattern with respect to the outputs of the neurons on the last layer. The error due to a single pattern is calculated as follows:</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=46 alt="Equation (1): Error due to a single pattern" src="/KB/library/NeuralNetRecognition/eqtn1-ErrNP.gif" width=157 border=0></P></TD>
<TD>(equation 1)</TD></TR></TBODY></TABLE>
<P>where:</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=25 alt="Error due to a single pattern P at the last layer n" src="/KB/library/NeuralNetRecognition/ErrNP.gif" width=25 border=0></P></TD>
<TD>is the error due to a single pattern <I>P</I> at the last layer <I>n</I>;</TD></TR>
<TR>
<TD>
<P><IMG height=25 alt="Target output at the last layer (i.e., the desired output at the last layer)" src="/KB/library/NeuralNetRecognition/TNI.gif" width=21 border=0></P></TD>
<TD>is the target output at the last layer (i.e., the desired output at the last layer); and</TD></TR>
<TR>
<TD>
<P><IMG height=25 alt="Actual value of the output at the last layer" src="/KB/library/NeuralNetRecognition/xNI.gif" width=21 border=0></P></TD>
<TD>is the actual value of the output at the last layer.</TD></TR></TBODY></TABLE>
<P>Given equation (1), then taking the partial derivative yields:</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=54 alt="Equation (2): Partial derivative of the output error for one pattern with respect to the neuron output values" src="/KB/library/NeuralNetRecognition/eqtn2-dErrNP-wrt-dxNI.gif" width=97 border=0></P></TD>
<TD>(equation 2)</TD></TR></TBODY></TABLE>
<P>Equation (2) gives us a starting value for the backpropagation process. We use the numeric values for the quantities on the right side of equation (2) in order to calculate numeric values for the derivative. Using the numeric values of the derivative, we calculate the numeric values for the changes in the weights, by applying the following two equations (3) and then (4):</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=57 alt="Equation (3): Partial derivative of the output error for one pattern with respect to the activation value of each neuron" src="/KB/library/NeuralNetRecognition/eqtn3-dErrNP-wrt-dyNI.gif" width=148 border=0></P></TD>
<TD>(equation 3)</TD></TR></TBODY></TABLE>
<TABLE>
<TBODY>
<TR>
<TD>where</TD>
<TD>
<P><IMG height=25 alt="Derivative of the activation function" src="/KB/library/NeuralNetRecognition/G-of-xNI.gif" width=48 border=0></P></TD>
<TD>is the derivative of the activation function.</TD></TR></TBODY></TABLE>
<TABLE>
<TBODY>
<TR>
<TD><IMG height=57 alt="Equation (4): Partial derivative of the output error for one pattern with respect to each weight feeding the neuron" src="/KB/library/NeuralNetRecognition/eqtn4-dErrNP-wrt-dWNij.gif" width=133 border=0></TD>
<TD>(equation 4)</TD></TR></TBODY></TABLE>
<P>Then, using equation (2) again and also equation (3), we calculate the error for the previous layer, using the following equation (5):</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=55 alt="Equation (5): Partial derivative of the error for the previous layer" src="/KB/library/NeuralNetRecognition/eqtn5-dErrNm1P-wrt-dxNm1K.gif" width=161 border=0></P></TD>
<TD>(equation 5)</TD></TR></TBODY></TABLE>
<P>The values we obtain from equation (5) are used as starting values for the calculations on the immediately preceding layer. <I><B>This is the single most important point in understanding backpropagation.</B></I> In other words, we take the numeric values obtained from equation (5), and use them in a repetition of equations (3), (4) and (5) for the immediately preceding layer.</P>
<P>Meanwhile, the values from equation (4) tell us how much to change the weights in the current layer n, which was the whole purpose of this gigantic exercise. In particular, we update the value of each weight according to the formula:</P>
<TABLE>
<TBODY>
<TR>
<TD>
<P><IMG height=55 alt="Equation (6): Updating the weights" src="/KB/library/NeuralNetRecognition/eqtn6-UpdateWeights.gif" width=245 border=0></P></TD>
<TD>(equation 6)</TD></TR></TBODY></TABLE>
<P>where <I>eta</I> is the "learning rate", typically a small number like 0.0005 that is gradually decreased during training.</P>
<P>In the code, these equations are implemented by calling <CODE>NeuralNetwork::Backpropagate()</CODE>. The input to the <CODE>NeuralNetwork::Backpropagate()</CODE> function is the actual output of the neural network and the desired output. Using these two inputs, the <CODE>NeuralNetwork::Backpropagate()</CODE> function calculates the value of equation (2). It then iterates through all layers in the network, starting from the last layer and proceeding backwards toward the first layer. For each layer, the layer's <CODE>NNLayer::Backpropagate()</CODE> function is called. The input to <CODE>NNLayer::Backpropagate()</CODE> is the derivative, and the output is equation (5). These derivatives are all stored in a <CODE>vector</CODE> of a <CODE>vector</CODE> of <CODE>doubles</CODE> named <CODE>differentials</CODE>. The output from one layer is then fed as the input to the next preceding layer:</P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified code
</span><span class="code-keyword">void</span> NeuralNetwork::Backpropagate(<span class="code-keyword">double</span> *actualOutput, 
     <span class="code-keyword">double</span> *desiredOutput, UINT count)
{
    <span class="code-comment">//</span><span class="code-comment"> Backpropagates through the neural net
</span>    <span class="code-comment">//</span><span class="code-comment"> Proceed from the last layer to the first, iteratively
</span>    <span class="code-comment">//</span><span class="code-comment"> We calculate the last layer separately, and first,
</span>    <span class="code-comment">//</span><span class="code-comment"> since it provides the needed derviative
</span>    <span class="code-comment">//</span><span class="code-comment"> (i.e., dErr_wrt_dXnm1) for the previous layers
</span>    
    <span class="code-comment">//</span><span class="code-comment"> nomenclature:
</span>    <span class="code-comment">//</span><span class="code-comment">
</span>    <span class="code-comment">//</span><span class="code-comment"> Err is output error of the entire neural net
</span>    <span class="code-comment">//</span><span class="code-comment"> Xn is the output vector on the n-th layer
</span>    <span class="code-comment">//</span><span class="code-comment"> Xnm1 is the output vector of the previous layer
</span>    <span class="code-comment">//</span><span class="code-comment"> Wn is the vector of weights of the n-th layer
</span>    <span class="code-comment">//</span><span class="code-comment"> Yn is the activation value of the n-th layer,
</span>    <span class="code-comment">//</span><span class="code-comment"> i.e., the weighted sum of inputs BEFORE 
</span>    <span class="code-comment">//</span><span class="code-comment">    the squashing function is applied
</span>    <span class="code-comment">//</span><span class="code-comment"> F is the squashing function: Xn = F(Yn)
</span>    <span class="code-comment">//</span><span class="code-comment"> F' is the derivative of the squashing function
</span>    <span class="code-comment">//</span><span class="code-comment">   Conveniently, for F = tanh,
</span>    <span class="code-comment">//</span><span class="code-comment">   then F'(Yn) = 1 - Xn^2, i.e., the derivative can be 
</span>    <span class="code-comment">//</span><span class="code-comment">   calculated from the output, without knowledge of the input
</span>    
    
    VectorLayers::iterator lit = m_Layers.end() - <span class="code-digit">1</span>;
    
    std::vector&lt; <span class="code-keyword">double</span> &gt; dErr_wrt_dXlast( (*lit)-&gt;m_Neurons.size() );
    std::vector&lt; std::vector&lt; <span class="code-keyword">double</span> &gt; &gt; differentials;
    
    <span class="code-keyword">int</span> iSize = m_Layers.size();
    
    differentials.resize( iSize );
    
    <span class="code-keyword">int</span> ii;
    
    <span class="code-comment">//</span><span class="code-comment"> start the process by calculating dErr_wrt_dXn for the last layer.
</span>    <span class="code-comment">//</span><span class="code-comment"> for the standard MSE Err function
</span>    <span class="code-comment">//</span><span class="code-comment"> (i.e., 0.5*sumof( (actual-target)^2 ), this differential is simply
</span>    <span class="code-comment">//</span><span class="code-comment"> the difference between the target and the actual
</span>    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;(*lit)-&gt;m_Neurons.size(); ++ii )
    {
        dErr_wrt_dXlast[ ii ] = 
            actualOutput[ ii ] - desiredOutput[ ii ];
    }
    
    
    <span class="code-comment">//</span><span class="code-comment"> store Xlast and reserve memory for
</span>    <span class="code-comment">//</span><span class="code-comment"> the remaining vectors stored in differentials
</span>    
    differentials[ iSize-1 ] = dErr_wrt_dXlast;  <span class="code-comment">//</span><span class="code-comment"> last one
</span>    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;iSize-1; ++ii )
    {
        differentials[ ii ].resize( 
             m_Layers[ii]-&gt;m_Neurons.size(), <span class="code-digit">0</span>.<span class="code-digit">0</span> );
    }
    
    <span class="code-comment">//</span><span class="code-comment"> now iterate through all layers including
</span>    <span class="code-comment">//</span><span class="code-comment"> the last but excluding the first, and ask each of
</span>    <span class="code-comment">//</span><span class="code-comment"> them to backpropagate error and adjust
</span>    <span class="code-comment">//</span><span class="code-comment"> their weights, and to return the differential
</span>    <span class="code-comment">//</span><span class="code-comment"> dErr_wrt_dXnm1 for use as the input value
</span>    <span class="code-comment">//</span><span class="code-comment"> of dErr_wrt_dXn for the next iterated layer
</span>    
    ii = iSize - <span class="code-digit">1</span>;
    <span class="code-keyword">for</span> ( lit; lit&gt;m_Layers.begin(); lit--)
    {
        (*lit)-&gt;Backpropagate( differentials[ ii ], 
              differentials[ ii - <span class="code-digit">1</span> ], m_etaLearningRate );
        --ii;
    }
    
    differentials.clear();
}
</PRE>
<P>Inside the <CODE>NNLayer::Backpropagate()</CODE> function, the layer implements equations (3) through (5) in order to determine the derivative for use by the next preceding layer. It then implements equation (6) in order to update the weights in its layer. In the following code, the derivative of the activation function <I>G(x)</I> is <CODE><span class='cpp-preprocessor'>#define</span></CODE>d as <CODE>DSIGMOID:</CODE></P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified code
</span>
<span class="code-keyword">void</span> NNLayer::Backpropagate( std::vector&lt; <span class="code-keyword">double</span> &gt;&amp; dErr_wrt_dXn <span class="code-comment">/*</span><span class="code-comment"> in */</span>, 
                            std::vector&lt; <span class="code-keyword">double</span> &gt;&amp; dErr_wrt_dXnm1 <span class="code-comment">/*</span><span class="code-comment"> out */</span>, 
                            <span class="code-keyword">double</span> etaLearningRate )
{
    <span class="code-keyword">double</span> output;

    <span class="code-comment">//</span><span class="code-comment"> calculate equation (3): dErr_wrt_dYn = F'(Yn) * dErr_wrt_Xn
</span>    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;m_Neurons.size(); ++ii )
    {
        output = m_Neurons[ ii ]-&gt;output;
    
        dErr_wrt_dYn[ ii ] = DSIGMOID( output ) * dErr_wrt_dXn[ ii ];
    }
    
    <span class="code-comment">//</span><span class="code-comment"> calculate equation (4): dErr_wrt_Wn = Xnm1 * dErr_wrt_Yn
</span>    <span class="code-comment">//</span><span class="code-comment"> For each neuron in this layer, go through
</span>    <span class="code-comment">//</span><span class="code-comment"> the list of connections from the prior layer, and
</span>    <span class="code-comment">//</span><span class="code-comment"> update the differential for the corresponding weight
</span>    
    ii = <span class="code-digit">0</span>;
    <span class="code-keyword">for</span> ( nit=m_Neurons.begin(); nit&lt;m_Neurons.end(); nit++ )
    {
        NNNeuron&amp; n = *(*nit);  <span class="code-comment">//</span><span class="code-comment"> for simplifying the terminology
</span>        
        <span class="code-keyword">for</span> ( cit=n.m_Connections.begin(); cit&lt;n.m_Connections.end(); cit++ )
        {
            kk = (*cit).NeuronIndex;
            <span class="code-keyword">if</span> ( kk == ULONG_MAX )
            {
                output = <span class="code-digit">1</span>.<span class="code-digit">0</span>;  <span class="code-comment">//</span><span class="code-comment"> this is the bias weight
</span>            }
            <span class="code-keyword">else</span>
            {
                output = m_pPrevLayer-&gt;m_Neurons[ kk ]-&gt;output;
            }
            
            dErr_wrt_dWn[ (*cit).WeightIndex ] += dErr_wrt_dYn[ ii ] * output;
        }
        
        ii++;
    }
    
    
    <span class="code-comment">//</span><span class="code-comment"> calculate equation (5): dErr_wrt_Xnm1 = Wn * dErr_wrt_dYn,
</span>    <span class="code-comment">//</span><span class="code-comment"> which is needed as the input value of
</span>    <span class="code-comment">//</span><span class="code-comment"> dErr_wrt_Xn for backpropagation of the next (i.e., previous) layer
</span>    <span class="code-comment">//</span><span class="code-comment"> For each neuron in this layer
</span>    
    ii = <span class="code-digit">0</span>;
    <span class="code-keyword">for</span> ( nit=m_Neurons.begin(); nit&lt;m_Neurons.end(); nit++ )
    {
        NNNeuron&amp; n = *(*nit);  <span class="code-comment">//</span><span class="code-comment"> for simplifying the terminology
</span>        
        <span class="code-keyword">for</span> ( cit=n.m_Connections.begin(); 
              cit&lt;n.m_Connections.end(); cit++ )
        {
            kk=(*cit).NeuronIndex;
            <span class="code-keyword">if</span> ( kk != ULONG_MAX )
            {
                <span class="code-comment">//</span><span class="code-comment"> we exclude ULONG_MAX, which signifies
</span>                <span class="code-comment">//</span><span class="code-comment"> the phantom bias neuron with
</span>                <span class="code-comment">//</span><span class="code-comment"> constant output of "1",
</span>                <span class="code-comment">//</span><span class="code-comment"> since we cannot train the bias neuron
</span>                
                nIndex = kk;
                
                dErr_wrt_dXnm1[ nIndex ] += dErr_wrt_dYn[ ii ] * 
                       m_Weights[ (*cit).WeightIndex ]-&gt;value;
            }
            
        }
        
        ii++;  <span class="code-comment">//</span><span class="code-comment"> ii tracks the neuron iterator
</span>        
    }
    
    
    <span class="code-comment">//</span><span class="code-comment"> calculate equation (6): update the weights
</span>    <span class="code-comment">//</span><span class="code-comment"> in this layer using dErr_wrt_dW (from 
</span>    <span class="code-comment">//</span><span class="code-comment"> equation (4)    and the learning rate eta
</span>
    <span class="code-keyword">for</span> ( jj=0; jj&lt;m_Weights.size(); ++jj )
    {
        oldValue = m_Weights[ jj ]-&gt;value;
        newValue = oldValue.dd - etaLearningRate * dErr_wrt_dWn[ jj ];
        m_Weights[ jj ]-&gt;value = newValue;
    }
}</PRE>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=SecondOrder>
<H3>Second Order Methods</H3></A>
<P>All second order techniques have one goal in mind: to increase the speed with which backpropagation converges to optimal weights. All second order techniques (at least in principle) accomplish this in the same fundamental way: by adjusting each weight differently, e.g., by applying a learning rate <I>eta</I> that differs for each individual weight.</P>
<P>In his <A href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target=_newwin>"Efficient BackProp,</A> article, Dr. LeCun proposes a second order technique that he calls the "stochastic diagonal Levenberg-Marquardt method". He compares the performance of this method with a "carefully tuned stochastic gradient algorithm", which is an algorithm that does not rely on second order techniques, but which does apply different learning rates to each individual weight. According to his comparisons, he concludes that "the additional cost <I>[of stochastic diagonal Levenberg-Marquardt]</I> over regular backpropagation is negligible and convergence is - as a rule of thumb - about three times faster than a carefully tuned stochastic gradient algorithm." (See page 35 of the article.)</P>
<P>It was clear to me that I needed a second order algorithm. Convergence without it was tediously slow. Dr. Simard, in his article titled <A href="http://research.microsoft.com/~patrice/PDF/fugu9.pdf" target=_newwin>"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis,"</A> indicated that he wanted to keep his algorithm as simple as possible and therefore did <I><B>not</B></I> use second order techniques. He also admitted that he required hundreds of epochs for convergence (my guess is that he required a few thousand).</P>
<P>With the MNIST database, each epoch requires 60,000 backpropagations, and on my computer each epoch took around 40 minutes. I did not have the patience (or confidence in the correctness of the code) to wait for thousands of epochs. It was also clear that, unlike Dr. LeCun, I did not have the skill to design "a carefully tuned stochastic gradient algorithm". So, in keeping with the advice that stochastic diagonal Levenberg-Marquardt would be around three times faster than that anyway, my neural network implements this second order technique.</P>
<P>I will not go into the math or the code for the stochastic diagonal Levenberg-Marquardt algorithm. It's actually not too dissimilar from standard backpropagation. Using this technique, I was able to achieve good convergence in around 20-25 epochs. In my mind this was terrific for two reasons. First, it increased my confidence that the network was performing correctly, since Dr. LeCun also reported convergence in around 20 epochs. Second, at 40 minutes per epoch, the network converged in around 14-16 hours, which is a palatable amount of time for an overnight run.</P>
<P>If you have the inclination to inspect the code on this point, the functions you want to focus on are named <CODE>CMNistDoc::CalculateHessian()</CODE> (which is in the document class - yes, the program is an MFC doc/view program), and <CODE>NeuralNetwork::BackpropagateSecondDervatives()</CODE>. In addition, you should note that the <CODE>NNWeight</CODE> class includes a <CODE><span class='cpp-keyword'>double</span></CODE> member that was not mentioned in the simplified view above. This member is named "<CODE>diagHessian</CODE>", and it stores the curvature (in weight space) that is calculated by Dr. LeCun's algorithm. Basically, when <CODE>CMNistDoc::CalculateHessian()</CODE> is called, 500 MNIST patterns are selected at random. For each pattern, the <CODE>NeuralNetwork::BackpropagateSecondDervatives()</CODE> function calculates the Hessian for each weight caused by the pattern, and this number is accumulated in <CODE>diagHessian</CODE>. After the 500 patterns are run, the value in <CODE>diagHessian</CODE> is divided by 500, which results in a unique value of <CODE>diagHessian</CODE> for each and every weight. During actual backpropagation, the <CODE>diagHessian</CODE> value is used to amplify the current learning rate <I>eta</I>, such that in highly curved areas in weight space, the learning rate is slowed, whereas in flat areas in weight space, the learning rate is amplified.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A> <A name=ConvolutionalStructure></A>
<H2>Structure of the Convolutional Neural Network</H2>
<P>As indicated above, the program does not implement a generalized neural network, and is not a neural network workbench. Rather, it is a very specific neural network, namely, a five-layer convolutional neural network. The input layer takes grayscale data of a 29x29 image of a handwritten digit, and the output layer is composed of ten neurons of which exactly one neuron has a value of +1 corresponding to the answer (hopefully) while all other nine neurons have an output of -1.</P>
<P>Convolutional neural networks are also known as "shared weight" neural networks. The idea is that a small kernel window is moved over neurons from a prior layer. In this network, I use a kernel sized to 5x5 elements. Each element in the 5x5 kernel window has a weight independent of that of another element, so there are 25 weights (plus one additional weight for the bias term). This kernel is shared across all elements in the prior layer, hence the name "shared weight". A more detailed explanation follows.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Illustration></A>
<H3>Illustration and General Description</H3>
<P>Here is an illustration of the neural network:</P>
<TABLE>
<TBODY>
<TR>
<TD width=599 colSpan=5>
<P><IMG height=300 alt="Illustration of the Neural Network" src="/KB/library/NeuralNetRecognition/IllustrationNeuralNet.gif" width=599 border=0></P></TD></TR>
<TR>
<TD align=middle width=229>Input Layer<BR>29x29</TD>
<TD align=middle width=140>Layer #1<BR>6 Feature Maps<BR>Each 13x13</TD>
<TD align=middle width=75>Layer #2<BR>50 Feature Maps<BR>Each 5x5</TD>
<TD align=middle width=75>Layer #3<BR>Fully Connected<BR>100 Neurons</TD>
<TD align=middle width=80>Layer #4<BR>Fully Connected<BR>10 Neurons</TD></TR></TBODY></TABLE>
<P>The input layer (Layer #0) is the grayscale image of the handwritten character. The MNIST image database has images whose size is 28x28 pixels each, but because of the considerations described by Dr. Simard in his article <A href="http://research.microsoft.com/~patrice/PDF/fugu9.pdf" target=_newwin>"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis,"</A> the image size is padded to 29x29 pixels. There are therefore 29x29 = 841 neurons in the input layer.</P>
<P>Layer #1 is a convolutional layer with six (6) feature maps. Each feature map is sized to 13x13 pixels/neurons. Each neuron in each feature map is a 5x5 convolutional kernel of the input layer, but every other pixel of the input layer is skipped (as described in Dr. Simard's article). As a consequence, there are 13 positions where the 5x5 kernel will fit in each row of the input layer (which is 29 neurons wide), and 13 positions where the 5x5 kernel will fit in each column of the input layer (which is 29 neurons high). There are therefore 13x13x6 = 1014 neurons in Layer #1, and (5x5+1)x6 = 156 weights. (The "+1" is for the bias.)</P>
<P>On the other hand, since each of the 1014 neurons has 26 connections, there are 1014x26 = 26364 connections from this Layer #1 to the prior layer. At this point, one of the benefits of a convolutional "shared weight" neural network should become more clear: because the weights are shared, even though there are 26364 connections, only 156 weights are needed to control those connections. As a consequence, only 156 weights need training. In comparison, a traditional "fully connected" neural network would have needed a unique weight for each connection, and would therefore have required training for 26364 different weights. None of that excess training is needed here.</P>
<P>Layer #2 is also a convolutional layer, but with 50 feature maps. Each feature map is 5x5, and each unit in the feature maps is a 5x5 convolutional kernel of corresponding areas of all 6 of the feature maps of the previous layers, each of which is a 13x13 feature map. There are therefore 5x5x50 = 1250 neurons in Layer #2, (5x5+1)x6x50 = 7800 weights, and 1250x26 = 32500 connections.</P>
<P>Before proceeding to Layer #3, it's worthwhile to mention a few points on the architecture of the neural network in general, and on Layer #2 in particular. As mentioned above, each feature map in Layer #2 is connected to all 6 of the feature maps of the previous layer. This was a design decision, but it's not the only decision possible. As far as I can tell, the design is the same as Dr. Simard's design. But it's distinctly different from Dr. LeCun's design. Dr. LeCun deliberately chose not to connect each feature map in Layer #2 to all of the feature maps in the previous layer. Instead, he connected each feature map in Layer #2 to only a few selected ones of the feature maps in the previous layer. Each feature map was, in addition, connected to a different combination of feature maps from the previous layer. As Dr. LeCun explained it, his non-complete connection scheme would force the feature maps to extract different and (hopefully) complementary information, by virtue of the fact that they are provided with different inputs. One way of thinking about this is to imagine that you are forcing information through fewer connections, which should result in the connections becoming more meaningful. I think Dr. LeCun's approach is correct. However, to avoid additional complications to programming that was already complicated enough, I chose the simpler approach of Dr. Simard.</P>
<P>Other than this, the architectures of all three networks (i.e., the one described here and those described by Drs. LeCun and Simard) are largely similar.</P>
<P>Turning to Layer #3, Layer #3 is a fully-connected layer with 100 units. Since it is fully-connected, each of the 100 neurons in the layer is connected to all 1250 neurons in the previous layer. There are therefore 100 neurons in Layer #3, 100*(1250+1) = 125100 weights, and 100x1251 = 125100 connections.</P>
<P>Layer #4 is the final, output layer. This layer is a fully-connected layer with 10 units. Since it is fully-connected, each of the 10 neurons in the layer is connected to all 100 neurons in the previous layer. There are therefore 10 neurons in Layer #4, 10x(100+1) = 1010 weights, and 10x101 = 1010 connections.</P>
<P>Like Layer #2, this output Layer #4 also warrants an architectural note. Here, Layer #4 is implemented as a standard, fully connected layer, which is the same as the implementation of Dr. Simard's network. Again, however, it's different from Dr. LeCun's implementation. Dr. LeCun implemented his output layer as a "radial basis function", which basically measures the Euclidean distance between the actual inputs and a desired input (i.e., a target input). This allowed Dr. LeCun to experiment in tuning his neural network so that the output of Layer #3 (the previous layer) matched idealized forms of handwritten digits. This was clever, and it also yields some very impressive graphics. For example, you can basically look at the outputs of his Layer #3 to determine whether the network is doing a good job at recognition. For my Layer #3 (and Dr. Simard's), the outputs of Layer #3 are meaningful only to the network; looking at them will tell you nothing. Nevertheless, the implementation of a standard, fully connected layer is far simpler than the implementation of radial basis functions, both for forward propagation and for training during backpropagation. I therefore chose the simpler approach.</P>
<P>Altogether, adding the above numbers, there are a total of 3215 neurons in the neural network, 134066 weights, and 184974 connections.</P>
<P>The object is to train all 134066 weights so that, for an arbitrary input of a handwritten digit at the input layer, there is exactly one neuron at the output layer whose value is +1 whereas all other nine (9) neurons at the output layer have a value of -1. Again, the benchmark was an error rate of 0.82% or better, corresponding to the results obtained by Dr. LeCun.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=CodeToBuild></A>
<H3>Code For Building the Neural Network</H3>
<P>The code for building the neural network is found in the <CODE>CMNistDoc::OnNewDocument()</CODE> function of the document class. Using the above illustration, together with its description, it should be possible to follow the code which is reproduced in simplified form below:</P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified code
</span>
BOOL CMNistDoc::OnNewDocument()
{
    <span class="code-keyword">if</span> (!COleDocument::OnNewDocument())
        <span class="code-keyword">return</span> FALSE;
    
    <span class="code-comment">//</span><span class="code-comment"> grab the mutex for the neural network
</span>    
    CAutoMutex tlo( m_utxNeuralNet );
    
    <span class="code-comment">//</span><span class="code-comment"> initialize and build the neural net
</span>    
    NeuralNetwork&amp; NN = m_NN;  <span class="code-comment">//</span><span class="code-comment"> for easier nomenclature
</span>    NN.Initialize();
    
    NNLayer* pLayer;
    
    <span class="code-keyword">int</span> ii, jj, kk;
    <span class="code-keyword">double</span> initWeight;
    
    <span class="code-comment">//</span><span class="code-comment"> layer zero, the input layer.
</span>    <span class="code-comment">//</span><span class="code-comment"> Create neurons: exactly the same number of neurons as the input
</span>    <span class="code-comment">//</span><span class="code-comment"> vector of 29x29=841 pixels, and no weights/connections
</span>    
    pLayer = <span class="code-keyword">new</span> NNLayer( _T(<span class="code-string">"</span><span class="code-string">Layer00"</span>) );
    NN.m_Layers.push_back( pLayer );
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">841</span>; ++ii )
    {
        pLayer-&gt;m_Neurons.push_back( <span class="code-keyword">new</span> NNNeuron() );
    }

    
    <span class="code-comment">//</span><span class="code-comment"> layer one:
</span>    <span class="code-comment">//</span><span class="code-comment"> This layer is a convolutional layer that
</span>    <span class="code-comment">//</span><span class="code-comment"> has 6 feature maps.  Each feature 
</span>    <span class="code-comment">//</span><span class="code-comment"> map is 13x13, and each unit in the
</span>    <span class="code-comment">//</span><span class="code-comment"> feature maps is a 5x5 convolutional kernel
</span>    <span class="code-comment">//</span><span class="code-comment"> of the input layer.
</span>    <span class="code-comment">//</span><span class="code-comment"> So, there are 13x13x6 = 1014 neurons, (5x5+1)x6 = 156 weights
</span>    
    pLayer = <span class="code-keyword">new</span> NNLayer( _T(<span class="code-string">"</span><span class="code-string">Layer01"</span>), pLayer );
    NN.m_Layers.push_back( pLayer );
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">1014</span>; ++ii )
    {
        pLayer-&gt;m_Neurons.push_back( <span class="code-keyword">new</span> NNNeuron() );
    }
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">156</span>; ++ii )
    {
        initWeight = <span class="code-digit">0</span>.<span class="code-digit">05</span> * UNIFORM_PLUS_MINUS_ONE;
        <span class="code-comment">//</span><span class="code-comment"> uniform random distribution
</span>
        pLayer-&gt;m_Weights.push_back( <span class="code-keyword">new</span> NNWeight( initWeight ) );
    }
    
    <span class="code-comment">//</span><span class="code-comment"> interconnections with previous layer: this is difficult
</span>    <span class="code-comment">//</span><span class="code-comment"> The previous layer is a top-down bitmap
</span>    <span class="code-comment">//</span><span class="code-comment"> image that has been padded to size 29x29
</span>    <span class="code-comment">//</span><span class="code-comment"> Each neuron in this layer is connected
</span>    <span class="code-comment">//</span><span class="code-comment"> to a 5x5 kernel in its feature map, which 
</span>    <span class="code-comment">//</span><span class="code-comment"> is also a top-down bitmap of size 13x13. 
</span>    <span class="code-comment">//</span><span class="code-comment"> We move the kernel by TWO pixels, i.e., we
</span>    <span class="code-comment">//</span><span class="code-comment"> skip every other pixel in the input image
</span>    
    <span class="code-keyword">int</span> kernelTemplate[<span class="code-digit">25</span>] = {
        <span class="code-digit">0</span>,  <span class="code-digit">1</span>,  <span class="code-digit">2</span>,  <span class="code-digit">3</span>,  <span class="code-digit">4</span>,
        <span class="code-digit">29</span>, <span class="code-digit">30</span>, <span class="code-digit">31</span>, <span class="code-digit">32</span>, <span class="code-digit">33</span>,
        <span class="code-digit">58</span>, <span class="code-digit">59</span>, <span class="code-digit">60</span>, <span class="code-digit">61</span>, <span class="code-digit">62</span>,
        <span class="code-digit">87</span>, <span class="code-digit">88</span>, <span class="code-digit">89</span>, <span class="code-digit">90</span>, <span class="code-digit">91</span>,
        <span class="code-digit">116</span>,<span class="code-digit">117</span>,<span class="code-digit">118</span>,<span class="code-digit">119</span>,<span class="code-digit">120</span> };
        
    <span class="code-keyword">int</span> iNumWeight;
        
    <span class="code-keyword">int</span> fm;  <span class="code-comment">//</span><span class="code-comment"> "fm" stands for "feature map"
</span>        
    <span class="code-keyword">for</span> ( fm=0; fm&lt;<span class="code-digit">6</span>; ++fm)
    {
        <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">13</span>; ++ii )
        {
            <span class="code-keyword">for</span> ( jj=0; jj&lt;<span class="code-digit">13</span>; ++jj )
            {
                <span class="code-comment">//</span><span class="code-comment"> 26 is the number of weights per feature map
</span>                iNumWeight = fm * <span class="code-digit">26</span>;
                NNNeuron&amp; n = 
                   *( pLayer-&gt;m_Neurons[ jj + ii*13 + fm*169 ] );
                
                n.AddConnection( ULONG_MAX, iNumWeight++ );  <span class="code-comment">//</span><span class="code-comment"> bias weight
</span>                
                <span class="code-keyword">for</span> ( kk=0; kk&lt;<span class="code-digit">25</span>; ++kk )
                {
                    <span class="code-comment">//</span><span class="code-comment"> note: max val of index == 840, 
</span>                    <span class="code-comment">//</span><span class="code-comment"> corresponding to 841 neurons in prev layer
</span>                    n.AddConnection( 2*jj + 58*ii + 
                        kernelTemplate[kk], iNumWeight++ );
                }
            }
        }
    }
    
    
    <span class="code-comment">//</span><span class="code-comment"> layer two:
</span>    <span class="code-comment">//</span><span class="code-comment"> This layer is a convolutional layer
</span>    <span class="code-comment">//</span><span class="code-comment"> that has 50 feature maps.  Each feature 
</span>    <span class="code-comment">//</span><span class="code-comment"> map is 5x5, and each unit in the feature
</span>    <span class="code-comment">//</span><span class="code-comment"> maps is a 5x5 convolutional kernel
</span>    <span class="code-comment">//</span><span class="code-comment"> of corresponding areas of all 6 of the
</span>    <span class="code-comment">//</span><span class="code-comment"> previous layers, each of which is a 13x13 feature map
</span>    <span class="code-comment">//</span><span class="code-comment"> So, there are 5x5x50 = 1250 neurons, (5x5+1)x6x50 = 7800 weights
</span>    
    pLayer = <span class="code-keyword">new</span> NNLayer( _T(<span class="code-string">"</span><span class="code-string">Layer02"</span>), pLayer );
    NN.m_Layers.push_back( pLayer );
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">1250</span>; ++ii )
    {
        pLayer-&gt;m_Neurons.push_back( 
                 <span class="code-keyword">new</span> NNNeuron( (LPCTSTR)label ) );
    }
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">7800</span>; ++ii )
    {
        initWeight = <span class="code-digit">0</span>.<span class="code-digit">05</span> * UNIFORM_PLUS_MINUS_ONE;
        pLayer-&gt;m_Weights.push_back( <span class="code-keyword">new</span> NNWeight( initWeight ) );
    }
    
    <span class="code-comment">//</span><span class="code-comment"> Interconnections with previous layer: this is difficult
</span>    <span class="code-comment">//</span><span class="code-comment"> Each feature map in the previous layer
</span>    <span class="code-comment">//</span><span class="code-comment"> is a top-down bitmap image whose size
</span>    <span class="code-comment">//</span><span class="code-comment"> is 13x13, and there are 6 such feature maps.
</span>    <span class="code-comment">//</span><span class="code-comment"> Each neuron in one 5x5 feature map of this 
</span>    <span class="code-comment">//</span><span class="code-comment"> layer is connected to a 5x5 kernel
</span>    <span class="code-comment">//</span><span class="code-comment"> positioned correspondingly in all 6 parent
</span>    <span class="code-comment">//</span><span class="code-comment"> feature maps, and there are individual
</span>    <span class="code-comment">//</span><span class="code-comment"> weights for the six different 5x5 kernels.  As
</span>    <span class="code-comment">//</span><span class="code-comment"> before, we move the kernel by TWO pixels, i.e., we
</span>    <span class="code-comment">//</span><span class="code-comment"> skip every other pixel in the input image.
</span>    <span class="code-comment">//</span><span class="code-comment"> The result is 50 different 5x5 top-down bitmap
</span>    <span class="code-comment">//</span><span class="code-comment"> feature maps
</span>    
    <span class="code-keyword">int</span> kernelTemplate2[<span class="code-digit">25</span>] = {
        <span class="code-digit">0</span>,  <span class="code-digit">1</span>,  <span class="code-digit">2</span>,  <span class="code-digit">3</span>,  <span class="code-digit">4</span>,
        <span class="code-digit">13</span>, <span class="code-digit">14</span>, <span class="code-digit">15</span>, <span class="code-digit">16</span>, <span class="code-digit">17</span>, 
        <span class="code-digit">26</span>, <span class="code-digit">27</span>, <span class="code-digit">28</span>, <span class="code-digit">29</span>, <span class="code-digit">30</span>,
        <span class="code-digit">39</span>, <span class="code-digit">40</span>, <span class="code-digit">41</span>, <span class="code-digit">42</span>, <span class="code-digit">43</span>, 
        <span class="code-digit">52</span>, <span class="code-digit">53</span>, <span class="code-digit">54</span>, <span class="code-digit">55</span>, <span class="code-digit">56</span>   };
        
        
    <span class="code-keyword">for</span> ( fm=0; fm&lt;<span class="code-digit">50</span>; ++fm)
    {
        <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">5</span>; ++ii )
        {
            <span class="code-keyword">for</span> ( jj=0; jj&lt;<span class="code-digit">5</span>; ++jj )
            {
                <span class="code-comment">//</span><span class="code-comment"> 26 is the number of weights per feature map
</span>                iNumWeight = fm * <span class="code-digit">26</span>;
                NNNeuron&amp; n = *( pLayer-&gt;m_Neurons[ jj + ii*5 + fm*25 ] );
                
                n.AddConnection( ULONG_MAX, iNumWeight++ );  <span class="code-comment">//</span><span class="code-comment"> bias weight
</span>                
                <span class="code-keyword">for</span> ( kk=0; kk&lt;<span class="code-digit">25</span>; ++kk )
                {
                    <span class="code-comment">//</span><span class="code-comment"> note: max val of index == 1013,
</span>                    <span class="code-comment">//</span><span class="code-comment"> corresponding to 1014 neurons in prev layer
</span>                    n.AddConnection(       2*jj + 26*ii + 
                     kernelTemplate2[kk], iNumWeight++ );
                    n.AddConnection( <span class="code-digit">169</span> + 2*jj + 26*ii + 
                     kernelTemplate2[kk], iNumWeight++ );
                    n.AddConnection( <span class="code-digit">338</span> + 2*jj + 26*ii + 
                     kernelTemplate2[kk], iNumWeight++ );
                    n.AddConnection( <span class="code-digit">507</span> + 2*jj + 26*ii + 
                     kernelTemplate2[kk], iNumWeight++ );
                    n.AddConnection( <span class="code-digit">676</span> + 2*jj + 26*ii + 
                     kernelTemplate2[kk], iNumWeight++ );
                    n.AddConnection( <span class="code-digit">845</span> + 2*jj + 26*ii + 
                     kernelTemplate2[kk], iNumWeight++ );
                }
            }
        }
    }
            
    
    <span class="code-comment">//</span><span class="code-comment"> layer three:
</span>    <span class="code-comment">//</span><span class="code-comment"> This layer is a fully-connected layer
</span>    <span class="code-comment">//</span><span class="code-comment"> with 100 units.  Since it is fully-connected,
</span>    <span class="code-comment">//</span><span class="code-comment"> each of the 100 neurons in the
</span>    <span class="code-comment">//</span><span class="code-comment"> layer is connected to all 1250 neurons in
</span>    <span class="code-comment">//</span><span class="code-comment"> the previous layer.
</span>    <span class="code-comment">//</span><span class="code-comment"> So, there are 100 neurons and 100*(1250+1)=125100 weights
</span>    
    pLayer = <span class="code-keyword">new</span> NNLayer( _T(<span class="code-string">"</span><span class="code-string">Layer03"</span>), pLayer );
    NN.m_Layers.push_back( pLayer );
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">100</span>; ++ii )
    {
        pLayer-&gt;m_Neurons.push_back( 
           <span class="code-keyword">new</span> NNNeuron( (LPCTSTR)label ) );
    }
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">125100</span>; ++ii )
    {
        initWeight = <span class="code-digit">0</span>.<span class="code-digit">05</span> * UNIFORM_PLUS_MINUS_ONE;
    }
    
    <span class="code-comment">//</span><span class="code-comment"> Interconnections with previous layer: fully-connected
</span>    
    iNumWeight = <span class="code-digit">0</span>;  <span class="code-comment">//</span><span class="code-comment"> weights are not shared in this layer
</span>    
    <span class="code-keyword">for</span> ( fm=0; fm&lt;<span class="code-digit">100</span>; ++fm )
    {
        NNNeuron&amp; n = *( pLayer-&gt;m_Neurons[ fm ] );
        n.AddConnection( ULONG_MAX, iNumWeight++ );  <span class="code-comment">//</span><span class="code-comment"> bias weight
</span>        
        <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">1250</span>; ++ii )
        {
            n.AddConnection( ii, iNumWeight++ );
        }
    }
    
    <span class="code-comment">//</span><span class="code-comment"> layer four, the final (output) layer:
</span>    <span class="code-comment">//</span><span class="code-comment"> This layer is a fully-connected layer
</span>    <span class="code-comment">//</span><span class="code-comment"> with 10 units.  Since it is fully-connected,
</span>    <span class="code-comment">//</span><span class="code-comment"> each of the 10 neurons in the layer
</span>    <span class="code-comment">//</span><span class="code-comment"> is connected to all 100 neurons in
</span>    <span class="code-comment">//</span><span class="code-comment"> the previous layer.
</span>    <span class="code-comment">//</span><span class="code-comment"> So, there are 10 neurons and 10*(100+1)=1010 weights
</span>    
    pLayer = <span class="code-keyword">new</span> NNLayer( _T(<span class="code-string">"</span><span class="code-string">Layer04"</span>), pLayer );
    NN.m_Layers.push_back( pLayer );
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">10</span>; ++ii )
    {
        pLayer-&gt;m_Neurons.push_back( 
              <span class="code-keyword">new</span> NNNeuron( (LPCTSTR)label ) );
    }
    
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">1010</span>; ++ii )
    {
        initWeight = <span class="code-digit">0</span>.<span class="code-digit">05</span> * UNIFORM_PLUS_MINUS_ONE;
    }
    
    <span class="code-comment">//</span><span class="code-comment"> Interconnections with previous layer: fully-connected
</span>    
    iNumWeight = <span class="code-digit">0</span>;  <span class="code-comment">//</span><span class="code-comment"> weights are not shared in this layer
</span>    
    <span class="code-keyword">for</span> ( fm=0; fm&lt;<span class="code-digit">10</span>; ++fm )
    {
        NNNeuron&amp; n = *( pLayer-&gt;m_Neurons[ fm ] );
        n.AddConnection( ULONG_MAX, iNumWeight++ );  <span class="code-comment">//</span><span class="code-comment"> bias weight
</span>        
        <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">100</span>; ++ii )
        {
            n.AddConnection( ii, iNumWeight++ );
        }
    }
    
    
    SetModifiedFlag( TRUE );
    
    <span class="code-keyword">return</span> TRUE;
}</PRE>
<P>This code builds the illustrated neural network in stages, one stage for each layer. In each stage, an <CODE>NNLayer</CODE> is <CODE><span class='cpp-keyword'>new</span></CODE>'d and then added to the <CODE>NeuralNetwork</CODE>'s vector of layers. The needed number of <CODE>NNNeuron</CODE>s and <CODE>NNWeight</CODE>s are <CODE><span class='cpp-keyword'>new</span></CODE>'d and then added respectively to the layer's vector of neurons and vector of weights. Finally, for each neuron in the layer, <CODE>NNConnection</CODE>s are added (using the <CODE>NNNeuron::AddConnection()</CODE> function), passing in appropriate indices for weights and neurons.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=AboutMNist></A>
<H2>MNIST Database of Handwritten Digits</H2>
<P>The MNIST database is modified (hence the "M") from a database of handwritten patterns offered by the <A href="http://www.nist.gov/srd/nistsd19.htm" target=_blank>National Institute of Standards and Technology ("NIST")</A>. As explained by Dr. LeCun at the <A href="http://yann.lecun.com/exdb/mnist/index.html" target=_newwin>MNIST section of his web site</A>, the database has been broken down into two distinct sets, a fist set of 60,000 images of handwritten digits that is used as a training set for the neural network, and a second set of 10,000 images that is used as a testing set. The training set is composed of digits written by around 250 different writers, of which approximately half are high school students and the other half are U.S. census workers. The number of writers in the testing set is unclear, but special precautions were made to ensure that all writers in the testing set were not also in the training set. This makes for a strong test, since the neural network is tested on images from writers that it has never before seen. It is thus a good test of the ability of the neural network to generalize, i.e., to extract intrinsically important features from the patterns in the training set that are also applicable to patterns that it has not seen before.</P>
<P>To use the neural network, you must download the MNIST database. Besides the two files that compose the patterns from the training and testing sets, there are also two companion files that give the "answers", i.e., the digit that is represented by a corresponding handwritten pattern. These two files are called "label" files. As indicated at the beginning of this article, the four files can be downloaded from <A href="http://yann.lecun.com/exdb/mnist/index.html" target=_blank>here (11,594 Kb total)</A>.</P>
<P>Incidentally, it's been mentioned that Dr. LeCun's achieval of an error rate of 0.82% has been used as a benchmark. If you read Dr. Simard's article, you will see that he claims an even better error rate of 0.40%. Why not use Dr. Simard's 0.40% as the benchmark?</P>
<P>The reason is that Dr. Simard did not respect the boundary between the training set and the testing set. In particular, he did not respect the fact that the writers in the training set were distinct from the writers in the testing set. In fact, Dr. Simard did not use the testing set at all. Instead, he trained with the first 50,000 patterns in the training set, and then tested with the remaining 10,000 patterns. This raises the possibility that, during testing, Dr. Simard's network was fed patterns from writers whose handwriting had already been seen before, which would give the network an unfair advantage. Dr. LeCun, on the other hand, took pains to ensure that his network was tested with patterns from writers it had never seen before. Thus, as compared with Dr. Simard's testing, Dr. LeCun's testing was more representative of real-world results since he did not give his network any unfair advantages. That's why I used Dr. LeCun's error rate of 0.82% as the benchmark.</P>
<P>Finally, you should note that the MNIST database is still widely used for study and testing, despite the fact that it was created back in 1998. As one recent example, published in February 2006, see:</P>
<UL>
<LI>Fabien Lauer, Ching Y. Suen and Gerard Bloch, <A href="http://hal.archives-ouvertes.fr/docs/00/05/75/61/PDF/LauerSuenBlochPR.pdf" target=_newwin>"A Trainable Feature Extractor for Handwritten Digit Recognition"</A>, Elsevier Science, February 2006 </LI></UL>
<P>In the Lauer et al. article, the authors used a convolutional neural network for everything except the actual classification/recognition step. Instead, they used the convolutional neural network for black-box extraction of feature vectors, which they then fed to a different type of classification engine, namely a support vector machine ("SVM") engine. With this architecture, they were able to obtain the excellent error rate of just 0.54%. Good stuff.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Architecture></A>
<H2>Overall Architecture of the Test/Demo Program</H2>
<P>The test program is an MFC SDI doc/view application, using worker threads for the various neural network tasks.</P>
<P>The document owns the neural network as a protected member variable. Weights for the neural network are saved to and loaded from an <CODE>.nnt</CODE> file in the <CODE>CMNistDoc::Serialize()</CODE> function. Storage/retrieval of the weights occurs in response to the menu items "<CODE>File-&gt;Open</CODE>" and "<CODE>File-&gt;Save</CODE>" or "<CODE>Save As</CODE>". For this purpose, the neural network also has a <CODE>Serialize()</CODE> function, which was not shown in the simplified code above, and it is the neural network that does the heavy lifting of storing its weights to a disk file, and extracting them later.</P>
<P>The document further holds two static functions that are used for the worker threads to run backpropagation and testing on the neural network. These functions are unimaginatively named <CODE>CMNistDoc::BackpropagationThread()</CODE> and <CODE>CMNistDoc::TestingThread()</CODE>. The functions are not called directly; instead, other classes that wish to begin a backpropagation or testing cycle ask the document to do so for them, by calling the document's <CODE>StartBackpropagation()</CODE> and <CODE>StartTesting()</CODE> functions. These functions accept parameters for the backpropagation or the testing, and then kick off the threads to do the work. Results are reported back to the class that requested the work using the API's <CODE>::PostMessage()</CODE> function with a user-defined message and user-defined codings of the <CODE>wParam</CODE> and <CODE>lParam</CODE> parameters.</P>
<P>Two helper classes are also defined in the document, named <CODE>CAutoCS</CODE> and <CODE>CAutoMutex</CODE>. These are responsible for automatic locking and release of critical sections and mutexes that are used for thread synchronization. Note that the neural network itself does not have a critical section. I felt that thread synchronization should be the responsibility of the owner of the neural network, and not the responsibility of the neural network, which is why the document holds these synchronization objects. The <CODE>CAutoCS</CODE> and <CODE>CAutoMutex</CODE> classes lock and release the synchronization objects through use of well-known RAII techniques ("resource acquisition is initialization").</P>
<P>The document further owns the MNIST database files, which are opened and closed in the <CODE>CMNistDoc::OnButtonOpenMnistFiles()</CODE> and <CODE>CMNistDoc::OnButtonCloseMnistFiles()</CODE> functions. These functions are button handlers for correspondingly-labeled buttons on the view. When opening the MNIST files, all four files must be opened, i.e., the pattern files for the training and testing sets, and the label files for the training and testing set. There are therefore four "<CODE>Open File</CODE>" dialogs, and prompts on the dialogs tell you which file should be opened next.</P>
<P>The view is based on <CODE>CFormView</CODE>, and holds a single tab control with three tabs, a first for a graphical view of the neural network and the outputs of each of its neurons, a second for backpropagation and training, and a third for testing. The view is resizable, using an excellent class named <CODE>DlgResizeHelper</CODE>, described at <A href="http://www.codeguru.com/Cpp/W-D/dislog/resizabledialogs/article.php/c1913/" target=_newwin>Dialog Resize Helper</A> by Stephan Keil.</P>
<P>Each tab on the tab control hosts a different <CODE>CDialog</CODE>-derived class. The first tab hosts a <CODE>CDlgCharacterImage</CODE> dialog which provides the graphical view of the neural network and the outputs of each neuron. The second tab hosts a <CODE>CDlgNeuralNet</CODE> dialog which provides control over training of the neural network, and which also gives feedback and progress during the training process (which can be lengthy). The third tab hosts a <CODE>CDlgTesting</CODE> dialog which provides control over testing and outputs test results. Each of these tabs/dialogs is described in more detail in the following sections.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Using></A>
<H3>Using The Demo Program</H3>
<P>To use the program, you must open <B><I>five</I></B> files: four files comprising the MNIST database, and one file comprising the weights for the neural network.</P>
<P>To open the MNIST database files, click the "Open MNist" button at the bottom of the screen. You will be prompted four successive times to open the four files comprising the MNIST database, namely, the training patterns, the label (i.e., the answers) for the training patterns, the testing patterns, and the labels for the testing patterns.</P>
<P>To open the weights for the neural network, from the main menu, choose File-&gt;Open, or choose the file-open icon from the toolbar. You will be prompted to open a <I>.nnt</I> file that contains the weights and the structure of the neural network.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=GraphicalView></A>
<H3>Graphical View of the Neural Network</H3>
<P>The graphical view of the neural network is the same as the screenshot at the top of this article, and it's repeated again here:</P><BR><IMG height=372 alt="Graphical view of the neural network" src="/KB/library/NeuralNetRecognition/Screenshot-GraphicalView.gif" width=600 border=0> 
<P>The window at the mid-right shows the output of <I><B>all</B></I> 3215 neurons. For each neuron, the output is represented as a single grayscale pixel whose gray level corresponds to the neuron's output: white equals a fully off neuron (value of -1) and black equals a fully on neuron (value of +1). The neurons are grouped into their layers. The input layer is the 29x29 pattern being recognized. Next are the six 13x13 feature maps of the second layer, followed in turn by the 50 5x5 feature maps of the third layer, the 100 neurons of the fourth layer (arranged in a column), and finally the 10 output neurons in the output layer.</P>
<P>Since individual pixels are hard to see clearly, a magnified view is provided. Simply move your mouse over the window, and a magnified window is displayed that lets you see each pixel's value clearly.</P>
<P>The display for the output layer is a bit different than for the other layers. Instead of a single pixel, the 10 output neurons are shown as a grayscale representation of the digit coded by that neuron. If the neuron is fully off (value of -1), the digit is shown as pure white, which of course means that it can't be seen against the white background. If the neuron is fully on (value of +1) then the digit is shown in pure black. In-between values are shown by varying degrees of grayness. In the screenshot above, the output of the neural network shows that it firmly believes that the pattern being recognized is an "8" (which is correct). But the dimly displayed "2" also shows that the neural network sees at least some similarity in the pattern to the digit "2". A red marker points to the most likely result.</P>
<P>The mid-left of the dialog shows the appearance of the pattern at a selectable index. Here the pattern's index is 1598 in the training set. Controls are arranged to allow fast sequencing through the patterns, and to allow selection of either the training set or the testing set. There is also a check box for distortion of the pattern. Distortion helps in training of the neural network, since it forces the network to extract the intrinsic shapes of the patterns, rather than allowing the network to (incorrectly) focus on peculiarities of individual patterns. This is discussed in greater detail below, but in essence, it helps the neural network to generalize. If you look carefully at the screenshot above, you will notice that the input pattern for the digit "8" (on the left) has been slightly distorted when it is given as the input layer to the neural network (on the right).</P>
<P>The "Calculate" button causes the neural network to forward propagate the pattern in the input layer and attempt a recognition of it. The actual numeric values of the output neurons are shown in the center, together with the time taken for the calculation. Although almost all other operations on the neural network are performed in a thread, for recognitions of single patterns, the time taken is so short (typically around 15 milliseconds) that the calculation is performed in the main UI thread.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=TrainingView></A>
<H3>Training View and Control Over the Neural Network</H3>
<P>Unless training is actually ongoing, the training view hides many of its controls. Training is started by clicking on the "Start Backpropagation" button, and during training, the training view looks like the following screenshot:</P>
<P><IMG height=370 alt="Training view of the neural network" src="/KB/library/NeuralNetRecognition/Screenshot-TrainingView.gif" width=600 border=0></P>
<P>During training, the 60,000 patterns in the training set are continuously processed (in a random sequence) by the backpropagation algorithm. Each pass through the 60,000 patterns is called an "epoch". The display shows statistics about this process. Starting at the top, the display gives an estimate of the current mean squared error ("MSE") of the neural network. MSE is the value of <IMG height=25 alt="Error due to a single pattern P at the last layer n" src="/KB/library/NeuralNetRecognition/ErrNP.gif" width=25 align=center border=0> in equation (1) above, averaged across all 60,000 patterns. The value at the top is only a running estimate, calculated over the last 200 patterns.</P>
<P>A history of the current estimate of MSE is seen graphically just to the right. This is a graph of the current estimates of MSE, over the last four epochs.</P>
<P>Just below are a few more statistics, namely the number of fully-completed epochs, and the cardinal number of the current pattern being backpropagated. A progress bar is also shown.</P>
<P>Below that is an edit control showing information about each epoch. The information is updated as each epoch is completed.</P>
<P>The edit control also indicates when the Hessian (needed for second order backpropagation) is being calculated. During this time, which requires an analysis of 500 random patters, the neural network is not able to do much else, so a string of dots slowly scrolls across the control. Frankly, it's not logical to put this display inside the edit control, and this might change in future developments.</P>
<P>Backpropagation can be stopped at any time by clicking the "Stop Backpropagation" button.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A> <A name=TestingView></A>
<H3>Testing View of the Neural Network</H3>
<P>The testing view of the neural network is shown in the following screenshot:</P>
<P><IMG height=372 alt="Testing view of the neural network" src="/KB/library/NeuralNetRecognition/Screenshot-TestingView.gif" width=600 border=0> 
<P>In the testing mode, the 10,000 patterns in the testing set are run through the neural network, and if the output of the neural network does not match the expected output, an error is recorded in the view's main edit control. A progress bar through the testing set is displayed, and at the completion of testing, a summary of the total number of errors is displayed.</P>
<P>A testing sequence is commenced by clicking the "Start Testing" button, at which point you are shown a dialog from which you can select the testing parameters:</P>
<P><IMG height=189 alt="Selection of testing parameters" src="/KB/library/NeuralNetRecognition/Screenshot-TestingParameters.gif" width=282 border=0></P>
<P>It's usually best simply to select the default values. The meaning of the available parameters will become clearer once we look at the training parameters in the next section. Note that it is possible to "test" the training set, which can be useful for checking on convergence of the weights.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Training></A>
<H2>Training the Neural Network</H2>
<P>In order of importance, training is probably the next most important topic after design of the overall architecture of the neural network. We will discuss it over the next few sections.</P>
<P>The idea of training is to force the neural network to generalize. The word "generalization" deserves a few moments of your thought. An enormous amount of time is spent in analyzing the training set, but out in the real world, the performance of the neural network on the training set is of absolutely no interest. Almost any neural network can be trained so well it might not encounter any errors at all on the training set. But who cares about that? We already know the answers for the training set. The real question is, how well will the neural network perform out in the real world on patterns that it has never before seen?</P>
<P>The ability of a neural network to do well on patterns that it has never seen before is called "generalization". The effort spent in training is to force the neural network to see intrinsic characteristics in the training set, which we hope will also be present in the real world. When we calculate the MSE of the training set, we do so with the understanding that this is only an estimate of the number that we are really interested in, namely, the MSE of real-world data.</P>
<P>A few techniques are used during training in an effort to improve the neural network's generalization. As one example, the training set is passed through the neural network in a randomized order in each epoch. Conceptually, these techniques cause the weights to "bounce around" a bit, thereby preventing the neural network from settling on weights that emphasize false attributes of the patterns, i.e., attributes that are peculiar to patterns in the training set but which are not intrinsic characteristics of patterns encountered out in the real world.</P>
<P>One of the more important techniques for improving generalization is distortion: the training patterns are distorted slightly before being used in backpropagation. The theory is that these distortions force the neural network to look more closely at the important aspects of the training patters, since these patterns will be different each time the neural network sees them. Another way of looking at this is that distortions enlarge the size of the training set, by artificially creating new training patterns from existing ones.</P>
<P>In this program, the <CODE>CMNistDoc::GenerateDistortionMap()</CODE> function generates a distortion map that is applied to the training patterns (using the <CODE>CMNistDoc::ApplyDistortionMap()</CODE> function) during training. The distortion is calculated randomly for each pattern just before backpropagation. Three different types of distortions are applied:</P>
<UL>
<LI>Scale Factor: The scale of the pattern is changed so as to enlarge or shrink it. The scale factor for the horizontal direction is different from the scale factor for the vertical direction, such that it is possible to see shrinkage in the vertical scale and enlargement in the horizontal scale. 
<LI>Rotation: The entire pattern is rotated clockwise or counterclockwise. 
<LI>Elastic: This is a word borrowed Dr. Simard's <A href="http://research.microsoft.com/~patrice/PDF/fugu9.pdf" target=_newwin>"Best Practices"</A> paper. Visually, elastic distortions look like a gentle pushing and pulling of pixels in the pattern, almost like viewing the pattern through wavy water. </LI></UL>
<P>The result of distortions is illustrated in the following diagram, which shows the original of a pattern for the digit "3" together with 25 examples of distortions applied to the pattern:</P>
<P><IMG height=148 alt="Examples of distortions applied to training patterns" src="/KB/library/NeuralNetRecognition/DistortionCollage.gif" width=180 border=0> 
<P>You can see the effect of the three types of distortions, but to a human viewer, it is clear that each distortion still "looks like" the digit "3". To the neural network, however, the pixel patterns are remarkably different. Because of these differences, the neural network is forced to see beyond the actual pixel patterns, and hopefully to understand and apply the intrinsic qualities that make a "3" look like a "3".</P>
<P>You select whether or not to apply distortions when you click the "Start Backpropagation" button in the training view, at which point you are shown the following dialog which lets you select other training parameters as well:</P>
<P><IMG height=230 alt="Selection of training parameters" src="/KB/library/NeuralNetRecognition/Screenshot-BackpropagationParameters.gif" width=282 border=0> 
<P>Besides distortions, this dialog lets you set other parameters for backpropagation. Most notably, you must specify an initial learning rate "<I>eta</I>" and a final learning rate. Generally speaking, the learning rate should be larger for untrained neural networks, since a large learning rate will allow large changes in the weights during backpropagation. The learning rate is slowly decreased during training, as the neural network learns, so as to allow the weights to converge to some final value. But it never really makes sense to allow the learning rate to decrease too much, or the network will stop learning. That's the purpose of the entry for the final value.</P>
<P>For the initial value of the learning rate, never use a value larger than around 0.001 (which is the default). Larger values cause the weights to change too quickly, and actually cause the weights to <I><B>diverge</B></I> rather than converge.</P>
<P>Most of the literature on training of neural networks gives a schedule of learning rates as a function of epoch number. Dr. LeCun, for example, recommends a schedule of 0.0005 for two epochs, followed by 0.0002 for the next three, 0.0001 for the next three, 0.00005 for the next four, and 0.00001 thereafter. I found it easier to program a reduction factor that is applied after N recognitions. Frankly, I think it might have been better to listen to the experts, and this might change in the future to a schedule of learning rates. At present, however, at the end of N recognitions (such as 120,000 recognitions which corresponds to two epochs and is the default value), the program simply multiplies the current learning rate by a factor that's less than one, which results in a continuously decreasing learning rate.</P>
<P>The dialog was also written at a naive time of development, when I thought it might be possible to reduce the learning rate within a single epoch, rather than only after an epoch is completed. So, the reduction factor is given in terms of a reduction after N recognitions, rather than after N epochs which would have been more appropriate.</P>
<P>The default values for the dialog are values that I found to work well for untrained networks. The initial learning rate is 0.001, which is rather large and results in good coarse training quickly, particularly given the second order nature of the backpropagation algorithm. The learning rate is reduced by 79.4% of its value after every two epochs. So, for example, the training rate for the third epoch is 0.000794. The final learning rate is 0.00005, which is reached after around 26 epochs. At this point the neural network is well-trained.</P>
<P>The other options in the dialog are discussed below in the "Tricks" section.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Tricks></A>
<H2>Tricks That Make Training Faster</H2>
<P>As indicated in the beginning of the article, this project is an engineering work-in-progress, where many different adjustments are made in an effort to improve accuracy. Against that background, training can be a maddeningly slow process, where it takes several CPU hours to determine whether or not a change was beneficial. As a consequence, there were a few things done to make training progress more quickly.</P>
<P>Three things in particular were done: second order backpropagation, multithreading, and backpropagation skipping. The first has been done before, but I have not seen the second and third techniques in any of the resources that I found (maybe they're new??). Each is discussed below.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Hessian></A>
<H3>Second Order Backpropagation Using Pseudo-Hessian</H3>
<P>Second order backpropagation is not really a "trick"; it's a well-understood mathematical technique. And it was discussed above in the section on "<A href="#SecondOrder">Second Order Methods</A>". It's mentioned here again since it clearly had the greatest impact on speeding convergence of the neural network, in that it dramatically reduced the number of epochs needed for convergence of the weights.</P>
<P>The next two techniques are slightly different in emphasis, since they reduce the amount of time spent in any one epoch by speeding progress through the epoch. Put another way, although second order backpropagation reduces the overall time needed for training, the next two techniques reduce the time needed to go through all of the 60,000 patterns that compose a single epoch.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=SimultaneousBackprop></A>
<H3>Simultaneous Backpropagation and Forward Propagation</H3>
<P>In this technique, multiple threads are used to speed the time needed for one epoch.</P>
<P>Note that in general, multiple threads will almost always have a <B><I>negative</I></B> impact on performance. In other words, if it takes time T to perform all work in a single thread, then it will take time T+x to perform the same work with multiple threads. The reason is that the overhead of context switching between threads, and the added burden of synchronization between threads, adds time that would not be necessary if only a single thread were used.</P>
<P>The only circumstance where multiple threads will improve performance is where there are also multiple processors. If there are multiple processors, then it makes sense to divide the work amongst the processors, since if there were only a single thread, then all the other processors would wastefully be idle.</P>
<P>So, this technique helps only if your machine has multiple processors, i.e., if you have a hyper-threaded or dual core processor (Intel terminology) or dual processors (AMD terminology). If you do not have multiple processors, then you will not see any improvement when using multiple threads. Moreover, there is absolutely no benefit to running more threads than you have processors. So, if you have a hyperthreaded machine, use two threads exactly; use of three or more threads does not give any advantage.</P>
<P>But there's a significant problem in trying to implement a multi-threaded backpropagation algorithm. The problem is that the backpropagation algorithm depends on the numerical outputs of the individual neurons from the forward propagation step. So consider a simple multi-threaded scenario: a first thread forward propagates a first input pattern, resulting in neuron outputs for each layer of the neural network including the output layer. The backpropagation stage is then started, and equation (2) above is used to calculate how errors in the pattern depend on outputs of the output layer.</P>
<P>Meanwhile, because of multithreading, another thread selects a second pattern and forward propagates it through the neural network, in preparation for the backpropagation stage. There's a context switch back to the first thread, which now tries to complete backpropagation for the first pattern.</P>
<P>And here's where the problem becomes evident. The first thread needs to apply equations (3) and (4). But these equations depend on the numerical outputs of the neurons, and <B><I>all</I></B> of those values have now changed, because of the action of the second thread's forward propagation of the second pattern.</P>
<P>My solution to this dilemma is to memorize the outputs of all the neurons. In other words, when forward propagating an input pattern, the outputs of all 3215 neurons are stored in separate memory locations, and these memorized outputs are used during the backpropagation stage. Since the outputs are stored, another thread's forward propagation of a different pattern will not affect the backpropagation calculations.</P>
<P>The sequence runs something like this. First, a thread tries to lock a mutex that protects the neural network, and will wait until it can obtain the lock. Once the lock is obtained, the thread forward propagates a pattern and memorizes the output values of all neurons in the network. The mutex is then released, which allows another thread to do the same thing.</P>
<P>Astute readers will note that this solution might solve the problem of equations (2) through (4), since those equations depend on the numerical values of the neuron outputs, but that this solution does not address additional problems caused by equations (5) and (6). These two equations depend on the values of the weights, and the values of the weights might be changed out from under one thread by another thread's backpropagation. For example, continuing the above explanation, the first thread starts to backpropagate, and changes the values of the weights in (say) the last two layers. At this point, there is a context switch to the second thread, which also tries to calculate equation (5) and also tries to change the values of weights according to equation (6). But since both equations depend on weights that have now been changed by the first thread, the calculations performed by the second thread are not valid.</P>
<P>The solution here is to ignore the problem, and explain why it's numerically valid to do so. It's valid to ignore the problem because the errors caused by using incorrect values for the weights are generally negligible. To see that the errors are negligible, let's use a numeric example. Consider a worst-case situation that might occur during very early training when the errors in the output layer are large. How large can the errors be? Well, the target value for the output of a neuron might be +1, whereas the actual output might be -1 which is as wrong as it can get. So, per equation (2), the error is 2. Let's backpropagate that error of 2. In equation (3) we see that the error is multiplied by <I>G(x)</I>, which is the derivative of the activation function. The maximum value that <I>G(x)</I> can assume is around +1, so the error of 2 is still 2. Likewise, in equation (4), the value of 2 is multiplied by the outputs of neurons in the previous layer. But those outputs generally cannot exceed a value of +1 (since the outputs are limited by the activation function). So again, the error of 2 is still 2.</P>
<P>We need to skip equation (5) for a moment, since it's equation (6) that actually changes the values of the weights. In equation (6) we see that the change in the weight is our value of 2 multiplied by the learning rate <I>eta</I> (possibly multiplied by a second order Hessian). We know <I>eta</I> is small, since we deliberately set it to a small value like 0.001 or less. So, any weight might be changed by as much as our value of 2 multiplied by <I>eta</I>, or 2 x 0.001 = 0.002.</P>
<P>Now we can tackle equation (5). Let's assume that the second thread has just modified a weight as described above, which is now 0.002 different from the value that the first thread should be using. The answer here is a big "so what". It's true that the value of the weight has been changed, but the change is only 0.2%. So even though the first thread is now using a value for the weight that is wrong, the amount by which the weight is wrong is completely negligible, and it's justifiable to ignore it.</P>
<P>It can also be seen that the above explanation is a worst-case explanation. As the training of the neural network improves, the errors in each layer are increasingly smaller, such that it becomes even more numerically justifiable to ignore this effect of multithreading.</P>
<P>There's one final note on implementation in the code. Since the program is multithreaded, it cannot alter weights without careful synchronization with other threads. The nature of equation (6) is also such that one thread must be respectful of changes to the value of weight made by other threads. In other words, if the first thread simply wrote over the value of the weight with the value it wants, then changes made by other threads would be lost. In addition, since the weights are stored as 64-bit <CODE><span class='cpp-keyword'>double</span></CODE>s, there would be a chance that the actual weight might be corrupt if a first thread were interrupted before it had a chance to update both of the 32-bit halves of the weight.</P>
<P>In this case, synchronization is achieved without a kernel-mode locking mechanism. Rather, synchronization is achieved with a compare-and-swap ("CAS") approach, which is a lock-free approach. This approach makes use of atomic operations that are guaranteed to complete in one CPU cycle. The function used is <CODE>InterlockedCompareExchange64()</CODE> which performs an atomic compare-and-exchange operation on specified 64-bit values. The function compares a <I>destination</I> value with a <I>comparand</I> value and exchanges it with an <I>exchange</I> value only if the two are equal. If the two are not equal, then that means that another thread has modified the value of the weight, and the code tries again to make another exchange. Theoretically (and unlike locking mechanisms for synchronization), lock-free methods are not guaranteed to complete in finite time, but that's theory only and in practice lock-free mechanisms are widely used.</P>
<P>The code for updating the weight is therefore the following, which can be found in the <CODE>NNLayer::Backpropagate()</CODE> function. Note that the code given above in the "<A href="#Backpropagation">Backpropagation</A>" section was simplified code that omitted this level of detail in the interests of brevity:</P><PRE><span class="code-comment">//</span><span class="code-comment"> simplified code showing an excerpt
</span><span class="code-comment">//</span><span class="code-comment"> from the NNLayer::Backpropagate() function
</span>
<span class="code-comment">//</span><span class="code-comment"> finally, update the weights of this layer
</span><span class="code-comment">//</span><span class="code-comment"> neuron using dErr_wrt_dW and the learning rate eta
</span><span class="code-comment">//</span><span class="code-comment"> Use an atomic compare-and-exchange operation,
</span><span class="code-comment">//</span><span class="code-comment"> which means that another thread might be in 
</span><span class="code-comment">//</span><span class="code-comment"> the process of backpropagation
</span><span class="code-comment">//</span><span class="code-comment"> and the weights might have shifted slightly
</span>
<span class="code-keyword">struct</span> DOUBLE_UNION
{
    union 
    {
        <span class="code-keyword">double</span> dd;
        unsigned __int64 ullong;
    };
};

DOUBLE_UNION oldValue, newValue;

<span class="code-keyword">double</span> epsilon, divisor;

<span class="code-keyword">for</span> ( jj=0; jj&lt;m_Weights.size(); ++jj )
{
    divisor = <span class="code-comment">/*</span><span class="code-comment"> a value that depends on the second order Hessian */</span> 
    
    epsilon = etaLearningRate / divisor;
    <span class="code-comment">//</span><span class="code-comment"> amplify the learning rate based on the Hessian
</span>
    oldValue.dd = m_Weights[ jj ]-&gt;value;
    newValue.dd = oldValue.dd - epsilon * dErr_wrt_dWn[ jj ];
        
    <span class="code-keyword">while</span> ( oldValue.ullong != _InterlockedCompareExchange64( 
           (unsigned __int64*)(&amp;m_Weights[ jj ]-&gt;value), 
            newValue.ullong, oldValue.ullong ) ) 
    {
        <span class="code-comment">//</span><span class="code-comment"> another thread must have modified the weight.
</span>        <span class="code-comment">//</span><span class="code-comment"> Obtain its new value, adjust it, and try again
</span>        
        oldValue.dd = m_Weights[ jj ]-&gt;value;
        newValue.dd = oldValue.dd - epsilon * dErr_wrt_dWn[ jj ];
    }
    
}</PRE>
<P>I was very pleased with this speed-up trick, which showed dramatic improvements in speed of backpropagation without any apparent adverse effects on convergence. In one test, the machine had an Intel Pentium 4 hyperthreaded processor, running at 2.8gHz. In singly threaded usage, the machine was able to backpropagate at around 13 patterns per second. In two-threaded use, backpropagation speed was increased to around 18.6 patterns per second. That's an improvement of around 43% in backpropagation speed, which translates into a reduction of 30% in backpropagation time.</P>
<P>In another test, the machine had an AMD Athlon 64 x2 Dual Core 4400+ processor, running at 2.21 gHz. For one-threaded backpropagation the speed was around 12 patterns per second, whereas for two-threaded backpropagation the speed was around 23 patterns per second. That's a speed improvement of 92% and a corresponding reduction of 47% in backpropagation time.</P>
<P>As one final implementation note, my development platform is VC++ 6.0, which does not have the <CODE>InterlockedCompareExchange64()</CODE> function, not even as a compiler intrinsic. With help from the comp.programming.threads newsgroup (see <A href="http://groups.google.com/group/comp.programming.threads/browse_thread/thread/1c3b38cd249ff2ba/e90ff2c919f84612" target=_newwin>this thread</A>), I wrote my own assembler version, which I am reproducing here:</P><PRE>inline unsigned __int64 
_InterlockedCompareExchange64(<span class="code-keyword">volatile</span> unsigned __int64 *dest,
                           unsigned __int64 exchange,
                           unsigned __int64 comparand) 
{
    <span class="code-comment">//</span><span class="code-comment">value returned in eax::edx
</span>    __asm {
        lea esi,comparand;
        lea edi,exchange;
        
        mov eax,[esi];
        mov edx,<span class="code-digit">4</span>[esi];
        mov ebx,[edi];
        mov ecx,<span class="code-digit">4</span>[edi];
        mov esi,dest;
        <span class="code-comment">//</span><span class="code-comment">lock CMPXCHG8B [esi] is equivalent to the following except
</span>        <span class="code-comment">//</span><span class="code-comment">that it's atomic:
</span>        <span class="code-comment">//</span><span class="code-comment">ZeroFlag = (edx:eax == *esi);
</span>        <span class="code-comment">//</span><span class="code-comment">if (ZeroFlag) *esi = ecx:ebx;
</span>        <span class="code-comment">//</span><span class="code-comment">else edx:eax = *esi;
</span>        <span class="code-keyword">lock</span> CMPXCHG8B [esi];            
    }
}</PRE>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=SkipBackprop></A>
<H3>Skip Backpropagation for Small Errors</H3>
<P>For a decently-trained network, there are some patterns for which the error is very small. The idea of this speed-up trick, therefore, is that for such patterns where there is only a small error, it is frankly meaningless to backpropagate the error. The error is so small that the weights won't change. Simply put, for errors that are small, there are bigger fish to fry, and there's no point in spending time to backpropagate small errors.</P>
<P>In practice, the demo program calculates the error for each pattern. If the error is smaller than some small fraction of the current MSE, then backpropagation is skipped entirely, and the program proceeds immediately to the next pattern.</P>
<P>The small fraction is set empirically to one-tenth of the current MSE. For a pattern whose error is smaller than one-tenth the overall MSE in the prior epoch, then backpropagation is skipped entirely, and training proceeds to the next pattern.</P>
<P>The actual value of the fractional threshold is settable in the program's <I>.ini</I> file. The dialog for setting training parameters asks you to input the current MSE, so that it has some idea of the cut-off point between performing and not performing backpropagation. It advises you to input a small number for the MSE if you are unsure of the actual MSE, since for small MSE's, essentially all errors are backpropagated.</P>
<P>In testing, as the neural network gets increasingly well-trained, I have found that approximately one-third of the patterns result in an error so small that there's no point in backpropagation. Since each epoch is 60,000 patterns, there's no backpropagation of error for around 20,000 patterns. The remaining 40,000 patterns result in an error large enough to justify backpropagation.</P>
<P>On an Intel Pentium 4 hyperthreaded processor running at 2.8gHz, when these two speed-up tricks are combined (i.e., the multithreading speed-up, combined with skipping of backpropagations for patterns that result in a small error), each epoch completes in around 40 minutes. It's still maddeningly slow, but it's not bad.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Experiences></A>
<H2>Experiences In Training the Neural Network</H2>
<P>The default values for parameters found on the "Training" dialog are the result of my experiences in training the neural network for best performance on the testing set. This section gives an abbreviated history of those experiences.</P>
<P>Note: I only recently realized that I should have been tracking the overall MSE for both the training set <I><B>and</B></I> the testing set. Before writing this article, I only tracked the MSE of the training set, without also tracking the MSE of the testing set. It was only when I sat down to write the article that I realized my mistake. So, when you see a discussion of MSE, it's the MSE of the training set and not the MSE of the testing set.</P>
<P>My first experimentations were designed to determine whether there was a need for distortions while training, or if they just got in the way. Over many epochs without distortions, I was never able to get the error rate in the testing set below around 140 mis-recognitions out of the 10,000 testing patterns, or a 1.40% error rate. To me this meant that distortions were needed, since without them, the neural network was not able to effectively generalize its learned behavior when confronted with a pattern (from the testing set) that it had never before seen.</P>
<P>I am still not able to explain why Dr. LeCun was able to achieve an error rate of 0.89% without distortions. Perhaps one day I will repeat these experiments, now that I have more experience in training the network.</P>
<P>Anyway, having determined that distortions were needed to improve training and generalization, my experimentations turned toward the selection of "good" values for distortions of the training patterns. Too much distortion seemed to prevent the neural network from reaching a stable point in its weights. In other words, if the distortions were large, then at the end of each epoch, the MSE for the training set remained very high, and did not reach a stable and small value. On the other hand, too little distortion prevented the neural network from generalizing its result to the testing set. In other words, if the distortion was small, then the results from the testing set were not satisfactory.</P>
<P>In the end, I selected values as follows. Note that the values of all tune-able parameters are found in the <I>.ini</I> file for the program:</P>
<UL>
<LI>Maximum scale factor change (percent, like 20.0 for 20%) = 15.0 
<LI>Maximum rotational change (degrees, like 20.0 for 20 degrees) = 15.0 
<LI>Sigma for elastic distortions (higher numbers are more smooth and less distorted; Simard uses 4.0) = 8.0 
<LI>Scaling for elastic distortions (higher numbers amplify distortions; Simard uses 0.34) = 0.5 </LI></UL>&lt;!-- NOTE to me: Use file 30August2006-FourCycles-Another36Epochs-dot10MSE-94Errors.txt -->
<P>Once these values were selected, I began to concentrate on the training progression, and on the influence of the learning rate <I>eta</I>. I set up a 24-hour run, starting from purely randomized weights, over which 30 epochs were completed. The training rate was varied from an initial value of 0.001 down to a minimum of 0.00001 over 20 epochs, and thereafter (i.e., for the final 10 epochs) was maintained at this minimum value. After training was completed, I ran the testing set to see how well the neural network performed.</P>
<P>The results were a very-respectable 1.14% error rate in the set of testing patterns. That is, in the 10,000 pattern testing set, of which the neural net had never before seen any of the patterns, and had never before even seen the handwriting of any of the writers, the neural network correctly recognized 9,886 patterns and incorrectly misrecognized only 114 patterns. For the set of training patterns, there were around 1880 mis-recognitions in the distorted patterns.</P>
<P>Naturally, although I was pleased that the neural network worked at all, I was not satisfied with this performance. Seven years earlier, Dr. LeCun had achieved an error rate of 0.82%. Certainly, given the passage of seven years, better results could be obtained.</P>
<P>So, I graphed backpropagation progress as a function of epoch. At each epoch, I graphed the learning rate <I>eta</I>, the MSE (of the training set), and the change in MSE relative to the previous epoch. Since the change in MSE bounced around a bit, I also graphed a smoothed version of delta MSE. Here are the results. Note that the right-hand axis is for MSE, whereas the left-hand axis is for everything else.</P>
<P><IMG height=337 alt="Backpropagation progress over 30 epochs starting from scratch" src="/KB/library/NeuralNetRecognition/First-30-epochs.gif" width=592 border=0> 
<P>The graph shows very clearly that the neural network reaches a constant MSE quickly, after around 12-15 epochs, and then does not improve any further. The asymptotic value of MSE was 0.135, corresponding to around 1880 mis-recognized patterns in the distorted training set. There was no significant improvement in the neural network's performance after 12-15 epochs, at least not for the learning rates that were used for the latter epochs.</P>
<P>My first reaction, given the asymptotic nature of the curve, was one of concern: maybe the neural network was incapable of learning any better than this. So, I restarted the training with the initial learning rate of 0.001. But this time, instead of starting from purely random weights, I used the weights that resulted from the first 30 epochs. After another 15 hours of training, here is the graph of results:</P>
<P><IMG height=338 alt="Backpropagation progress over another 25 epochs" src="/KB/library/NeuralNetRecognition/Second-25-epochs.gif" width=513 border=0> 
<P>This graph was reassuring, since it showed that the neural network still had the capability to learn. It was simply a matter of teaching it correctly. At this point, the neural network had settled in on an MSE of around 0.113, corresponding to around 1550 mis-recognized patterns in the distorted training set. For the testing set, there were 103 mis-recognized patterns out of 10,000, which is an error rate of 1.03%. At least there was some improvement, which meant that the neural network could learn more, but not much improvement.</P>
<P>Looking at the graph, I decided that the learning rate should be set to a value that would allow the neural network to improve at a slow but deliberate pace. Arbitrarily, I tried a constant learning rate of 0.00015, which (as seen in the above graph) should have allowed the neural network to improve around 0.01 MSE every three or so epochs. More specifically, looking at the "Smoothed Delta MSE" graph above, at a learning rate of around 0.00015, the delta MSE per epoch was around 0.0033, which should have translated to an improvement of around 0.01 MSE after every three epochs.</P>
<P>The results were miserable. As shown in the following graph, even after an additional 15 epochs at the carefully chosen constant learning rate of 0.00015, there was no noticeable improvement in the network. For the set of training patterns, there were still around 1550 mis-recognized patterns; for the set of testing patterns, there was a slight improvement to 100 errors, for an error rate of exactly 1.00%:</P>
<P><IMG height=338 alt="Backpropagation progress over another 15 epochs at a constant learning rate of 0.0015" src="/KB/library/NeuralNetRecognition/Third-15-epochs.gif" width=512 border=0> 
<P>I was not certain of why the neural network failed to improve. Clearly the learning rate was too small, given the small size of the errors being produced by the network, which after all, had decent performance. So, I decided to increase the learning rate to a much larger value. I abandoned the idea of trying to estimate the change in MSE as a function of learning rate, and arbitrarily chose a starting value of <I>eta</I> = 0.0005. It was also clear that the minimum learning rate of 0.00001, used previously, was too small; instead, I chose a minimum learning rate of 0.0002.</P>
<P>On the other hand, I thought that I might be rushing the neural network, in the sense that I had been decreasing the learning rate after each and every epoch. After all, the training patterns were distorted; as a consequence, the neural network never really saw the same training pattern twice, despite the fact that the same patterns were used for all epochs. I decided to let the neural network stick with the same training rate for four epochs in a row, before decreasing it. This produced good results:</P>
<P><IMG height=339 alt="Backpropagation progress over another 35 epochs with stepped learing rate" src="/KB/library/NeuralNetRecognition/Fourth-35-Stepped-Epochs.gif" width=556 border=0> 
<P>As seen in the above graph, the neural network continued to learn for at least 15-20 epochs. The final MSE was somewhere around 0.102, corresponding to around 1410 mis-recognized characters in the distorted training set. On the testing set, there were only 94 errors (an error rate of 0.94%), so I had finally crossed the 1.00% threshold, and could see the possibility of meeting or exceeding the benchmark performance of Dr. LeCun's implementation.</P>
<P>But it had taken many, many epochs to get here. And each training cycle (except the first) had started with an already-trained network. I decided it was time to check whether the results could be reproduced, starting again from scratch, i.e., a blank neural network with purely random weights.</P>&lt;!-- Note to me: Use file 04September-SteppedFromScratch-64epochs-dot10MSE-86Errors.txt -->
<P>I again chose an initial learning rate of 0.001, but in keeping with the experiences to date, chose a minimum learning rate of 0.00005 (which is five times larger than the minimum learning rate in the first experiment). I also used a stepped decrease in the learning rate, as above, where the learning rate was kept at the same value for 4 epochs before it was reduced. I frankly did not like the math when these parameters were multiplied together: It would take 52 epochs to reach the minimum learning rate, and at 40 minutes per epoch, that would require at least 35 hours of processing time. (Because of the timing of overnight runs, I actually let it run for 63 epochs, or 42 hours.) I bit the bullet, hit the "Backpropagate" button, and waited. The results showed something interesting:</P>
<P><IMG height=336 alt="Backpropagation progress over 63 epochs, starring from scratch, with a stepped learning rate" src="/KB/library/NeuralNetRecognition/Fifth-63-epochs-Stepped-From-Scratch.gif" width=597 border=0> 
<P>First off, it should be apparent that the network trained itself well. The final MSE for the training set settled in at around 0.102, corresponding to around 1440 mis-recognitions in the distorted patterns of the training set. More importantly, mis-recognitions for the testing set were quite good: there were only 86 mis-recognitions out of the 10,000 patterns in the testing set, for an error rate of 0.86%. Dr. LeCun's benchmark was in sight.</P>
<P>The interesting thing about the graph is the "bump" in the MSE that seems to appear after each time that the learning rate is decreased. Look carefully: there's a kind of periodicity to the "Delta MSE" curve, with a spike (which represents a good reduction in MSE) occurring right after the learning rate is decreased. I theorized that the neural network needs to see the same learning rate for more than one epoch, but does not need to see it for as many as four epochs. After more experimentation, I concluded that the learning rate needs to be constant for only two epochs. This is good news for training, since it means that the neural network can be trained, reproducibly from scratch, to sub-one-percent errors in less than around 15-18 hours.</P>
<P>All together, based on the above experimentation, these are the defaults that you see in the "Backpropagation" dialog:</P>
<UL>
<LI>Initial learning rate (eta) = 0.001 
<LI>Minimum learning rate (eta) = 0.00005 
<LI>Rate of decay for learning rate (eta) = 0.794183335 
<LI>Decay rate is applied after this number of backprops = 120000 </LI></UL>
<P>The 0.86% error rate obtained above is very good, but it's still not as good as the 0.74% error rate in the title of this article. How did I get the error reduced further?</P>
<P>After some reflection on the results obtained so far, it appeared to me that there was still an apparent paradox in the error rates. On the training set, which the neural network actually sees, over and over again with only slight distortions, the network was not able to perform better than 1440 mis-recognitions out of 60,000 patterns, which works out to an error rate of 2.40%. That's nearly three times larger than the error rate of 0.86% for the testing set, which the neural network had never even seen. I theorized that while the distortions were clearly needed to force the neural network to generalize (remember: without distortions I was not able to achieve anything better than a 1.40% error rate on the testing set), after a while, they actually hampered the ability of the neural network to recognize and settle in on "good" weights. In a sense, the network might benefit from a final "polishing" with non-distorted patterns.</P>
<P>That's exactly what I did. First I trained (as above) with the distorted training set until I had obtained an error rate of 0.86% on the testing set. Then, I set the learning rate to a constant value of 0.0001, which is small but is still twice as large as the minimum value of 0.00005. At this learning rate, I ran non-distorted training patterns for five "polishing" epochs. The selection of five epochs was somewhat arbitrary/intuitive: at five epochs, the neural network showed 272 errors out of the 60,000 patterns in the training set, for an error rate of 0.45%. This value for error rate seemed appropriate, since it was smaller than the error rate on the testing set, yet not so small that all of the good generalizations introduced by distortions might be undone.</P>
<P>The "polishing" worked well, and resulted in the 0.74% error rate advertised above.</P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Results></A>
<H2>Results</H2>
<P>All 74 errors made by the neural network are shown in the following collage. For each pattern, the sequence number is given, together with an indication of the error made by the network. For example, "4176 2=&gt;7" means that for pattern number 4176, the network misrecognized a 2, and thought it was a 7:</P>
<P><IMG height=600 alt="Collage showing all 74 errors made by the neural network" src="/KB/library/NeuralNetRecognition/Collage-74-Errors.gif" width=429 border=0> 
<P>For some of these patterns, it's easy to see why the neural network was wrong: the patterns are genuinely confusing. For example, pattern number 5937, which is purported to be a 5, looks to me like a 3, which is what the neural network thought too. Other patterns appear to have artifacts from pre-processing by the MNIST authors, and it's the presence of these artifacts that confused the network. For example, pattern number 5457, which is clearly a 1, also has artifacts on the right-hand side, possibly caused when the pattern was separated from an adjacent pattern. Other patterns, primarily in the 8's, have too much missing from the bottom of the patterns.</P>
<P>But for the vast majority, the neural network simply got it wrong. The patterns aren't especially confusing. Each of the 7's looks like a 7, and there's no good reason why the neural network failed to recognize them as 7's.</P>
<P>Perhaps more training, with a larger training set, would help. I'm inclined to believe, however, that the network is at a point of diminishing returns with respect to training. In other words, more training might help some, but probably not much.</P>
<P>Instead, I believe that a different architecture is needed. For example, I think that the input layer should be designed with due recognition for the fact that the human visual system is very sensitive to spatial frequency. As a result, I believe that better performance could be obtained by somehow converting the input pattern to a frequency domain, which could be used to supplement the purely spatial input now being given as input. </P>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A> <A name=Bibliography></A>
<H2>Bibliography</H2>
<P>Here, in one place, is a list of all the articles and links mentioned in the article, as well as a few extra articles that might be helpful. Clicking the link will open a new window.</P>
<UL>
<LI><A href="http://yann.lecun.com/exdb/publis/index.html" target=_newwin>List of publications by Dr. Yann LeCun</A> 
<LI>Section of Dr. LeCun's web site on <A href="http://yann.lecun.com/exdb/lenet/index.html" target=_newwin>"Learning and Visual Perception"</A> 
<LI>Microsoft's <A href="http://www.research.microsoft.com/dpu/" target=_newwin>"Document Processing and Understanding"</A> group 
<LI><A href="http://research.microsoft.com/~patrice/publi.html" target=_newwin>List of publications by Dr. Patrice Simard</A> 
<LI><A href="http://www.nist.gov/srd/nistsd19.htm" target=_newwin>Database of handwritten patterns offered by the National Institute of Standards and Technology ("NIST")</A> 
<LI><A href="http://yann.lecun.com/exdb/mnist/index.html" target=_newwin>Modified NIST ("MNIST") database (11,594 Kb total)</A> 
<LI>Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, <A href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target=_newwin>"Gradient-Based Learning Applied to Document Recognition,"</A> Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, Nov. 1998. [46 pages] 
<LI>Y. LeCun, L. Bottou, G. Orr, and K. Muller, <A href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target=_newwin>"Efficient BackProp,"</A> in Neural Networks: Tricks of the trade, (G. Orr and Muller K., eds.), 1998. [44 pages] 
<LI>Patrice Y. Simard, Dave Steinkraus, John Platt, <A href="http://research.microsoft.com/~patrice/PDF/fugu9.pdf" target=_newwin>"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis,"</A> International Conference on Document Analysis and Recognition (ICDAR), IEEE Computer Society, Los Alamitos, pp. 958-962, 2003. 
<LI>Fabien Lauer, Ching Y. Suen and Gerard Bloch, <A href="http://hal.archives-ouvertes.fr/docs/00/05/75/61/PDF/LauerSuenBlochPR.pdf" target=_newwin>"A Trainable Feature Extractor for Handwritten Digit Recognition"</A>, Elsevier Science, February 2006 
<LI><CODE>DlgResizeHelper</CODE> class, by Stephan Keil, described at <A href="http://www.codeguru.com/Cpp/W-D/dislog/resizabledialogs/article.php/c1913/" target=_newwin>Dialog Resize Helper</A> 
<LI><A href="http://groups.google.com/group/comp.programming.threads/browse_thread/thread/1c3b38cd249ff2ba/e90ff2c919f84612" target=_newwin><CODE>InterlockedCompareExchange64()</CODE> function</A> on the comp.programming.threads newsgroup </LI></UL>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P><A name=Version></A>
<H2>License and Version Information</H2>
<P>The source code is licensed under the <A href="http://en.wikipedia.org/wiki/MIT_License" target=_blank>MIT X11-style open source license</A>. Basically, under this license, you can use/modify the code for almost anything you want. For a comparison with the BSD-style license and the much more restrictive GNU GPL-style license, read this Wikipedia article: <A href="http://en.wikipedia.org/wiki/BSD_and_GPL_licensing" target=_blank>"BSD and GPL licensing"</A>.</P>
<P>Version information:</P>
<UL>
<LI>26 November 2006: Original release of the code and this article. </LI></UL>
<P><A href="#topmost"><SMALL>go back to top</SMALL></A></P>


							</div>
							

							
							
							<h2>License</h2>
							<div id="LicenseTerms"><p>This article has no explicit license attached to it but may contain usage terms in the article text or the download files themselves. If in doubt please contact the author via the discussion board below.</p><p>A list of licenses authors might use can be found <a href="/info/Licenses.aspx">here</a></p></div>
							

							<div class="float-right" style="margin:20px 0 0 0;border:1px solid #ccc">
							<div class="msg-300x250" data-format="300x250" data-type="ad" data-publisher="lqm.codeproject.site" data-zone="ros"  data-loadOnView='true'  data-tags='VC6, Win2K, WinXP, MFC, Dev, Advanced,rating4.5'></div>
							</div>

							
							<h2 id="ctl00_AboutHeading">About the Author</h2>

							
							

<div class="container">
<div style="width:210px;overflow:hidden;float:left;text-align:center">
	<img id="ctl00_AboutAuthorRptr_ctl00_AboutAuthor_memberPhoto" class="profile-pic" src="http://www.codeproject.com/script/Membership/ProfileImages/{F26CCF55-3B82-4EBF-8BE7-3F023319AFB5}.jpg" style="border-width:0px;transform:rotate(2deg);" />
</div>
<div class="container-member float-left" style="width:235px">
	<b><a id="ctl00_AboutAuthorRptr_ctl00_AboutAuthor_memberProfileLink" class="author" href="/Members/Mike-ONeill">Mike O'Neill</a></b>
	<div class="company">
		<span id="ctl00_AboutAuthorRptr_ctl00_AboutAuthor_memberJobTitle"></span>
		<span id="ctl00_AboutAuthorRptr_ctl00_AboutAuthor_memberCompany"></span> 
		<br /><span id="ctl00_AboutAuthorRptr_ctl00_AboutAuthor_memberLocation">United States <img src="/script/Geo/Images/US.gif" alt="United States" width="16px" height="11px" /></span>
	</div>
</div>
	
<div class="padded-top float-left clearfix" style="width:600px">
	Mike O'Neill is a patent attorney in Southern California, where he specializes in computer and software-related patents.  He programs as a hobby, and in a vain attempt to keep up with and understand the technology of his clients.

	

	
</div>
</div><br />
							
							

							<div class="clearfix"></div>

							
							<div id="ctl00_RateArticleRow" class="clearfix voting-bar">
							<div class="float-left" style="padding-top:8px"><a class="anchorLink" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi#_articleTop">Article Top</a></div>
							<div class="float-left"><a id="_rating" name="_rating">&nbsp;</a></div> 
							<div class="float-left">

<div class="social-bookmarks">
<span class="facebook"><div id="fb-root"></div><div class="fb-like" data-href="http://www.codeproject.com/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi" data-send="false" data-layout="button_count" data-width="450"  data-show-faces="false" data-font="segoe ui"></div></span>
<span class="google" style="position:relative;top:-4px"><div class="g-plusone" data-size="medium"></div></span>
<span class="twitter" style="position:relative;top:-4px"><a href="https://twitter.com/share" class="twitter-share-button" data-hashtags="CodeProject">Tweet</a></span>
</div></div> 
							<div class="float-right align-right">
								<div id="ctl00_RateArticle_RateItemWrapper" class="container-rating small-text" name="RateItem_16650">

	<table width="100%" cellpadding="0" cellspacing="0" class="small-text">
	<tr>
		<td id="ctl00_RateArticle_VoteResultDiv" nowrap="nowrap" align="right">
			<span class="voteRes"></span>
			<img class="loaderImg" width="16px" alt="loading..." height="16px" 
				src="/Images/animated_loading_blue.gif" style="display:none;" /> 
		</td>

	
		<td class="voteTbl" style="white-space:nowrap" align="right">
			<table class="small-text">
			<tr>
				
				<td id="ctl00_RateArticle_RateText" class="rating-prompt">
					Rate this:
				</td>

				<td id="ctl00_RateArticle_StartForm" align="right" nowrap="nowrap">
					<i>&nbsp;&nbsp;Poor</i>
				</td>

				<td id="ctl00_RateArticle_VoteFormDiv" class="nowrap">
					

					<span id="ctl00_RateArticle_RB" class="tooltip ajaxHist radio voting">
						<span id="ctl00_RateArticle_VoteRBL"><input id="ctl00_RateArticle_VoteRBL_0" type="radio" name="ctl00$RateArticle$VoteRBL" value="1" onclick="ChkRtctl00_RateArticle(1, 16650);
$(&#39;#ctl00_RateArticle_RCD&#39;).show();
;" /><input id="ctl00_RateArticle_VoteRBL_1" type="radio" name="ctl00$RateArticle$VoteRBL" value="2" onclick="ChkRtctl00_RateArticle(2, 16650);
$(&#39;#ctl00_RateArticle_RCD&#39;).show();
;" /><input id="ctl00_RateArticle_VoteRBL_2" type="radio" name="ctl00$RateArticle$VoteRBL" value="3" onclick="ChkRtctl00_RateArticle(3, 16650);
$(&#39;#ctl00_RateArticle_RCD&#39;).show();
;" /><input id="ctl00_RateArticle_VoteRBL_3" type="radio" name="ctl00$RateArticle$VoteRBL" value="4" onclick="ChkRtctl00_RateArticle(4, 16650);
$(&#39;#ctl00_RateArticle_RCD&#39;).show();
;" /><input id="ctl00_RateArticle_VoteRBL_4" type="radio" name="ctl00$RateArticle$VoteRBL" value="5" onclick="ChkRtctl00_RateArticle(5, 16650);
$(&#39;#ctl00_RateArticle_RCD&#39;).show();
;" /></span> 

						
					</span>

				</td>

				<td id="ctl00_RateArticle_EndForm" align="left">
					<i>Excellent</i>
				</td>

				<td style="padding-left:5px">	
					<input type="submit" name="ctl00$RateArticle$SubmitRateBtn" value="Vote" onclick="return PostBack_ctl00_RateArticle_RateItemWrapper();" id="ctl00_RateArticle_SubmitRateBtn" class="button" />
				</td>
			</tr>
			</table>
			
		</td>
	</tr>
	</table>
	<div class="hover-container">
		<div id="ctl00_RateArticle_RCD" class="rating-comment align-left float-right">
			Add a reason or comment to your vote: <a href="#" id="clear-rate_ctl00_RateArticle_RCD" 
				title="close">x</a><br />
			<textarea class="RateComment" rows="5" cols="60" style="width:98%;"></textarea>
			<span id="ctl00_RateArticle_CommentReq" class="subdue">Votes of 3 or less require a comment</span>
		</div>
	</div>
</div>
							</div>
							</div>
							

						</form>

						
						<div style="margin:auto;height:90px;margin-top:10px"> 
							<div class="msg-728x90" data-format="728x90" data-type="ad" data-publisher="lqm.codeproject.site" data-zone="bottom"  data-loadOnView='true'  data-tags='VC6, Win2K, WinXP, MFC, Dev, Advanced,pos_bottom'></div>
						</div>
						
					

				</div>

				
					
					<h2>Comments and Discussions</h2>
					<a class="float-left" name="_comments" id="_comments">&nbsp;</a><div id="_MessageBoardctl00_MessageBoard" onclick="return SwitchMessage(event, null)">
	<table id="ForumTable" class="forum relaxed" cellpadding="0" cellspacing="0">
		<tr>
			<td><table width="100%" border="0" cellpadding="3px" cellspacing="0">
				<tr class="header1">
					<td colspan="2" style="white-space:nowrap;"><div class="container">
						<div class="button new-message compose float-left" onclick="FireNew(this)">
							<a href="/script/Forums/Edit.aspx?fid=364895&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi" name="Frm_HoverNL" target="_top">Add a Comment or Question&nbsp;</a>
						</div><div class="admin-links float-left align-middle" style="width:60px;line-height:24px;margin-top:4px;">
							&nbsp;<a href="/KB/FAQs/MessageBoardsFAQ.aspx"><img src="/images/help_sm.png" title="FAQ" alt="FAQ" style="border-width:0;width:16px;height:16px;vertical-align:middle;" /></a>
						</div><div class="float-right">
							<form action="/Search.aspx?fid=0" method="get" class="tight">
								<input type="hidden" name="fid" value="364895" /><b>Search this forum </b><input type="text" class="text-input" name="qf" style="width:200px;" />&nbsp;<input type="submit" value="Go" class="button" />
							</form>
						</div>
					</div></td><tr class="header2">
						<td></td><td style="width:100%;"><div style="text-align:right;">
							<form action="/script/Forums/SetOptions.aspx?floc=%2fArticles%2f16650%2fNeural-Network-for-Recognition-of-Handwritten-Digi&amp;fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed" method="get" style="margin:0;padding:0;">
								<input type="hidden" name="fid" value="364895" /><input type="hidden" name="currentQS" value="?floc=%2fArticles%2f16650%2fNeural-Network-for-Recognition-of-Handwritten-Digi&amp;fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed" /><input type="hidden" name="floc" value="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi" /><input type="checkbox" name="prof" id="prof" style="vertical-align:middle;" /><label for="prof">Profile popups</label>&nbsp;&nbsp;&nbsp;&nbsp;Spacing<select size="1" class="dropdown" name="spc">
									<option selected value="Relaxed">Relaxed</option><option value="Compact">Compact</option><option value="Tight">Tight</option>
								</select>&nbsp;&nbsp;Noise<select size="1" class="dropdown" name="noise">
									<option value="1">Very High</option><option value="2">High</option><option selected value="3">Medium</option><option value="4">Low</option><option value="5">Very Low</option>
								</select>&nbsp;&nbsp;Layout<select size="1" class="dropdown" name="view">
									<option selected value="Quick">Normal</option><option value="Topic">Open Topics</option><option value="Expanded">Open All</option><option value="Thread">Thread View</option><option value="Normal">No Javascript</option><option value="Preview">Preview</option>
								</select>&nbsp;&nbsp;Per page<select size="1" class="dropdown" name="mpp">
									<option value="10">10</option><option selected value="25">25</option><option value="50">50</option>
								</select>&nbsp;&nbsp;&nbsp;<input type="submit" value="Update" name="SetOpt" class="button" />
							</form>
						</div></td>
					</tr>
				</tr>
			</table></td><tr>
				<td><a name="xx0xx"></a><table border="0" cellpadding="2px" cellspacing="0" width="100%">
					<tr class="navbar">
						<td></td><td style="text-align:right;width:50%;"></td><td style="text-align:right;white-space:nowrap;"><span class="nav-link disabled">First</span> <span class="nav-link disabled">Prev</span><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=26#xx0xx">Next</a></td>
					</tr>
				</table></td>
			</tr><tr>
				<td><table border="0" cellpadding="0" cellspacing="0" width="100%" class="fixed-layout blank-background">
					<tr>
						<td><img src="/script/Forums/Images/t.gif" border="0" width="1px" height="5px" alt="" /></td>
					</tr><tr id="F4633096_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4633096xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4633096" parent="0" thread="4633096" href="/Messages/4633096/want-the-whole-code.aspx">want   the whole code</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=10197013">zerotwoyy</a></td><td class="date">10-Aug-13  3:15&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4633096_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="10197013" msgid="4633096" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">I  download the Neural Network demo project,and i am ready to learn it but i feel it is not a complete project,so i want the complete code in the project,thank you!<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4633096&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4633096&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4633096" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4633096/want-the-whole-code.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4633096&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4633096&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4633096" data-ref="3_4633096" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="10197013" msgid="4633096"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4577759_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4577759xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4577759" parent="0" thread="4577759" href="/Messages/4577759/My-vote-of-5.aspx">My vote of 5</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=10085837">new_coder2013</a></td><td class="date">2-Jun-13  0:57&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4577759_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="10085837" msgid="4577759" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">that is really helpful,thank you very much<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4577759&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4577759&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4577759" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4577759/My-vote-of-5.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4577759&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4577759&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4577759" data-ref="3_4577759" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="10085837" msgid="4577759"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4559945_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4559945xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4559945" parent="0" thread="4559945" href="/Messages/4559945/Can-that-architecture-be-used-for-letter-recogniti.aspx">Can that architecture be used for letter recognition?</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=10037784">Member 10037784</a></td><td class="date">8-May-13  12:57&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4559945_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="10037784" msgid="4559945" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">I am planning to program a neural network for handwritten letters recognition and I would like to use your neural network as a prototype. Will that work?<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4559945&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4559945&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4559945" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4559945/Can-that-architecture-be-used-for-letter-recogniti.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4559945&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4559945&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4559945" data-ref="3_4559945" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="10037784" msgid="4559945"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4539867_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4539867xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4539867" parent="0" thread="4539867" href="/Messages/4539867/Help-Im-stuck.aspx">Help! I'm stuck</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9984880">BnVn101</a></td><td class="date">13-Apr-13  3:53&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4539867_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="9984880" msgid="4539867" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hi sir, <br />
I wanna say it's really awesome! Thank you for sharing! <img src="/script/Forums/Images/smiley_smile.gif" align="top" alt="Smile | :)" />  <br />
Can you tell me, how can i creat and open file 10September-PolishedWithUndistorted-7epochs-dot026MSE-74Errors.nnt, please?<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4539867&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4539867&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4539867" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4539867/Help-Im-stuck.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4539867&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4539867&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4539867" data-ref="3_4539867" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9984880" msgid="4539867"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4504419_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4504419xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4504419" parent="0" thread="4504419" href="/Messages/4504419/Activation-Function.aspx">Activation Function</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=681013">OnlyJoe</a></td><td class="date">25-Feb-13  15:15&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4504419_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="681013" msgid="4504419" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hi Mike,<br />
&nbsp;<br />
Thanks so much for this article, it was very helpful and useful.<br />
&nbsp;<br />
I did just want to mention that the general sigmoid activation function does have its place still. But really only in networks that have to deal with very large input sets. For example, if you have a network which has say 50,000 input nodes, with a tanh activation function you could have 1 input set to 1 and 49,999 set to -1. However, with the general sigmoid you would have 1 input set to 1, and 49,999 set to 0. So with tanh you need to process all 50,000 sets of weights to get the sum for the function, but with the general sigmoid, you only need to process 1 set of weights to get the sum. This means you can store these weights in a lookup table, and effectively have networks with very large numbers of inputs. Great for processing text, where you might have 100,000 different words as your possible inputs.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4504419&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4504419&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4504419" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4504419/Activation-Function.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4504419&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4504419&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4504419" data-ref="3_4504419" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="681013" msgid="4504419"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4503768_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4503768xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4503768" parent="0" thread="4503768" href="/Messages/4503768/CNN-Structure.aspx">CNN Structure</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9701709">Anurag Gupta</a></td><td class="date">25-Feb-13  1:54&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4503768_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="9701709" msgid="4503768" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hi Mike,<br />
&nbsp;<br />
Thanks for sharing your work. I have a few questions, could you please help me out?<br />
&nbsp;<br />
1) Why are there 6 and 50 feature maps in first and second convolution layers?<br />
&nbsp;<br />
2) Are all the feature maps in a layers same i.e. are all neurons of the 6 feature maps in first convolution layer are made up from same 5*5 kernels from input layer? If they are same then why do we have 6 of them and if not how are they created?<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4503768&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4503768&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4503768" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4503768/CNN-Structure.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4503768&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4503768&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4503768" data-ref="3_4503768" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9701709" msgid="4503768"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4399313_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4399313xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4399313" parent="0" thread="4399313" href="/Messages/4399313/Question-about-backpropagation-training.aspx">Question about backpropagation training</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9505654">xiaoleih</a></td><td class="date">16-Oct-12  9:03&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4399313_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="9505654" msgid="4399313" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hi, Mike, <br />
&nbsp;<br />
You mentioned that this code built a specific network. I am wondering if you set the back-propagation training specifically for the built network as well? In another word, if I modify the code to build another new network, can I still use the same training code?<br />
&nbsp;<br />
I have not looked through your code, but in my impression back-propagation involves a lot more mathematics. Did you spend the most time coding on this part?<br />
&nbsp;<br />
Thanks much.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4399313&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4399313&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4399313" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4399313/Question-about-backpropagation-training.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4399313&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4399313&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4399313" data-ref="3_4399313" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9505654" msgid="4399313"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4377685_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4377685xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4377685" parent="0" thread="4377685" href="/Messages/4377685/regarding-increase-in-input-size.aspx">regarding increase in input size</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=7060129">ATISH VAZE</a></td><td class="date">25-Sep-12  1:42&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4377685_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="7060129" msgid="4377685" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Thanks for such informative article..<br />
I have been using similar CNN based approach for HINDI characters [42 classes].<br />
As Hindi characters are complex in shape,i want to increase the input size to say 60x60, can you please suggest how to proceed regarding that in selecting parameters i.e. how to select # of feature maps, feature map size # of layers etc etc ???<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4377685&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4377685&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4377685" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4377685/regarding-increase-in-input-size.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4377685&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4377685&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4377685" data-ref="3_4377685" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="7060129" msgid="4377685"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4399320_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="38px" class="indent"><a name="xx4399320xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_answer.gif" alt="Answer" /></td><td class="subject hover-container"><a class="message-link" name="4399320" parent="4377685" thread="4377685" href="/Messages/4399320/Re-regarding-increase-in-input-size.aspx">Re: regarding increase in input size</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9505654">xiaoleih</a></td><td class="date">16-Oct-12  9:06&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4399320_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:38px;"><img src="/script/Forums/Images/t.gif" height="1px" width="38px" alt="" /><div class="voteform vertical" ownerid="9505654" msgid="4399320" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">I think you will have to experiment various settings yourself. In Dr.Sigmoid's article, he gave some brief ideas, but for each specific case like yours, I don't think anyone knows more than you do.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4399320&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4399320&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4377685" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4399320/Re-regarding-increase-in-input-size.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4399320&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4399320&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4399320" data-ref="3_4399320" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9505654" msgid="4399320"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4336160_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4336160xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4336160" parent="0" thread="4336160" href="/Messages/4336160/whether-there-is-a-problem-in-your-code.aspx">whether there is a problem in your code</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=6526260">chenrui6321278</a></td><td class="date">12-Aug-12  2:43&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4336160_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="6526260" msgid="4336160" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2"><pre lang="cs"><span class="code-keyword">for</span> ( fm=0; fm&lt;<span class="code-digit">50</span>; ++fm)
{
    <span class="code-keyword">for</span> ( ii=0; ii&lt;<span class="code-digit">5</span>; ++ii )
    {
        <span class="code-keyword">for</span> ( jj=0; jj&lt;<span class="code-digit">5</span>; ++jj )
        {
            iNumWeight = fm * <span class="code-digit">26</span>;  <span class="code-comment">//</span><span class="code-comment"> 26 is the number of weights per feature map
</span>            NNNeuron&amp; n = *( pLayer-&gt;m_Neurons[ jj + ii*5 + fm*25 ] );
&nbsp;
            n.AddConnection( ULONG_MAX, iNumWeight++ );  <span class="code-comment">//</span><span class="code-comment"> bias weight
</span>
            <span class="code-keyword">for</span> ( kk=0; kk&lt;<span class="code-digit">25</span>; ++kk )
            {
                <span class="code-comment">//</span><span class="code-comment"> note: max val of index == 1013, corresponding to 1014 neurons in prev layer
</span>                n.AddConnection(       2*jj + 26*ii + kernelTemplate2[kk], iNumWeight++ );
                n.AddConnection( <span class="code-digit">169</span> + 2*jj + 26*ii + kernelTemplate2[kk], iNumWeight++ );
                n.AddConnection( <span class="code-digit">338</span> + 2*jj + 26*ii + kernelTemplate2[kk], iNumWeight++ );
                n.AddConnection( <span class="code-digit">507</span> + 2*jj + 26*ii + kernelTemplate2[kk], iNumWeight++ );
                n.AddConnection( <span class="code-digit">676</span> + 2*jj + 26*ii + kernelTemplate2[kk], iNumWeight++ );
                n.AddConnection( <span class="code-digit">845</span> + 2*jj + 26*ii + kernelTemplate2[kk], iNumWeight++ );
            }
        }
    }
}</pre> <br />
"26 is the number of weights per feature map" may be not right, in Layer #2, (5x5+1)x6x50 = 7800 weights,<br />
so you 26*6 is the number of weights per feature map ,and<br />
the code should rewrite as<br />
"<pre lang="cs">iNumWeight = fm * 26*6;  <span class="code-comment">//</span><span class="code-comment"> 26*6 is the number of weights per feature map</span></pre>
"<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4336160&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4336160&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4336160" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4336160/whether-there-is-a-problem-in-your-code.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4336160&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4336160&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4336160" data-ref="3_4336160" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="6526260" msgid="4336160"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4339633_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="38px" class="indent"><a name="xx4339633xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_answer.gif" alt="Answer" /></td><td class="subject hover-container"><a class="message-link" name="4339633" parent="4336160" thread="4336160" href="/Messages/4339633/Re-whether-there-is-a-problem-in-your-code-Yes-Re-.aspx">Re: whether there is a problem in your code: Yes, Re-Confirmed Again</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=208786">Mike O'Neill</a></td><td class="date">15-Aug-12  15:44&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4339633_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:38px;"><img src="/script/Forums/Images/t.gif" height="1px" width="38px" alt="" /><div class="voteform vertical" ownerid="208786" msgid="4339633" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">You are 100% correct that there is a bug in this code, which assigns weights and connections for layer#2.<br />
 <br />
Others have noticed this error too, for example:<br />
&nbsp;<br />
(1) "Weights in Level #2" by Droopy79, at <a href="http://www.codeproject.com/script/Forums/View.aspx?fid=364895&msg=2003444">http://www.codeproject.com/script/Forums/View.aspx?fid=364895&msg=2003444</a>[<a href="http://www.codeproject.com/script/Forums/View.aspx?fid=364895&msg=2003444" target="_blank" title="New Window">^</a>]. My response to Droopy's comment gives corrected code.<br />
&nbsp;<br />
(2) "A Bug?" by billconan at <a href="http://www.codeproject.com/Messages/2440587/a-bug.aspx">http://www.codeproject.com/Messages/2440587/a-bug.aspx</a>[<a href="http://www.codeproject.com/Messages/2440587/a-bug.aspx" target="_blank" title="New Window">^</a>].<br />
&nbsp;<br />
Best regards,<br />
Mike O'Neill<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4339633&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4339633&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4336160" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4339633/Re-whether-there-is-a-problem-in-your-code-Yes-Re-.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4339633&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4339633&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4339633" data-ref="3_4339633" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="208786" msgid="4339633"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4339944_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="56px" class="indent"><a name="xx4339944xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4339944" parent="4339633" thread="4336160" href="/Messages/4339944/Re-whether-there-is-a-problem-in-your-code-Yes-Re-.aspx">Re: whether there is a problem in your code: Yes, Re-Confirmed Again</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=6526260">chenrui6321278</a></td><td class="date">16-Aug-12  3:09&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4339944_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:56px;"><img src="/script/Forums/Images/t.gif" height="1px" width="56px" alt="" /><div class="voteform vertical" ownerid="6526260" msgid="4339944" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">sorry , i have read your code recently , so i have not noticed the comments before. please update the code ,or present the bug in the html page. And are there any other bug in your code ? please show us together, thank you very much.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4339944&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4339944&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4336160" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4339944/Re-whether-there-is-a-problem-in-your-code-Yes-Re-.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4339944&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4339944&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4339944" data-ref="3_4339944" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="6526260" msgid="4339944"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4290131_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4290131xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4290131" parent="0" thread="4290131" href="/Messages/4290131/My-vote-of-5.aspx">My vote of 5</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9128876">Jerry Jin</a></td><td class="date">24-Jun-12  22:08&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4290131_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="9128876" msgid="4290131" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">learned a lot from this article, excellent demo program!<br />
Thank you, Mike!<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4290131&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4290131&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4290131" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4290131/My-vote-of-5.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4290131&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4290131&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4290131" data-ref="3_4290131" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9128876" msgid="4290131"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4289899_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4289899xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4289899" parent="0" thread="4289899" href="/Messages/4289899/Need-help-with-math-equations-in-this-article.aspx">Need help with math equations in this article</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9128876">Jerry Jin</a></td><td class="date">24-Jun-12  6:33&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4289899_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="9128876" msgid="4289899" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hi, All<br />
&nbsp;<br />
I'm new to this area, could someone help me with math equations in this article please?<br />
&nbsp;<br />
I only made to equation (3), which i believe is applying chain rule.<br />
&nbsp;<br />
How does it arrive at equation (4),(5),(6)<br />
&nbsp;<br />
Thanks a lot!<br />
&nbsp;<br />
Best Regards,<br />
Jerry<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4289899&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4289899&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4289899" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4289899/Need-help-with-math-equations-in-this-article.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4289899&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4289899&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4289899" data-ref="3_4289899" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9128876" msgid="4289899"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4290007_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="38px" class="indent"><a name="xx4290007xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_answer.gif" alt="Answer" /></td><td class="subject hover-container"><a class="message-link" name="4290007" parent="4289899" thread="4289899" href="/Messages/4290007/Re-Need-help-with-math-equations-in-this-article.aspx">Re: Need help with math equations in this article</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=208786">Mike O'Neill</a></td><td class="date">24-Jun-12  12:43&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4290007_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:38px;"><img src="/script/Forums/Images/t.gif" height="1px" width="38px" alt="" /><div class="voteform vertical" ownerid="208786" msgid="4290007" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">(Please note that in this answer, which is text-only, I can't easily give the needed subscripts and superscripts.  I try to suggest them for the derivation of equation (5), but for the rest, you need to infer the subscripts and superscripts as much as possible.)<br />
&nbsp;<br />
All of equations (3), (4) and (5) are applications of the chain rule.  For equation (4):<br />
&nbsp;<br />
dE/dw = dy/dw * dE/dy<br />
&nbsp;<br />
where dE/dy is given in equation (3) and dy/dw is calculated from the derviative of the feedforward equation (given by the diagrams) of y = Sum( w*x ).  You should be able to determine that this derivative with respect to weights (w) of y = Sum( w*x ) tends to select the value of x whose index is related to the index of the weight, hence leading to the result that<br />
&nbsp;<br />
dy/dw = x, and<br />
dE/dw = x * dE/dy, which is equation (4).<br />
&nbsp;<br />
For equation (5), we need the partial derivative of error E with respect to x's of the previous layer (x_sub_n-1), so that we can backpropagate by repeating equations (3), (4) and (5) for the previous layer.  Again applying the chain rule:<br />
&nbsp;<br />
dE/dx_sub_n-1 = dy/dx_sub_n-1 * dE/dy<br />
&nbsp;<br />
where again y is the feedforward equation of y = Sum( w*x ).  You should be able to determine that this derivative with respect to input values x_sub_n-1 of the previous layer of y = Sum( w*x ) tends to select the values of the weights w whose indices are related to the index of the input, hence leading to the result that<br />
&nbsp;<br />
dy/dx_sub_n-1 = Sum( w ), and<br />
dE/dx_sub_n-1 = Sum( w ) * dE/dy, which is equation (5)<br />
&nbsp;<br />
Good luck,<br />
Mike<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4290007&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4290007&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4289899" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4290007/Re-Need-help-with-math-equations-in-this-article.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4290007&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4290007&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4290007" data-ref="3_4290007" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="208786" msgid="4290007"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4290130_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="56px" class="indent"><a name="xx4290130xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4290130" parent="4290007" thread="4289899" href="/Messages/4290130/Re-Need-help-with-math-equations-in-this-article.aspx">Re: Need help with math equations in this article</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=9128876">Jerry Jin</a></td><td class="date">24-Jun-12  22:03&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4290130_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:56px;"><img src="/script/Forums/Images/t.gif" height="1px" width="56px" alt="" /><div class="voteform vertical" ownerid="9128876" msgid="4290130" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Thanks a lot, Mike!<br />
&nbsp;<br />
Now i understand, really appreciate your help!<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4290130&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4290130&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4289899" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4290130/Re-Need-help-with-math-equations-in-this-article.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4290130&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4290130&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4290130" data-ref="3_4290130" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="9128876" msgid="4290130"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4225250_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4225250xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4225250" parent="0" thread="4225250" href="/Messages/4225250/My-vote-of-5.aspx">My vote of 5</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=3318782">Vietdungiitb</a></td><td class="date">18-Apr-12  22:33&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4225250_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="3318782" msgid="4225250" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hi Mike,<br />
Thank you very much for your article. It really helped me so much to understand and develope a library for neural network<a href=""></a>[<a href="" target="_blank"></a>] and especially for convolution neural network. At present the library can create a network with input parameters from  developer. So I can create not only network for digit recognition but networks for letter or etc. If you did not publish your article I could not complete my project. Once again, please receive thanks from my heart.<br />
The library is publish here: <a href="http://www.codeproject.com/Articles/363596/Library-for-online-handwriting-recognition-system">Library for online handwriting recognition system using UNIPEN database.</a>[<a href="http://www.codeproject.com/Articles/363596/Library-for-online-handwriting-recognition-system" target="_blank" title="New Window">^</a>]<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4225250&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4225250&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4225250" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4225250/My-vote-of-5.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4225250&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4225250&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4225250" data-ref="3_4225250" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="3318782" msgid="4225250"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4217856_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4217856xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4217856" parent="0" thread="4217856" href="/Messages/4217856/My-vote-of-5.aspx">My vote of 5</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=5071129">manoj kumar choubey</a></td><td class="date">11-Apr-12  8:37&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4217856_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="5071129" msgid="4217856" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Nice<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4217856&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4217856&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4217856" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4217856/My-vote-of-5.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4217856&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4217856&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4217856" data-ref="3_4217856" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="5071129" msgid="4217856"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4212667_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4212667xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4212667" parent="0" thread="4212667" href="/Messages/4212667/very-nice-job.aspx">very nice job</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=3167738">Member 3167738</a></td><td class="date">5-Apr-12  0:20&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4212667_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="3167738" msgid="4212667" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">This project was a helpful debugging guide (sensitivities, intermediate learn rates, etc.) for writing my own generic convolutional net/MLP framework. Your information on performance was helpful as well and served as one of my baselines (the framework I wrote does the training on a CUDA graphics card).<br />
&nbsp;<br />
Excellent work and a very well written article. Thanks for posting it.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4212667&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4212667&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4212667" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4212667/very-nice-job.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4212667&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4212667&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4212667" data-ref="3_4212667" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="3167738" msgid="4212667"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4192881_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4192881xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4192881" parent="0" thread="4192881" href="/Messages/4192881/My-vote-of-5.aspx">My vote of 5</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=4320844">Member 4320844</a></td><td class="date">16-Mar-12  9:53&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4192881_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="4320844" msgid="4192881" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Nice Work Mike, I have a question about the method used in handling your derivatives G() for the activation function .. Centered , Forward, Backward difference method .. which one is used in your code?. <br />
Since the central method is more accurate. if this may reflect on your results may be?.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4192881&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4192881&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4192881" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4192881/My-vote-of-5.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4192881&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4192881&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4192881" data-ref="3_4192881" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="4320844" msgid="4192881"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4195001_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="38px" class="indent"><a name="xx4195001xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="4195001" parent="4192881" thread="4192881" href="/Messages/4195001/Re-My-vote-of-5.aspx">Re: My vote of 5</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=208786">Mike O'Neill</a></td><td class="date">19-Mar-12  14:59&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4195001_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:38px;"><img src="/script/Forums/Images/t.gif" height="1px" width="38px" alt="" /><div class="voteform vertical" ownerid="208786" msgid="4195001" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Given the activation function x = F(y) = tanh(y) (where y is the input to the activation function and x is the output), then the derivative of the activation function G = 1 - x^2 is exact, i.e., the derivative is calculated as algebraically exact, without the need for any approximating numerical methods such as centered, forward or backward differences.<br />
&nbsp;<br />
And the beauty of this equation for G is that it depends only on a value we already have, namely, it depends only on the value "x" which is the output of the activation function F(y).<br />
&nbsp;<br />
Read the section titled <a href="http://www.codeproject.com/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi#ActivationFunction">The Activation Function (or, "Sigmoid" or "Squashing" Function)<br />
</a>[<a href="http://www.codeproject.com/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi#ActivationFunction" target="_blank" title="New Window">^</a>] for a more detailed explanation.   But again, given the activation function of tanh(), the derivative is exact and is not calculated through some numerical approximation to the derivative.<br />
&nbsp;<br />
Mike<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4195001&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4195001&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4192881" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4195001/Re-My-vote-of-5.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4195001&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4195001&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4195001" data-ref="3_4195001" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="208786" msgid="4195001"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F4056639_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx4056639xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="4056639" parent="0" thread="4056639" href="/Messages/4056639/About-the-number-of-possible-positions-of-the-conv.aspx">About the number of possible positions of the convolution kernel [modified]</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=6675850">yacek1234</a></td><td class="date">19-Oct-11  11:03&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F4056639_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="6675850" msgid="4056639" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Hey Mike,<br />
&nbsp;<br />
I'm struggling to understand the number of possible positions for 5x5 kernel in 29x29 input image. You wrote: "As a consequence, there are 13 positions where the 5x5 kernel will fit in each row of the input layer(...)" Why 13 positions? If there is 29 pixels in a row, there is actually 25 positions for the kernel with the width of 5. However, if you skip every other pixel in the input image, there is still 21 positions for the 5x5 kernel. How did you get the number of 13?<br />
&nbsp;<br />
Edit: ok, I finally got it. It goes like this: 1,2,3,4,5;  3,4,5,6,7;  5,6,7,8,9; ... 25,26,27,28,29. There are 13 of these.<br /><br /><div class="modified">modified  22-Oct-11 7:21am.</div><br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4056639&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=4056639&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=4056639" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/4056639/About-the-number-of-possible-positions-of-the-conv.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=4056639&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=4056639&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF4056639" data-ref="3_4056639" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="6675850" msgid="4056639"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F3949347_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx3949347xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_question.gif" alt="Question" /></td><td class="subject hover-container"><a class="message-link" name="3949347" parent="0" thread="3949347" href="/Messages/3949347/How-reduce-the-number-of-patterns.aspx">How reduce the number of patterns</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=8042529">gabrieldarge</a></td><td class="date">6-Jul-11  4:59&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F3949347_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="8042529" msgid="3949347" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">I would training this Neural net on only 10000 patterns instead of 60000 that i download by this site to reduce the time for backpropagation. I don' t know where the code would be changed and i ask you a solution to resolve this problem!<br />
&nbsp;<br />
thanks.<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=3949347&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=3949347&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=3949347" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/3949347/How-reduce-the-number-of-patterns.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=3949347&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=3949347&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF3949347" data-ref="3_3949347" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="8042529" msgid="3949347"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F3883526_h0" class="header hover-row root">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="20px" class="indent"><a name="xx3883526xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="3883526" parent="0" thread="3883526" href="/Messages/3883526/Learning-Rate-Problem-modified.aspx">Learning Rate Problem [modified]</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=5275606">kebomix</a></td><td class="date">7-May-11  0:35&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F3883526_h1" class="content root selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:20px;"><img src="/script/Forums/Images/t.gif" height="1px" width="20px" alt="" /><div class="voteform vertical" ownerid="5275606" msgid="3883526" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Firstly, i have to thank you for your awesome article and great efforts you made, it really helped me much on my Graduation Project <img src="/script/Forums/Images/smiley_smile.gif" align="top" alt="Smile | :)" /> <br />
&nbsp;<br />
Secondly: I'm trying to train 500 Pattern using Standard Backpropagation with no distortions, and using also your CNN Structure as a start to ensure that the system is working well, and i have a strange problem, i can't find the appropriate learning rate !, for ex: if i'm training 3 patters, i can't get the error less than 3 ( as known it must be less than one), what happens actually the system only train one pattern in all training cases, i tried learning rates you mentioned in your experiences above, and they doesn't work, here is an <u><a href="http://pastebin.com/j0YUsPHE">example</a></u>   of training 3 patterns after 70 epoch using <br />
    <pre>Initial learning rate (eta) = <span class="code-digit">0</span>.<span class="code-digit">001</span>
    Minimum learning rate (eta) = <span class="code-digit">0</span>.<span class="code-digit">00005</span>
    Rate of decay <span class="code-keyword">for</span> learning rate (eta) = <span class="code-digit">0</span>.<span class="code-digit">794183335</span>
</pre>
I even tried a lot of learning rates, small and large as well, also I'm using tanh() only as a activation function and using dsigmoid function you mentioned above, my implementation is correct, i almost converted your code to java, i tried to fix that issue with no luck, hope you can help me with this problem.<br />
<div class="signature"><br />
<div class="modified">modified on Saturday, May 7, 2011 1:41 AM</div></div><br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=3883526&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=3883526&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=3883526" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/3883526/Learning-Rate-Problem-modified.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=3883526&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=3883526&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF3883526" data-ref="3_3883526" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="5275606" msgid="3883526"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr id="F3885876_h0" class="header hover-row">
						<td class="subject-line quick " width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr>
								<td width="38px" class="indent"><a name="xx3885876xx"></a><img height="16px" width="16px" align="top" src="/script/Forums/Images/msg_general.gif" alt="General" /></td><td class="subject hover-container"><a class="message-link" name="3885876" parent="3883526" thread="3883526" href="/Messages/3885876/Re-Learning-Rate-Problem.aspx">Re: Learning Rate Problem</a> <a onclick="return Pin(this);" href="#" title="Click to pin message"><img src="/script/Forums/Images/pin.png" border="0" align="top" alt="Pin" width="13px" height="13px" /></a></td><td class="icon"><img border="0" src="/App_Themes/CodeProject/Img/icn-member-16.gif" title="member" alt="member" height="16px" /></td><td class="author"><a href="/script/Membership/View.aspx?mid=208786">Mike O'Neill</a></td><td class="date">9-May-11  19:01&nbsp;</td>
							</tr>
						</table></td>
					</tr><tr id="F3885876_h1" class="content selected" style="display:none;">
						<td class="quick" width="100%"><table border="0" cellpadding="0" cellspacing="0" width="100%">
							<tr valign="top">
								<td class="indent align-right" style="width:38px;"><img src="/script/Forums/Images/t.gif" height="1px" width="38px" alt="" /><div class="voteform vertical" ownerid="208786" msgid="3885876" votingType="GoodOrBad">

								</div></td><td class="text"><table border="0" cellpadding="0" cellspacing="5px" width="100%">
									<tr>
										<td><table border="0" cellpadding="0" cellspacing="0" width="100%">
											<tr>
												<td colspan="2">Training with only "3 patterns" makes no sense.  You must train on a vast number of visually diverse patterns.  The article trains on 60,000 patterns, and in addition distorts them, so as to obtain a "vast number" of visually diverse training patterns.  Results from training with only 3 patterns are useless.<br />
&nbsp;<br />
Mike<br /></td>
											</tr><tr class="footer" style="vertical-align:top;">
												<td><a class="new-message" href="/script/Forums/Edit.aspx?fid=364895&amp;select=3885876&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=r" title="Reply">Reply</a>·<wbr><a class="nav-link" href="/script/Forums/Edit.aspx?fid=364895&amp;select=3885876&amp;floc=/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi&amp;action=e" title="Email">Email</a>·<wbr><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;sort=Position&amp;spc=Relaxed&amp;tid=3883526" title="View&nbsp;Thread">View&nbsp;Thread</a>·<wbr><a href="/Messages/3885876/Re-Learning-Rate-Problem.aspx" title="Get permanent link">Permalink</a>·<wbr><a href="/script/Bookmarks/Add.aspx?obid=3885876&amp;obtid=3&amp;action=AddBookmark&amp;bio=false" title="Bookmark this post" onclick="return bookmarkMe(0,0,'/script/Bookmarks/Ajax/Add.aspx?obid=3885876&obtid=3&action=AddBookmark&bio=false',false, this, this);">Bookmark</a></td><td style="text-align:right;"><span id="MVF3885876" data-ref="3_3885876" class="rating-label" style="white-space:nowrap;"><span class="reportform" ownerid="208786" msgid="3885876"></span></span></td>
											</tr>
										</table></td>
									</tr>
								</table></td>
							</tr>
						</table></td>
					</tr><tr>
						<td><img src="/script/Forums/Images/t.gif" border="0" width="1px" height="5px" alt="" /></td>
					</tr>
				</table></td>
			</tr><tr>
				<td><table width="100%" cellpadding="2px" cellspacing="0">
					<tr class="footer">
						<td>Last Visit: 24-Sep-13  16:10 &nbsp; &nbsp; Last Update: 24-Sep-13  13:58</td><td><a href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed">Refresh</a></td><td style="text-align:right;white-space:nowrap;"><input id="_mbnUrl" type="hidden" value="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=26" /><span class="nav-link selected">1</span><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=26#xx0xx">2</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=51#xx0xx">3</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=76#xx0xx">4</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=101#xx0xx">5</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=126#xx0xx">6</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=151#xx0xx">7</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=176#xx0xx">8</a><a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=201#xx0xx">9</a> <a class="nav-link" name="Frm_HoverNL" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?fid=364895&amp;df=90&amp;mpp=25&amp;noise=3&amp;prof=False&amp;sort=Position&amp;view=Quick&amp;spc=Relaxed&amp;fr=26#xx0xx">Next »</a></td>
					</tr>
				</table></td>
			</tr>
		</tr>
	</table>
</div><p class="small-text"><img align="top" src="/script/Forums/Images/msg_general.gif" width="16px" height="16px" alt="General" /> General &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_news.gif" width="16px" height="16px" alt="News" /> News &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_idea.gif" width="16px" height="16px" alt="Suggestion" /> Suggestion &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_question.gif" width="16px" height="16px" alt="Question" /> Question &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_bug.gif" width="16px" height="16px" alt="Bug" /> Bug &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_answer.gif" width="16px" height="16px" alt="Answer" /> Answer &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_joke.gif" width="16px" height="16px" alt="Joke" /> Joke &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_rant.gif" width="16px" height="16px" alt="Rant" /> Rant &nbsp;&nbsp; <img align="top" src="/script/Forums/Images/msg_admin.gif" width="16px" height="16px" alt="Admin" /> Admin &nbsp;&nbsp; </p><p class="small-text">Use Ctrl+Left/Right to switch messages, Ctrl+Up/Down to switch threads, Ctrl+Shift+Left/Right to switch pages.</p>

				

			</div>
			
		</td>
		<td>
			<div id="ctl00_RightSideBar" class="container-article-info">

				<div class="header">About Article</div>
				<div class="article-summary">

					
					

					
					

					
					<div class="summary"><span id="ctl00_ArticleDescr">A convolutional neural network achieves 99.26% accuracy on a modified NIST database of hand-written digits.</span></div>

					<a id="ctl00_InfoBox_ParentLink"></a>

<table cellpadding="0" cellspacing="0" class="article-info">

	
	<tr><td>Type&nbsp;</td><td class="value"><a id="ctl00_InfoBox_TypeName" href="/script/Articles/Types.aspx?#Article">Article</a></td></tr>
	

	<tr><td>Licence&nbsp;</td><td class="value"></td></tr>

	

	<tr><td>First Posted&nbsp;</td><td nowrap="nowrap" class="value"><span itemprop="datePublished" content="2006-12-05">5 Dec 2006</span></td></tr>

	<tr><td>Views&nbsp;</td><td class="value">445,440</td></tr>

		

	
	<tr><td>Bookmarked&nbsp;</td><td class="value">476 times</td></tr>
	

	

	
	
	
	<tr><td colspan="2"></td>
	</tr>
	
	
</table>

					<div class="tags"> 
					<span id="ctl00_TagsList_TagWrp" class="tags">
	
	
	
	<span id="ctl00_TagsList_VisibleTags"><span class="t"><a rel="tag" href="/Tags/VC6">VC6</a></span><span class="t"><a rel="tag" href="/Tags/Win2K">Win2K</a></span><span class="t"><a rel="tag" href="/Tags/WinXP">WinXP</a></span><span class="t"><a rel="tag" href="/Tags/MFC">MFC</a></span><span class="t"><a rel="tag" href="/Tags/Dev">Dev</a></span><br><span class="t"><a rel="tag" href="/Tags/Advanced">Advanced</a></span></span> 

	
	
</span>

					</div>

					<div class="nowrap align-left">
						<a id="ctl00_ActionLinks_ArticleBmk_ImgBt" title="Bookmark" AlternateText="Bookmark" name="bm_16650_2" onclick="return bookmarkMe(16650,2,&#39;/script/Bookmarks/Ajax/Add.aspx?obid=16650&amp;obtid=2&amp;action=AddBookmark&amp;bio=true&#39;,false);" href="/script/Bookmarks/Add.aspx?obid=16650&amp;obtid=2&amp;action=AddBookmark&amp;bio=true" style="display:inline-block;height:46px;width:46px;vertical-align:middle;"><img title="Bookmark" src="/App_Themes/CodeProject/Img/bookmark.gif" alt="" style="border-width:0px;" /></a>


<span id="ctl00_ActionLinks_ArticleBmk_StatusMsg" class="tiny-text" style="display:none" name="bm_16650_2"></span>
 

<a id="ctl00_ActionLinks_PrintLnk" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?display=Print">
	<img src="/App_Themes/CodeProject/Img/print.gif" 
		width="46px" height="46px" style="border:0">
</a>

<a id="ctl00_ActionLinks_MailLink" href="/script/common/TellFriend.aspx?obtid=2&amp;obid=16650">
	<img src="/App_Themes/CodeProject/Img/email.gif" 
		width="46px" height="46px" style="border:0">
</a>
					</div>

					
				</div>

				<div style="width:160px;margin: 10px auto;">
					<div class="msg-160x600" data-format="160x600" data-type="ad" data-publisher="lqm.codeproject.site" data-zone="ros"  data-tags='VC6, Win2K, WinXP, MFC, Dev, Advanced,rating4.5'></div>
				</div>

				
<div class="padded-top">
<div class="header">Top News</div>

<p><a id="ctl00_News_News_ctl01_Link" href="http://blog.splinter.me/salaries-for-developers-and-designers-across-the-world/">Salaries for Developers and Designers across the world</a></p>

Get the <a id="ctl00_News_News_ctl02_Subscribe" href="/Feature/Insider/">Insider News</a> free each morning.
</div>

				

				<div class="padded-top">
					
	<div id="ctl00_RelatedVideos_RelatedResults_ctl00_header" class="header">Related Videos</div>
	<div class="content-list align-center">	
	
	<div class="content-list-item">
		<a id="ctl00_RelatedVideos_RelatedResults_ctl01_Link" class="title" href="http://codeproject.tv/video/5000855/javascript_chrome_developer_tools_network_panel"><img id="ctl00_RelatedVideos_RelatedResults_ctl01_Thumbnail" src="//codeprojecttv.s3.amazonaws.com/thumbnails_production/5/6057/thumb/cptv100x80ms.jpg" style="border-style:None;width:125px;border-width:0px;" /></a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedVideos_RelatedResults_ctl02_Link" class="title" href="http://codeproject.tv/video/4938430/working_with_gestures"><img id="ctl00_RelatedVideos_RelatedResults_ctl02_Thumbnail" src="//codeprojecttv.s3.amazonaws.com/thumbnails_production/c/1857/thumb/ios-Thumbnail.png" style="border-style:None;width:125px;border-width:0px;" /></a>
		
	</div>
	
	</div>
	

				</div>
				<div class="padded-top">
					
	<div id="ctl00_RelatedArticles_RelatedResults_ctl00_header" class="header">Related Articles</div>
	<div class="content-list">	
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl01_Link" class="title" href="/Articles/523074/Online-handwriting-recognition-using-multi-convolu">Online handwriting recognition using multi convolution neural networks</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl02_Link" class="title" href="/Articles/376798/Large-pattern-recognition-system-using-multi-neura">Large pattern recognition system using multi neural networks</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl03_Link" class="title" href="/Articles/24361/A-Neural-Network-on-GPU">A Neural Network on GPU</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl04_Link" class="title" href="/Articles/571462/Multiple-convolution-neural-networks-approach-for-">Multiple convolution neural networks approach for online handwriting recognition</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl06_Link" class="title" href="/Articles/143059/Neural-Network-for-Recognition-of-Handwritten-Digi">Neural Network for Recognition of Handwritten Digits in C#</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl07_Link" class="title" href="/Articles/74348/Handwriting-Recognition-using-Kernel-Discriminant-">Handwriting Recognition using Kernel Discriminant Analysis</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl08_Link" class="title" href="/Articles/140631/Convolutional-Neural-Network-Workbench">Convolutional Neural Network Workbench</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl09_Link" class="title" href="/Articles/106583/Handwriting-Recognition-Revisited-Kernel-Support-V">Handwriting Recognition Revisited: Kernel Support Vector Machines</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl10_Link" class="title" href="/Articles/15304/Unicode-Optical-Character-Recognition">Unicode Optical Character Recognition</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl11_Link" class="title" href="/Articles/14188/Brainnet-1-A-Neural-Netwok-Project-With-Illustrati">Brainnet 1 - A Neural Netwok Project - With Illustration And Code - Learn Neural Network Programming Step By Step And Develop a Simple Handwriting Detection System</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl12_Link" class="title" href="/Articles/346244/UPV-UNIPEN-online-handwriting-recognition-database">UPV – UNIPEN online handwriting recognition database viewer control</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl13_Link" class="title" href="/Articles/16447/Neural-Networks-on-Csharp">Neural Networks on C#</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl14_Link" class="title" href="/Articles/3907/Creating-Optical-Character-Recognition-OCR-applica">Creating Optical Character Recognition (OCR) applications using Neural Networks</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl15_Link" class="title" href="/Articles/1591/Mouse-gestures-recognition">Mouse gestures recognition</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl16_Link" class="title" href="/Articles/363596/Library-for-online-handwriting-recognition-system-">Library for online handwriting recognition system using UNIPEN database.</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl17_Link" class="title" href="/Articles/160868/A-Csharp-Project-in-Optical-Character-Recognition-">A C# Project in Optical Character Recognition (OCR) Using Chain Code</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl18_Link" class="title" href="/Articles/11285/Neural-Network-OCR">Neural Network OCR</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl19_Link" class="title" href="/Articles/477689/JavaScript-Machine-Learning-and-Neural-Networks-wi">JavaScript Machine Learning and Neural Networks with Encog</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl20_Link" class="title" href="/Articles/19323/Image-Recognition-with-Neural-Networks">Image Recognition with Neural Networks</a>
		
	</div>
	
	<div class="content-list-item">
		<a id="ctl00_RelatedArticles_RelatedResults_ctl21_Link" class="title" href="/Articles/54575/An-Introduction-to-Encog-Neural-Networks-for-Cshar">An Introduction to Encog Neural Networks for C#</a>
		
	</div>
	
	</div>
	

				</div>
				<div class="padded-top">
					
				</div>

				
				
			</div>
		</td>
		</tr></table>

		
		<div class="theme1-background" style="height:2px"></div>

		<div class="extended tiny-text">
			<div class="row">
				<div class="float-left">
					<a id="ctl00_PermaLink" itemprop="url" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi">Permalink</a> | 
					<a id="ctl00_AdvertiseLink" href="http://developermedia.com/">Advertise </a> |
					<a id="ctl00_PrivacyLink" href="/info/privacy.aspx">Privacy</a> |
					<a id="ctl00_Mobile" rel="nofollow" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?display=Mobile">Mobile</a>
					<br />
								
					
					Web03 |
					2.6.1309024.1 |
					Last Updated 5 Dec 2006								
				</div>
				<div class="float-right align-right">
					Article Copyright 2006 by Mike O'Neill<br />Everything else
					Copyright &copy; <a href="mailto:webmaster@codeproject.com">CodeProject</a>, 1999-2013 <br />
					<a id="ctl00_TermsOfUseLink" href="/info/TermsOfUse.aspx">Terms of Use</a>
				</div>

				


<div class="page-width">
Layout: <a id="ctl00_PageWidth_FixedT" title="Fixed width layout" rel="nofollow" class=" active" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?PageFlow=FixedWidth">fixed</a>
|
<a id="ctl00_PageWidth_FluidT" title="Fluid layout" rel="nofollow" href="/Articles/16650/Neural-Network-for-Recognition-of-Handwritten-Digi?PageFlow=Fluid">fluid</a>
</div>



			</div>
		</div>
		

		<br clear="all" />
		
			

	</div> 
	</div>
</div>


<div style="display:none;" id="lqm_AdTable">
	
</div>


<script type="text/javascript" language="Javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.6.2/jquery.min.js"></script><script type='text/javascript'>//<![CDATA[
if (typeof jQuery == 'undefined') {
    document.write(unescape("%3Cscript src='/script/JS/jquery-1.6.2.min.js' type='text/javascript' %3E%3C/script%3E"));
}//]]></script>
<script type="text/javascript" language="Javascript" src="/script/Articles/JS/article.min.js?dt=2.6.1309024.1"></script>
<script type="text/javascript" language="Javascript" src="/script/JS/navbar.min.js?dt=2.6.1309024.1"></script>
<script type="text/javascript" language="Javascript" src="/script/Membership/JS/Notifications.min.js?dt=2.6.1309024.1"></script>
<script type="text/javascript" language="Javascript">//<![CDATA[
$(document).ready(function() { anchorAnimate(); });
(function(d, s, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js = d.createElement(s); js.id = id; js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1"; fjs.parentNode.insertBefore(js, fjs); }(document, 'script', 'facebook-jssdk'));
(function() {var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = 'https://apis.google.com/js/plusone.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s); })();
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){ js=d.createElement(s);js.id=id; js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
var DMReportsOK = null;function showDMAlert() {   var $div = $('div.msg-728x90');  $div.append($('<img src="/images/alert-top-block.gif" style="right:0;position:absolute;z-index:0">'));}function onDMcallBack(event){   if (event.originalEvent) event = event.originalEvent;   jQuery.support.cors = true;   if (event.data == 'DM-disabled') DMReportsOK = false;   else if (event.data == 'DM-enabled') DMReportsOK = true;}function checkLoaded() {  var recordCheck  = false; var showBlockMsg = false; var block        = 'None'; if (!DMReportsOK && block == 'None' && typeof DMAds === 'undefined')     block = 'ResourceBlocked'; if (DMReportsOK === true) block = 'None'; else if (DMReportsOK === false) block = 'DomModified'; if (recordCheck) {  $.ajax({ url:'/script/AdServe/Ajax/VS.aspx',data:{'adbm':block}, cache:false, async:true }); } if (showBlockMsg && block != 'None')    showDMAlert();}$(document).ready(function() {  $(window).bind('message', onDMcallBack);  setTimeout(checkLoaded, 4000);});
var notificationAlert = new NotificationAlert('ctl00_MemberMenu_Messages_NotificationCount','Notifications','/script/Membership/Ajax/NotificationList.aspx');
notificationAlert.initialise();
var oSrchFlt = false, oSrchBox=false,srchBoxFoc=false;
$(document).ready(function() {
 if(InitWatermark)InitWatermark('sb_tb', 'Search for articles, questions, tips');
 var sbar = $('#sb_tb'); 
 var sfilter = $('#SearchFilter');
 if (sbar && sfilter) {
  sfilter.removeClass('popup'); sfilter.hide();
  sbar.blur(function() {
 if (!oSrchFlt)sfilter.hide();
 srchBoxFoc=false;
 /*sbar.animate( { width:'210px' }, { queue:false, duration:300 });
*/ });
  sbar.focus(function() {
 oSrchFlt=false;srchBoxFoc=true;
 sfilter.show();
 /*sbar.animate( { width:'500px' }, { queue:false, duration:300 });
*/ });
  sbar.mouseleave(function() { oSrchBox=false; });
  sbar.mouseover(function() { oSrchBox=true; });
  sfilter.mouseleave(function() { oSrchFlt=false; if (!srchBoxFoc&&!oSrchBox)sfilter.hide();});
  sfilter.mouseover(function() { oSrchFlt=true; });
 }
});
$("#ctl00_RateArticle_RateItemWrapper").removeClass("container-rating");$('#clear-rate_ctl00_RateArticle_RCD').click(function () { $('#ctl00_RateArticle_RCD').hide(); return false;});
function PostBack_ctl00_RateArticle_RateItemWrapper() {
  return rateItem(16650,2,1,true,true,3,'LargeStars');
}
function ChkRtctl00_RateArticle(val, objId) {if (val<=3||true) {
$('div[name=RateItem_' + objId + '] .rating-comment').css("display","");}
else $('div[name=RateItem_' + objId + '] .rating-comment').css("display","none");}

forumDir = '/script/Forums/';
staticServer = '';
allowReporting = false;
allowRating = true;
allowRatingDisplay = true;
var smoothScroll = false;
Selected        = -1;
oldTitle        = document.title;
minMessageScore = 1;
minMessageScore = 5;
abuseScore      = -2;
spamScore       = -1;
getRatingUrl    = '/script/Ratings/Ajax/GetRatings.aspx';
noiseThreshold  = 3;
getRatingRefKey = 'obrs';


//]]>
</script>


</body>
</html>